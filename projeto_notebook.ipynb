{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.io.arff import loadarff\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para criar os diretórios\n",
    "def creat_dir(model_name):\n",
    "    if not 'log_metrics' in os.listdir():\n",
    "        os.mkdir('log_metrics')\n",
    "    if not 'imgs' in os.listdir():\n",
    "        os.mkdir('imgs')\n",
    "    if not model_name in os.listdir('./imgs'):\n",
    "        os.mkdir('./imgs/'+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para adicionar as métricas de um fold em um dicionário\n",
    "def dic_par_metrics(y_test, y_onehot_test, y_pred, y_proba, grid_search_cv):\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    balanced_accuracy = metrics.balanced_accuracy_score(y_test, y_pred)\n",
    "    precision_micro = metrics.precision_score(y_test, y_pred, average='micro')\n",
    "    precision_macro = metrics.precision_score(y_test, y_pred, average='macro')\n",
    "    precision_weighted = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "    recall_micro = metrics.recall_score(y_test, y_pred, average='micro')\n",
    "    recall_macro = metrics.recall_score(y_test, y_pred, average='macro')\n",
    "    recall_weighted = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "    f1_micro = metrics.f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "    f1_weighted = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "    roc_auc_ovr_micro = metrics.roc_auc_score(y_onehot_test, y_proba, multi_class='ovr', average='micro')\n",
    "    roc_auc_ovo_micro = metrics.roc_auc_score(y_onehot_test, y_proba, multi_class='ovo', average='micro')\n",
    "    roc_auc_ovr_macro = metrics.roc_auc_score(y_onehot_test, y_proba, multi_class='ovr', average='macro')\n",
    "    roc_auc_ovo_macro = metrics.roc_auc_score(y_onehot_test, y_proba, multi_class='ovo', average='macro')\n",
    "    roc_auc_ovr_weighted = metrics.roc_auc_score(y_onehot_test, y_proba, multi_class='ovr', average='weighted')\n",
    "    roc_auc_ovo_weighted = metrics.roc_auc_score(y_onehot_test, y_proba, multi_class='ovo', average='weighted')\n",
    "    classification_report = metrics.classification_report(y_test, y_pred, output_dict=True)\n",
    "    dicMetricas = {\n",
    "        \"parameters\": grid_search_cv.best_params_,\n",
    "        \"metrics\":{\n",
    "            \"accuracy\": accuracy,\n",
    "            \"balanced_accuracy\": balanced_accuracy,\n",
    "            \"precision_micro\": precision_micro,\n",
    "            \"precision_macro\": precision_macro,\n",
    "            \"precision_weighted\": precision_weighted,\n",
    "            \"recall_micro\": recall_micro,\n",
    "            \"recall_macro\": recall_macro,\n",
    "            \"recall_weighted\": recall_weighted,\n",
    "            \"f1_micro\": f1_micro,\n",
    "            \"f1_macro\": f1_macro,\n",
    "            \"f1_weighted\": f1_weighted,\n",
    "            \"roc_auc_ovr_micro\": roc_auc_ovr_micro,\n",
    "            \"roc_auc_ovo_micro\": roc_auc_ovo_micro,\n",
    "            \"roc_auc_ovr_macro\": roc_auc_ovr_macro,\n",
    "            \"roc_auc_ovo_macro\": roc_auc_ovo_macro,\n",
    "            \"roc_auc_ovr_weighted\": roc_auc_ovr_weighted,\n",
    "            \"roc_auc_ovo_weighted\": roc_auc_ovo_weighted\n",
    "        },\n",
    "        \"classification_report\": classification_report\n",
    "    }\n",
    "    return dicMetricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para calcular a média e o desvio padrão das métricas de cada fold, além de plotar os boxplots\n",
    "def calc_mean_std(dic_json, model_name):\n",
    "    key = list(dic_json.keys())[0]\n",
    "    dic_mean = {}\n",
    "    dic_std = {}\n",
    "    for j in dic_json[key]['metrics'].keys():\n",
    "        metrics_list = []\n",
    "        for i in dic_json.keys():\n",
    "            metrics_list.append(dic_json[i]['metrics'][j])\n",
    "        mean = np.mean(metrics_list)\n",
    "        std = np.std(metrics_list)\n",
    "        dic_mean.update({j: mean})\n",
    "        dic_std.update({j: std})\n",
    "        plt.close('all')\n",
    "        plt.boxplot(metrics_list, labels=[model_name])\n",
    "        plt.ylabel(j)\n",
    "        plt.savefig('./imgs/'+model_name+'/boxplot_'+j+'.png')\n",
    "        plt.close('all')\n",
    "    dic_json.update({\"mean\": dic_mean})\n",
    "    dic_json.update({\"std\": dic_std})\n",
    "    return dic_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matriz_confusao_one_vs_one(y_test, y_pred, model_name, fold_i, flag_normalizado=\"true\"):\n",
    "    \"\"\"Plota a matriz de confusao comparando cada classe entre si, mostrando as predicoes contra as\n",
    "    classes verdadeiras.\n",
    "\n",
    "    Args:\n",
    "        y_test: serie com os valores verdadeiros\n",
    "        y_pred: serie com os valores preditos\n",
    "        flag_normalizado (optional): flag indicando se os valores da matriz de confusao devem ser\n",
    "        normalizados. Se devem ser normalizados pel. Defaults to None.\n",
    "    \"\"\"\n",
    "    class_names = np.unique(y_pred)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    cm_plot = metrics.ConfusionMatrixDisplay.from_predictions(\n",
    "        y_test, y_pred, cmap=\"YlOrRd\", normalize=flag_normalizado, ax=ax)\n",
    "    ax.set_xticklabels(class_names, rotation=45, ha=\"right\")\n",
    "    ax.set_title(f\"Matriz de Confusao - Modelo {model_name} - Fold {fold_i}\")\n",
    "\n",
    "    cm_plot.figure_.savefig(\n",
    "        f\"imgs/{model_name}/cm_normalizado_{flag_normalizado}_{model_name}_fold_{fold_i}.png\", \n",
    "        dpi=300\n",
    "    )\n",
    "    plt.close()\n",
    "    \n",
    "    return cm_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicializa_roc_one_class_vs_rest_kfold(y_onehot_test, y_pred_score, i, class_id, ax, tprs, aucs, mean_fpr):\n",
    "    viz = metrics.RocCurveDisplay.from_predictions(\n",
    "        y_onehot_test[:, class_id],\n",
    "        y_pred_score[:, class_id],\n",
    "        name=f\"ROC OvR Class_{class_id+1} fold {i}\",\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "        plot_chance_level=(i==9),\n",
    "    )\n",
    "\n",
    "    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_roc_one_class_vs_rest_kfold(tprs, aucs, mean_fpr, plot, model_name, class_id):\n",
    "    fig = plot[0]\n",
    "    ax = plot[1]\n",
    "    \n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = metrics.auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    ax.plot(\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        color=\"b\",\n",
    "        label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(\n",
    "        mean_fpr,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        label=r\"$\\pm$ 1 std. dev.\",\n",
    "    )\n",
    "    ax.set(\n",
    "        xlim=[-0.05, 1.05],\n",
    "        ylim=[-0.05, 1.05],\n",
    "        xlabel=\"False Positive Rate\",\n",
    "        ylabel=\"True Positive Rate\",\n",
    "        title=f\"Curva ROC media com desvio padrao\\nROC OvR Class_{class_id+1}\",\n",
    "    )\n",
    "    ax.axis(\"square\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    fig.savefig(f\"imgs/{model_name}/roc_{model_name}_class_{class_id+1}.png\", dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicializa_roc_micro_average_kfold(y_onehot_test, y_pred_score, i, ax, tprs, aucs, mean_fpr):\n",
    "    viz = metrics.RocCurveDisplay.from_predictions(\n",
    "        y_onehot_test.ravel(),\n",
    "        y_pred_score.ravel(),\n",
    "        name=f\"micro-average OvR fold {i}\",\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "        plot_chance_level=(i==9)\n",
    "    )\n",
    "\n",
    "    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_roc_micro_average_kfold(tprs, aucs, mean_fpr, fig, ax, model_name):\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = metrics.auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    ax.plot(\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        color=\"b\",\n",
    "        label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(\n",
    "        mean_fpr,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        label=r\"$\\pm$ 1 std. dev.\",\n",
    "    )\n",
    "    ax.set(\n",
    "        xlim=[-0.05, 1.05],\n",
    "        ylim=[-0.05, 1.05],\n",
    "        xlabel=\"False Positive Rate\",\n",
    "        ylabel=\"True Positive Rate\",\n",
    "        title=f\"Curva ROC media com desvio padrao\\nROC micro-average\",\n",
    "    )\n",
    "    ax.axis(\"square\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    fig.savefig(f\"imgs/{model_name}/roc_micro_average_{model_name}.png\", dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_k_fold_grid_search_cv(\n",
    "        model, params:dict, X, y, model_name, flag_smote=False, flag_variance_threshold=False,\n",
    "        flag_pca=False\n",
    "):\n",
    "    \"\"\"Realiza o treino e validacao do modelo utilizando StratifiedKFold com GridSearchCV para\n",
    "    busca dos melhores hiperparametros (tendo assim um nested cross-validation).\n",
    "\n",
    "    Args:\n",
    "        model: modelo que se deseja treinar e validar\n",
    "        params (dict): dicionario com os parametros e seus respectivos valores possiveis para o \n",
    "        grid search\n",
    "        X: features do modelo\n",
    "        y: coluna de target do modelo\n",
    "    \"\"\"\n",
    "    startTime = time.time()\n",
    "    # criando os diretórios necessários para salvar as métricas e os plots\n",
    "    creat_dir(model_name)\n",
    "\n",
    "    print(f\"Modelo: {model_name}\")\n",
    "    dic_json = {}\n",
    "\n",
    "    n_splits_k_fold = 10\n",
    "    n_splits_grid_search = 5\n",
    "\n",
    "    matriz_tprs = [[] for i in range(9)]\n",
    "    matriz_aucs = [[] for i in range(9)]\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    lista_plots = [plt.subplots(figsize=(6, 6)) for i in range(9)]\n",
    "\n",
    "    tprs_micro_average = []\n",
    "    aucs_micro_average = []\n",
    "    fig_micro_average, ax_micro_average = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits_k_fold, random_state=4, shuffle=True)\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        print(f\"## INICIO FOLD {i} ##\")\n",
    "        # separa os dados de treino e teste\n",
    "        X_train = X.iloc[train_index]\n",
    "        X_test = X.iloc[test_index]\n",
    "        y_train = y.iloc[train_index]\n",
    "        y_test = y.iloc[test_index]\n",
    "        # realiza a tecnica SMOTE no dados de treino para tratamento do desbalanceamento\n",
    "        if flag_smote:\n",
    "            smote = SMOTE(random_state=4)\n",
    "            X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "        # realiza a tecnica de selecao de atributos utilizando Variance Threshold\n",
    "        if flag_variance_threshold:\n",
    "            filter_variance = VarianceThreshold(0.8)\n",
    "            X_train = filter_variance.fit_transform(X_train)\n",
    "            X_test = filter_variance.transform(X_test)\n",
    "        # normaliza os dados\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        # realiza a tecnica de extracao de caracteristicas e reducao de dimensionalidade PCA\n",
    "        if flag_pca:\n",
    "            # mantem apenas os componentes principais que contem 90% da informacao dos dados \n",
    "            # originais\n",
    "            pca = PCA(n_components=0.9, svd_solver=\"full\")\n",
    "            X_train = pca.fit_transform(X_train)\n",
    "            X_test = pca.transform(X_test)\n",
    "        # binariza a coluna target para uso no plot roc e metrica roc_auc_score\n",
    "        label_binarizer = LabelBinarizer().fit(y_train)\n",
    "        y_onehot_test = label_binarizer.transform(y_test)\n",
    "        # prepara o y_train\n",
    "        y_train = y_train.values.ravel()\n",
    "        # inicializa e roda o grid search\n",
    "        grid_search_cv = GridSearchCV(\n",
    "            estimator=model, param_grid=params, scoring=\"f1_weighted\", cv=n_splits_grid_search, \n",
    "            verbose=3)\n",
    "        grid_search_cv.fit(X_train, y_train)\n",
    "        # com os melhores parametros encontrados, realiza a predicao no fold de teste e calcula a \n",
    "        # metrica de avaliacao\n",
    "        y_pred = grid_search_cv.predict(X_test)\n",
    "        # verifica se o modelo em execucao eh o perceptron, ja que o mesmo nao possui a funcao \n",
    "        # predict_proba\n",
    "        if model_name != 'Perceptron':\n",
    "            y_proba = grid_search_cv.predict_proba(X_test)\n",
    "        else:\n",
    "            y_proba = grid_search_cv.decision_function(X_test)\n",
    "        # armazenando as metricas e os parametros em um dicionario\n",
    "        dic_fold = dic_par_metrics(y_test, y_onehot_test, y_pred, y_proba, grid_search_cv)\n",
    "        dic_json.update({\"fold \"+str(i): dic_fold})\n",
    "        # gera a matriz de confusao com dados normalizados e nao normalizados e salva ambas versoes\n",
    "        plot_matriz_confusao_one_vs_one(y_test, y_pred, model_name, i, flag_normalizado=\"true\")\n",
    "        plot_matriz_confusao_one_vs_one(y_test, y_pred, model_name, i, flag_normalizado=None)\n",
    "        # inicializa a curva roc para cada classe neste fold\n",
    "        for class_id, plot, tprs, aucs in zip(range(9), lista_plots, matriz_tprs, matriz_aucs):\n",
    "            inicializa_roc_one_class_vs_rest_kfold(\n",
    "                y_onehot_test, y_proba, i, class_id, plot[1], tprs, aucs, mean_fpr\n",
    "            )\n",
    "        # inicializa a curva roc micro average neste fold\n",
    "        inicializa_roc_micro_average_kfold(\n",
    "            y_onehot_test, y_proba, i, ax_micro_average, tprs_micro_average, \n",
    "            aucs_micro_average, mean_fpr\n",
    "        )\n",
    "        print(f\"## FINAL FOLD {i} ##\\n\", dic_fold)\n",
    "\n",
    "    endTime = time.time()\n",
    "    # inserindo a média dos folds no dicionário\n",
    "    dic_json = calc_mean_std(dic_json, model_name)\n",
    "    # inserindo o tempo de execução\n",
    "    dic_json.update({\"time\": endTime-startTime})\n",
    "    # salvando o dicionário no formato json\n",
    "    objOpen = open(f'./log_metrics/{model_name}.json', 'w')\n",
    "    objOpen.write(json.dumps(dic_json, indent=4))\n",
    "    objOpen.close()\n",
    "\n",
    "    # gera o plot da curva roc para cada classe, juntando todos os folds e realizando uma media\n",
    "    for class_id, plot, tprs, aucs in zip(range(9), lista_plots, matriz_tprs, matriz_aucs):\n",
    "        gera_roc_one_class_vs_rest_kfold(tprs, aucs, mean_fpr, plot, model_name, class_id)\n",
    "    # gera o plot da curva roc micro average, juntando todos os folds e realizando uma media \n",
    "    gera_roc_micro_average_kfold(\n",
    "        tprs_micro_average, aucs_micro_average, mean_fpr, fig_micro_average, ax_micro_average, \n",
    "        model_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carrega dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = loadarff('data/dataset.arff')\n",
    "df_data = pd.DataFrame(raw_data[0])\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decodifica string de target\n",
    "df_data[\"target\"] = df_data[\"target\"].str.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando o número de linhas e colunas do dataset\n",
    "print(\"Shape dataset:\", df_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando o menor valor das colunas de características\n",
    "print(\"Valor mínimo das features:\", df_data.iloc[:,1:-1].min().min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando o maior valor das colunas de características\n",
    "print(\"Valor máximo das features:\", df_data.iloc[:,1:-1].max().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando o número de instâncias para cada classe\n",
    "print('Número de Instâncias por Classe:\\n', df_data.groupby('target').count()['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando o percentual de instâncias para cada classe\n",
    "print('Percentual de Instâncias por Classe:\\n', (df_data.groupby('target').count()['id']/df_data.shape[0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando se existem valores NaN\n",
    "print('\\nNúmero de Valores NaN:', df_data.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_data.drop(columns=[\"id\", \"target\"])\n",
    "y = df_data[[\"target\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"n_neighbors\": [5, 10, 15]\n",
    "}\n",
    "# define o modelo\n",
    "model = KNeighborsClassifier(n_jobs=1)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"n_neighbors\": [5, 10, 15]\n",
    "}\n",
    "# define o modelo\n",
    "model = KNeighborsClassifier(n_jobs=1)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"KNN_smote\", flag_smote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"n_neighbors\": [5, 10, 15]\n",
    "}\n",
    "# define o modelo\n",
    "model = KNeighborsClassifier(n_jobs=1)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(\n",
    "    model, params, X, y, \"KNN_variance_threshold\", flag_variance_threshold=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"n_neighbors\": [5, 10, 15]\n",
    "}\n",
    "# define o modelo\n",
    "model = KNeighborsClassifier(n_jobs=1)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(\n",
    "    model, params, X, y, \"KNN_pca\", flag_pca=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"max_depth\": [None, 50, 100, 200, 500, 1000]\n",
    "}\n",
    "# define o modelo\n",
    "model = DecisionTreeClassifier(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"DecisionTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"max_depth\": [None, 50, 100, 200, 500, 1000]\n",
    "}\n",
    "# define o modelo\n",
    "model = DecisionTreeClassifier(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"DecisionTree_smote\", flag_smote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"max_depth\": [None, 50, 100, 200, 500, 1000]\n",
    "}\n",
    "# define o modelo\n",
    "model = DecisionTreeClassifier(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(\n",
    "    model, params, X, y, \"DecisionTree_variance_threshold\", flag_variance_threshold=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"max_depth\": [None, 50, 100, 200, 500, 1000]\n",
    "}\n",
    "# define o modelo\n",
    "model = DecisionTreeClassifier(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(\n",
    "    model, params, X, y, \"DecisionTree_pca\", flag_pca=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação efeito PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sem PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dt_sem_pca, X_test_dt_sem_pca, y_train_dt_sem_pca, y_test_dt_sem_pca = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=4)\n",
    "# define o modelo\n",
    "model_dt_sem_pca = DecisionTreeClassifier(random_state=4)\n",
    "# normaliza os dados\n",
    "scaler_dt_sem_pca = StandardScaler()\n",
    "X_train_dt_sem_pca = scaler_dt_sem_pca.fit_transform(X_train_dt_sem_pca)\n",
    "X_test_dt_sem_pca = scaler_dt_sem_pca.transform(X_test_dt_sem_pca)\n",
    "# inicializa e roda o grid search\n",
    "model_dt_sem_pca.fit(X_train_dt_sem_pca, y_train_dt_sem_pca)\n",
    "# com os melhores parametros encontrados, realiza a predicao no fold de teste e calcula a \n",
    "# metrica de avaliacao\n",
    "y_pred_dt_sem_pca = model_dt_sem_pca.predict(X_test_dt_sem_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt_sem_pca.get_n_leaves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt_sem_pca.get_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Com PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dt_com_pca, X_test_dt_com_pca, y_train_dt_com_pca, y_test_dt_com_pca = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=4)\n",
    "# define o modelo\n",
    "model_dt_com_pca = DecisionTreeClassifier(random_state=4)\n",
    "# normaliza os dados\n",
    "scaler_dt_com_pca = StandardScaler()\n",
    "X_train_dt_com_pca = scaler_dt_com_pca.fit_transform(X_train_dt_com_pca)\n",
    "X_test_dt_com_pca = scaler_dt_com_pca.transform(X_test_dt_com_pca)\n",
    "# realiza a tecnica de extracao de caracteristicas e reducao de dimensionalidade PCA\n",
    "# mantem apenas os componentes principais que contem 90% da informacao dos dados \n",
    "# originais\n",
    "pca_dt_com_pca = PCA(n_components=0.9, svd_solver=\"full\")\n",
    "X_train_dt_com_pca = pca_dt_com_pca.fit_transform(X_train_dt_com_pca)\n",
    "X_test_dt_com_pca = pca_dt_com_pca.transform(X_test_dt_com_pca)\n",
    "# inicializa e roda o grid search\n",
    "model_dt_com_pca.fit(X_train_dt_com_pca, y_train_dt_com_pca)\n",
    "# com os melhores parametros encontrados, realiza a predicao no fold de teste e calcula a \n",
    "# metrica de avaliacao\n",
    "y_pred_dt_com_pca = model.predict(X_test_dt_com_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt_com_pca.get_n_leaves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt_com_pca.get_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    #\"n_estimators\": [100, 300, 500],\n",
    "    \"n_estimators\": [300, 500],\n",
    "    #\"max_depth\": [None, 400, 800],\n",
    "    \"class_weight\": [\"balanced_subsample\", None]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = RandomForestClassifier(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"RandomForest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    #\"n_estimators\": [100, 300, 500],\n",
    "    \"n_estimators\": [300, 500],\n",
    "    #\"max_depth\": [None, 400, 800],\n",
    "    \"class_weight\": [\"balanced_subsample\", None]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = RandomForestClassifier(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"RandomForest_smote\", flag_smote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    #\"n_estimators\": [100, 300, 500],\n",
    "    \"n_estimators\": [300, 500],\n",
    "    #\"max_depth\": [None, 400, 800],\n",
    "    \"class_weight\": [\"balanced_subsample\", None]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = RandomForestClassifier(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(\n",
    "    model, params, X, y, \"RandomForest_variance_threshold\", flag_variance_threshold=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    #\"n_estimators\": [100, 300, 500],\n",
    "    \"n_estimators\": [300, 500],\n",
    "    #\"max_depth\": [None, 400, 800],\n",
    "    \"class_weight\": [\"balanced_subsample\", None]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = RandomForestClassifier(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"RandomForest_pca\", flag_pca=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes (Gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = GaussianNB()\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"NaiveBayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = GaussianNB()\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"NaiveBayes_smote\", flag_smote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = GaussianNB()\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(\n",
    "    model, params, X, y, \"NaiveBayes_variance_threshold\", flag_variance_threshold=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = GaussianNB()\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"NaiveBayes_pca\", flag_pca=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"penalty\": [None, \"l2\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"max_iter\": [100, 300, 500, 700, 1000]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = LogisticRegression(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"LogisticRegression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"penalty\": [None, \"l2\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"max_iter\": [100, 300, 500, 700, 1000]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = LogisticRegression(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"LogisticRegression_smote\", flag_smote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"penalty\": [None, \"l2\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"max_iter\": [100, 300, 500, 700, 1000]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = LogisticRegression(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(\n",
    "    model, params, X, y, \"LogisticRegression_variance_threshold\", flag_variance_threshold=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"penalty\": [None, \"l2\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"max_iter\": [100, 300, 500, 700, 1000]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = LogisticRegression(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"LogisticRegression_pca\", flag_pca=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"penalty\": [None, \"l2\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"max_iter\": [100, 300, 500, 700, 1000]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = Perceptron(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"Perceptron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"penalty\": [None, \"l2\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"max_iter\": [100, 300, 500, 700, 1000]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = Perceptron(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"Perceptron_smote\", flag_smote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"penalty\": [None, \"l2\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"max_iter\": [100, 300, 500, 700, 1000]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = Perceptron(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(\n",
    "    model, params, X, y, \"Perceptron_variance_threshold\", flag_variance_threshold=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"penalty\": [None, \"l2\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"max_iter\": [100, 300, 500, 700, 1000]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = Perceptron(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"Perceptron_pca\", flag_pca=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"learning_rate_init\": [0.001, 0.01],\n",
    "    # \"max_iter\": [200, 500, 700],\n",
    "    \"max_iter\": [200, 500],\n",
    "    # \"hidden_layer_sizes\": [20, 50, 100]\n",
    "    \"hidden_layer_sizes\": [50, 100]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = MLPClassifier(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"MLPClassifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"learning_rate_init\": [0.001, 0.01],\n",
    "    # \"max_iter\": [200, 500, 700],\n",
    "    \"max_iter\": [200, 500],\n",
    "    # \"hidden_layer_sizes\": [20, 50, 100]\n",
    "    \"hidden_layer_sizes\": [50, 100]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = MLPClassifier(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"MLPClassifier_smote\", flag_smote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"learning_rate_init\": [0.001, 0.01],\n",
    "    # \"max_iter\": [200, 500, 700],\n",
    "    \"max_iter\": [200, 500],\n",
    "    # \"hidden_layer_sizes\": [20, 50, 100]\n",
    "    \"hidden_layer_sizes\": [50, 100]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = MLPClassifier(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(\n",
    "    model, params, X, y, \"MLPClassifier_variance_threshold\", flag_variance_threshold=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"learning_rate_init\": [0.001, 0.01],\n",
    "    # \"max_iter\": [200, 500, 700],\n",
    "    \"max_iter\": [200, 500],\n",
    "    # \"hidden_layer_sizes\": [20, 50, 100]\n",
    "    \"hidden_layer_sizes\": [50, 100]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = MLPClassifier(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"MLPClassifier_pca\", flag_pca=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"C\": [1],\n",
    "    \"kernel\": [\"rbf\", \"linear\"]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = SVC(random_state=4, probability=True)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"C\": [1],\n",
    "    \"kernel\": [\"rbf\", \"linear\"]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = SVC(random_state=4, probability=True)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"SVM_pca\", flag_pca=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste de Hipótese\n",
    "\n",
    "Vamos avaliar se a média dos resultados obtidos com o modelo Random Forest é maior que a média dos resultados obtidos com o modelo MLP. Iremos realizar um teste de hipótese para checar se, estatisticamente, podemos constatar essa afirmação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"log_metrics/RandomForest.json\") as json_file:\n",
    "    json_rf = json.load(json_file)\n",
    "\n",
    "lista_resultados_rf = []\n",
    "for key in list(json_rf.keys()):\n",
    "    if (key != \"mean\") & (key != \"std\") & (key != \"time\"):\n",
    "        lista_resultados_rf.append(json_rf[key][\"metrics\"][\"f1_weighted\"])\n",
    "\n",
    "with open(\"log_metrics/MLPClassifier.json\") as json_file:\n",
    "    json_mlp = json.load(json_file)\n",
    "\n",
    "lista_resultados_mlp = []\n",
    "for key in list(json_mlp.keys()):\n",
    "    if (key != \"mean\") & (key != \"std\") & (key != \"time\"):\n",
    "        lista_resultados_mlp.append(json_mlp[key][\"metrics\"][\"f1_weighted\"])\n",
    "\n",
    "df_resultados = pd.DataFrame({\"rf\": lista_resultados_rf, \"mlp\": lista_resultados_mlp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "sns.set(rc={'figure.figsize':(10,5)})\n",
    "\n",
    "sns.histplot(df_resultados, x=\"rf\", ax=ax[0]).set_title(\"Distribuicao Random Forest\")\n",
    "sns.histplot(df_resultados, x=\"mlp\", ax=ax[1]).set_title(\"Distribuicao MLP\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Teste normalidade random forest: {stats.shapiro(df_resultados['rf'])}\\n\"\n",
    "    f\"Teste normalidade mlp: {stats.shapiro(df_resultados['mlp'])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.mannwhitneyu(df_resultados[\"rf\"], df_resultados[\"mlp\"], alternative=\"greater\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Variancia random forest: {np.var(df_resultados['rf'])}\\n\"\n",
    "    f\"Variancia mlp: {np.var(df_resultados['mlp'])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(a=df_resultados[\"rf\"], b=df_resultados[\"mlp\"], equal_var=True, alternative=\"greater\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo da média das métricas de performance por classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"MLPClassifier_smote\"\n",
    "with open(f\"log_metrics/{}.json\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "    precision_dict = {}\n",
    "    precision_mean_dict = {}\n",
    "    precision_std_dict = {}\n",
    "    recall_dict = {}\n",
    "    recall_mean_dict = {}\n",
    "    recall_std_dict = {}\n",
    "    f1_score_dict = {}\n",
    "    f1_score_mean_dict = {}\n",
    "    f1_score_std_dict = {}\n",
    "\n",
    "    for fold in data:\n",
    "        if \"fold \" in fold:\n",
    "            for class_number in data[fold][\"classification_report\"]:\n",
    "                if \"Class_\" in class_number:\n",
    "                    if class_number not in precision_dict:\n",
    "                        precision_dict[class_number] = []\n",
    "                    if class_number not in recall_dict:\n",
    "                        recall_dict[class_number] = []\n",
    "                    if class_number not in f1_score_dict:\n",
    "                        f1_score_dict[class_number] = []\n",
    "                    for class_metric in data[fold][\"classification_report\"][class_number]:\n",
    "                            if class_metric == \"precision\":\n",
    "                                precision_dict[class_number].append(\n",
    "                                    data[fold][\"classification_report\"][class_number][class_metric]\n",
    "                                )\n",
    "                            if class_metric == \"recall\":\n",
    "                                recall_dict[class_number].append(\n",
    "                                    data[fold][\"classification_report\"][class_number][class_metric]\n",
    "                                )\n",
    "                            if class_metric == \"f1-score\":\n",
    "                                f1_score_dict[class_number].append(\n",
    "                                    data[fold][\"classification_report\"][class_number][class_metric]\n",
    "                                )\n",
    "    for class_number in precision_dict:\n",
    "        precision_mean_dict[class_number] = np.mean(precision_dict[class_number])\n",
    "        precision_std_dict[class_number] = np.std(precision_dict[class_number])\n",
    "\n",
    "    for class_number in recall_dict:\n",
    "        recall_mean_dict[class_number] = np.mean(recall_dict[class_number])\n",
    "        recall_std_dict[class_number] = np.std(recall_dict[class_number])\n",
    "\n",
    "    for class_number in f1_score_dict:\n",
    "        f1_score_mean_dict[class_number] = np.mean(f1_score_dict[class_number])\n",
    "        f1_score_std_dict[class_number] = np.std(f1_score_dict[class_number])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
