{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.io.arff import loadarff\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para criar os diretórios\n",
    "def creat_dir(model_name):\n",
    "    if not 'log_metrics' in os.listdir():\n",
    "        os.mkdir('log_metrics')\n",
    "    if not 'imgs' in os.listdir():\n",
    "        os.mkdir('imgs')\n",
    "    if not model_name in os.listdir('./imgs'):\n",
    "        os.mkdir('./imgs/'+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para adicionar as métricas de um fold em um dicionário\n",
    "def dic_par_metrics(y_test, y_onehot_test, y_pred, y_proba, grid_search_cv):\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    balanced_accuracy = metrics.balanced_accuracy_score(y_test, y_pred)\n",
    "    precision_micro = metrics.precision_score(y_test, y_pred, average='micro')\n",
    "    precision_macro = metrics.precision_score(y_test, y_pred, average='macro')\n",
    "    precision_weighted = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "    recall_micro = metrics.recall_score(y_test, y_pred, average='micro')\n",
    "    recall_macro = metrics.recall_score(y_test, y_pred, average='macro')\n",
    "    recall_weighted = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "    f1_micro = metrics.f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "    f1_weighted = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "    roc_auc_ovr_micro = metrics.roc_auc_score(y_onehot_test, y_proba, multi_class='ovr', average='micro')\n",
    "    roc_auc_ovo_micro = metrics.roc_auc_score(y_onehot_test, y_proba, multi_class='ovo', average='micro')\n",
    "    roc_auc_ovr_macro = metrics.roc_auc_score(y_onehot_test, y_proba, multi_class='ovr', average='macro')\n",
    "    roc_auc_ovo_macro = metrics.roc_auc_score(y_onehot_test, y_proba, multi_class='ovo', average='macro')\n",
    "    roc_auc_ovr_weighted = metrics.roc_auc_score(y_onehot_test, y_proba, multi_class='ovr', average='weighted')\n",
    "    roc_auc_ovo_weighted = metrics.roc_auc_score(y_onehot_test, y_proba, multi_class='ovo', average='weighted')\n",
    "    classification_report = metrics.classification_report(y_test, y_pred, output_dict=True)\n",
    "    dicMetricas = {\n",
    "        \"parameters\": grid_search_cv.best_params_,\n",
    "        \"metrics\":{\n",
    "            \"accuracy\": accuracy,\n",
    "            \"balanced_accuracy\": balanced_accuracy,\n",
    "            \"precision_micro\": precision_micro,\n",
    "            \"precision_macro\": precision_macro,\n",
    "            \"precision_weighted\": precision_weighted,\n",
    "            \"recall_micro\": recall_micro,\n",
    "            \"recall_macro\": recall_macro,\n",
    "            \"recall_weighted\": recall_weighted,\n",
    "            \"f1_micro\": f1_micro,\n",
    "            \"f1_macro\": f1_macro,\n",
    "            \"f1_weighted\": f1_weighted,\n",
    "            \"roc_auc_ovr_micro\": roc_auc_ovr_micro,\n",
    "            \"roc_auc_ovo_micro\": roc_auc_ovo_micro,\n",
    "            \"roc_auc_ovr_macro\": roc_auc_ovr_macro,\n",
    "            \"roc_auc_ovo_macro\": roc_auc_ovo_macro,\n",
    "            \"roc_auc_ovr_weighted\": roc_auc_ovr_weighted,\n",
    "            \"roc_auc_ovo_weighted\": roc_auc_ovo_weighted\n",
    "        },\n",
    "        \"classification_report\": classification_report\n",
    "    }\n",
    "    return dicMetricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para calcular a média e o desvio padrão das métricas de cada fold, além de plotar os boxplots\n",
    "def calc_mean_std(dic_json, model_name):\n",
    "    key = list(dic_json.keys())[0]\n",
    "    dic_mean = {}\n",
    "    dic_std = {}\n",
    "    for j in dic_json[key]['metrics'].keys():\n",
    "        metrics_list = []\n",
    "        for i in dic_json.keys():\n",
    "            metrics_list.append(dic_json[i]['metrics'][j])\n",
    "        mean = np.mean(metrics_list)\n",
    "        std = np.std(metrics_list)\n",
    "        dic_mean.update({j: mean})\n",
    "        dic_std.update({j: std})\n",
    "        plt.close('all')\n",
    "        plt.boxplot(metrics_list, labels=[model_name])\n",
    "        plt.ylabel(j)\n",
    "        plt.savefig('./imgs/'+model_name+'/boxplot_'+j+'.png')\n",
    "        plt.close('all')\n",
    "    dic_json.update({\"mean\": dic_mean})\n",
    "    dic_json.update({\"std\": dic_std})\n",
    "    return dic_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matriz_confusao_one_vs_one(y_test, y_pred, model_name, fold_i, flag_normalizado=\"true\"):\n",
    "    \"\"\"Plota a matriz de confusao comparando cada classe entre si, mostrando as predicoes contra as\n",
    "    classes verdadeiras.\n",
    "\n",
    "    Args:\n",
    "        y_test: serie com os valores verdadeiros\n",
    "        y_pred: serie com os valores preditos\n",
    "        flag_normalizado (optional): flag indicando se os valores da matriz de confusao devem ser\n",
    "        normalizados. Se devem ser normalizados pel. Defaults to None.\n",
    "    \"\"\"\n",
    "    class_names = np.unique(y_pred)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    cm_plot = metrics.ConfusionMatrixDisplay.from_predictions(\n",
    "        y_test, y_pred, cmap=\"YlOrRd\", normalize=flag_normalizado, ax=ax)\n",
    "    ax.set_xticklabels(class_names, rotation=45, ha=\"right\")\n",
    "    ax.set_title(f\"Matriz de Confusao - Modelo {model_name} - Fold {fold_i}\")\n",
    "\n",
    "    cm_plot.figure_.savefig(\n",
    "        f\"imgs/{model_name}/cm_normalizado_{flag_normalizado}_{model_name}_fold_{fold_i}.png\", \n",
    "        dpi=300\n",
    "    )\n",
    "    plt.close()\n",
    "    \n",
    "    return cm_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicializa_roc_one_class_vs_rest_kfold(y_onehot_test, y_pred_score, i, class_id, ax, tprs, aucs, mean_fpr):\n",
    "    viz = metrics.RocCurveDisplay.from_predictions(\n",
    "        y_onehot_test[:, class_id],\n",
    "        y_pred_score[:, class_id],\n",
    "        name=f\"ROC OvR Class_{class_id+1} fold {i}\",\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "        plot_chance_level=(i==9),\n",
    "    )\n",
    "\n",
    "    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_roc_one_class_vs_rest_kfold(tprs, aucs, mean_fpr, plot, model_name, class_id):\n",
    "    fig = plot[0]\n",
    "    ax = plot[1]\n",
    "    \n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = metrics.auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    ax.plot(\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        color=\"b\",\n",
    "        label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(\n",
    "        mean_fpr,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        label=r\"$\\pm$ 1 std. dev.\",\n",
    "    )\n",
    "    ax.set(\n",
    "        xlim=[-0.05, 1.05],\n",
    "        ylim=[-0.05, 1.05],\n",
    "        xlabel=\"False Positive Rate\",\n",
    "        ylabel=\"True Positive Rate\",\n",
    "        title=f\"Curva ROC media com desvio padrao\\nROC OvR Class_{class_id+1}\",\n",
    "    )\n",
    "    ax.axis(\"square\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    fig.savefig(f\"imgs/{model_name}/roc_{model_name}_class_{class_id+1}.png\", dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicializa_roc_micro_average_kfold(y_onehot_test, y_pred_score, i, ax, tprs, aucs, mean_fpr):\n",
    "    viz = metrics.RocCurveDisplay.from_predictions(\n",
    "        y_onehot_test.ravel(),\n",
    "        y_pred_score.ravel(),\n",
    "        name=f\"micro-average OvR fold {i}\",\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "        plot_chance_level=(i==9)\n",
    "    )\n",
    "\n",
    "    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_roc_micro_average_kfold(tprs, aucs, mean_fpr, fig, ax, model_name):\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = metrics.auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    ax.plot(\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        color=\"b\",\n",
    "        label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(\n",
    "        mean_fpr,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        label=r\"$\\pm$ 1 std. dev.\",\n",
    "    )\n",
    "    ax.set(\n",
    "        xlim=[-0.05, 1.05],\n",
    "        ylim=[-0.05, 1.05],\n",
    "        xlabel=\"False Positive Rate\",\n",
    "        ylabel=\"True Positive Rate\",\n",
    "        title=f\"Curva ROC media com desvio padrao\\nROC micro-average\",\n",
    "    )\n",
    "    ax.axis(\"square\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    fig.savefig(f\"imgs/{model_name}/roc_micro_average_{model_name}.png\", dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_k_fold_grid_search_cv(model, params:dict, X, y, model_name):\n",
    "    \"\"\"Realiza o treino e validacao do modelo utilizando StratifiedKFold com GridSearchCV para\n",
    "    busca dos melhores hiperparametros (tendo assim um nested cross-validation).\n",
    "\n",
    "    Args:\n",
    "        model: modelo que se deseja treinar e validar\n",
    "        params (dict): dicionario com os parametros e seus respectivos valores possiveis para o \n",
    "        grid search\n",
    "        X: features do modelo\n",
    "        y: coluna de target do modelo\n",
    "    \"\"\"\n",
    "    startTime = time.time()\n",
    "    # criando os diretórios necessários para salvar as métricas e os plots\n",
    "    creat_dir(model_name)\n",
    "\n",
    "    print(f\"Modelo: {model_name}\")\n",
    "    dic_json = {}\n",
    "\n",
    "    n_splits_k_fold = 10\n",
    "    n_splits_grid_search = 5\n",
    "\n",
    "    matriz_tprs = [[] for i in range(9)]\n",
    "    matriz_aucs = [[] for i in range(9)]\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    lista_plots = [plt.subplots(figsize=(6, 6)) for i in range(9)]\n",
    "\n",
    "    tprs_micro_average = []\n",
    "    aucs_micro_average = []\n",
    "    fig_micro_average, ax_micro_average = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits_k_fold, random_state=4, shuffle=True)\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        print(f\"## INICIO FOLD {i} ##\")\n",
    "        # separa os dados de treino e teste\n",
    "        X_train = X.iloc[train_index]\n",
    "        X_test = X.iloc[test_index]\n",
    "        y_train = y.iloc[train_index]\n",
    "        y_test = y.iloc[test_index]\n",
    "        # normaliza os dados\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        # binariza a coluna target para uso no plot roc e metrica roc_auc_score\n",
    "        label_binarizer = LabelBinarizer().fit(y_train)\n",
    "        y_onehot_test = label_binarizer.transform(y_test)\n",
    "        # prepara o y_train\n",
    "        y_train = y_train.values.ravel()\n",
    "        # inicializa e roda o grid search\n",
    "        grid_search_cv = GridSearchCV(\n",
    "            estimator=model, param_grid=params, scoring=\"f1_weighted\", cv=n_splits_grid_search, \n",
    "            verbose=3)\n",
    "        grid_search_cv.fit(X_train, y_train)\n",
    "        # com os melhores parametros encontrados, realiza a predicao no fold de teste e calcula a \n",
    "        # metrica de avaliacao\n",
    "        y_pred = grid_search_cv.predict(X_test)\n",
    "        # verifica se o modelo em execucao eh o perceptron, ja que o mesmo nao possui a funcao \n",
    "        # predict_proba\n",
    "        if model_name != 'Perceptron':\n",
    "            y_proba = grid_search_cv.predict_proba(X_test)\n",
    "        else:\n",
    "            y_proba = grid_search_cv.decision_function(X_test)\n",
    "        # armazenando as metricas e os parametros em um dicionario\n",
    "        dic_fold = dic_par_metrics(y_test, y_onehot_test, y_pred, y_proba, grid_search_cv)\n",
    "        dic_json.update({\"fold \"+str(i): dic_fold})\n",
    "        # gera a matriz de confusao com dados normalizados e nao normalizados e salva ambas versoes\n",
    "        plot_matriz_confusao_one_vs_one(y_test, y_pred, model_name, i, flag_normalizado=\"true\")\n",
    "        plot_matriz_confusao_one_vs_one(y_test, y_pred, model_name, i, flag_normalizado=None)\n",
    "        # inicializa a curva roc para cada classe neste fold\n",
    "        for class_id, plot, tprs, aucs in zip(range(9), lista_plots, matriz_tprs, matriz_aucs):\n",
    "            inicializa_roc_one_class_vs_rest_kfold(\n",
    "                y_onehot_test, y_proba, i, class_id, plot[1], tprs, aucs, mean_fpr\n",
    "            )\n",
    "        # inicializa a curva roc micro average neste fold\n",
    "        inicializa_roc_micro_average_kfold(\n",
    "            y_onehot_test, y_proba, i, ax_micro_average, tprs_micro_average, \n",
    "            aucs_micro_average, mean_fpr\n",
    "        )\n",
    "        print(f\"## FINAL FOLD {i} ##\\n\", dic_fold)\n",
    "\n",
    "    endTime = time.time()\n",
    "    # inserindo a média dos folds no dicionário\n",
    "    dic_json = calc_mean_std(dic_json, model_name)\n",
    "    # inserindo o tempo de execução\n",
    "    dic_json.update({\"time\": endTime-startTime})\n",
    "    # salvando o dicionário no formato json\n",
    "    objOpen = open(f'./log_metrics/{model_name}.json', 'w')\n",
    "    objOpen.write(json.dumps(dic_json, indent=4))\n",
    "    objOpen.close()\n",
    "\n",
    "    # gera o plot da curva roc para cada classe, juntando todos os folds e realizando uma media\n",
    "    for class_id, plot, tprs, aucs in zip(range(9), lista_plots, matriz_tprs, matriz_aucs):\n",
    "        gera_roc_one_class_vs_rest_kfold(tprs, aucs, mean_fpr, plot, model_name, class_id)\n",
    "    # gera o plot da curva roc micro average, juntando todos os folds e realizando uma media \n",
    "    gera_roc_micro_average_kfold(\n",
    "        tprs_micro_average, aucs_micro_average, mean_fpr, fig_micro_average, ax_micro_average, \n",
    "        model_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carrega dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>feat_11</th>\n",
       "      <th>feat_12</th>\n",
       "      <th>feat_13</th>\n",
       "      <th>feat_14</th>\n",
       "      <th>feat_15</th>\n",
       "      <th>feat_16</th>\n",
       "      <th>feat_17</th>\n",
       "      <th>feat_18</th>\n",
       "      <th>feat_19</th>\n",
       "      <th>feat_20</th>\n",
       "      <th>feat_21</th>\n",
       "      <th>feat_22</th>\n",
       "      <th>feat_23</th>\n",
       "      <th>feat_24</th>\n",
       "      <th>feat_25</th>\n",
       "      <th>feat_26</th>\n",
       "      <th>feat_27</th>\n",
       "      <th>feat_28</th>\n",
       "      <th>feat_29</th>\n",
       "      <th>feat_30</th>\n",
       "      <th>feat_31</th>\n",
       "      <th>feat_32</th>\n",
       "      <th>feat_33</th>\n",
       "      <th>feat_34</th>\n",
       "      <th>feat_35</th>\n",
       "      <th>feat_36</th>\n",
       "      <th>feat_37</th>\n",
       "      <th>feat_38</th>\n",
       "      <th>feat_39</th>\n",
       "      <th>feat_40</th>\n",
       "      <th>feat_41</th>\n",
       "      <th>feat_42</th>\n",
       "      <th>feat_43</th>\n",
       "      <th>feat_44</th>\n",
       "      <th>feat_45</th>\n",
       "      <th>feat_46</th>\n",
       "      <th>feat_47</th>\n",
       "      <th>feat_48</th>\n",
       "      <th>feat_49</th>\n",
       "      <th>feat_50</th>\n",
       "      <th>feat_51</th>\n",
       "      <th>feat_52</th>\n",
       "      <th>feat_53</th>\n",
       "      <th>feat_54</th>\n",
       "      <th>feat_55</th>\n",
       "      <th>feat_56</th>\n",
       "      <th>feat_57</th>\n",
       "      <th>feat_58</th>\n",
       "      <th>feat_59</th>\n",
       "      <th>feat_60</th>\n",
       "      <th>feat_61</th>\n",
       "      <th>feat_62</th>\n",
       "      <th>feat_63</th>\n",
       "      <th>feat_64</th>\n",
       "      <th>feat_65</th>\n",
       "      <th>feat_66</th>\n",
       "      <th>feat_67</th>\n",
       "      <th>feat_68</th>\n",
       "      <th>feat_69</th>\n",
       "      <th>feat_70</th>\n",
       "      <th>feat_71</th>\n",
       "      <th>feat_72</th>\n",
       "      <th>feat_73</th>\n",
       "      <th>feat_74</th>\n",
       "      <th>feat_75</th>\n",
       "      <th>feat_76</th>\n",
       "      <th>feat_77</th>\n",
       "      <th>feat_78</th>\n",
       "      <th>feat_79</th>\n",
       "      <th>feat_80</th>\n",
       "      <th>feat_81</th>\n",
       "      <th>feat_82</th>\n",
       "      <th>feat_83</th>\n",
       "      <th>feat_84</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'Class_1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'Class_1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'Class_1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'Class_1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'Class_1'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  \\\n",
       "0  1.0     1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1  2.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0   \n",
       "2  3.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0   \n",
       "3  4.0     1.0     0.0     0.0     1.0     6.0     1.0     5.0     0.0   \n",
       "4  5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   feat_9  feat_10  feat_11  feat_12  feat_13  feat_14  feat_15  feat_16  \\\n",
       "0     0.0      0.0      1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1     0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2     0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3     0.0      1.0      1.0      0.0      1.0      0.0      0.0      1.0   \n",
       "4     0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   feat_17  feat_18  feat_19  feat_20  feat_21  feat_22  feat_23  feat_24  \\\n",
       "0      2.0      0.0      0.0      0.0      0.0      1.0      0.0      4.0   \n",
       "1      0.0      2.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      1.0      0.0      0.0      0.0      0.0      0.0      0.0      7.0   \n",
       "4      4.0      0.0      0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "\n",
       "   feat_25  feat_26  feat_27  feat_28  feat_29  feat_30  feat_31  feat_32  \\\n",
       "0      1.0      1.0      0.0      0.0      2.0      0.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      2.0      2.0      0.0      0.0      0.0     58.0      0.0     10.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   feat_33  feat_34  feat_35  feat_36  feat_37  feat_38  feat_39  feat_40  \\\n",
       "0      0.0      0.0      1.0      0.0      0.0      0.0      0.0      1.0   \n",
       "1      0.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "2      1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      3.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   feat_41  feat_42  feat_43  feat_44  feat_45  feat_46  feat_47  feat_48  \\\n",
       "0      0.0      5.0      0.0      0.0      0.0      0.0      0.0      2.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "3      0.0      0.0      0.0      2.0      0.0      2.0      0.0      1.0   \n",
       "4      1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   feat_49  feat_50  feat_51  feat_52  feat_53  feat_54  feat_55  feat_56  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      1.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "3      2.0      1.0      3.0      0.0      0.0      3.0      1.0      0.0   \n",
       "4      0.0      2.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   feat_57  feat_58  feat_59  feat_60  feat_61  feat_62  feat_63  feat_64  \\\n",
       "0      2.0      0.0      0.0     11.0      0.0      1.0      1.0      0.0   \n",
       "1      0.0      1.0      0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      1.0      0.0      0.0   \n",
       "\n",
       "   feat_65  feat_66  feat_67  feat_68  feat_69  feat_70  feat_71  feat_72  \\\n",
       "0      1.0      0.0      7.0      0.0      0.0      0.0      1.0      0.0   \n",
       "1      0.0      0.0      1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      6.0      0.0      0.0      2.0      0.0      0.0   \n",
       "3      2.0      1.0      5.0      0.0      0.0      4.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0      1.0      0.0      0.0      3.0      0.0   \n",
       "\n",
       "   feat_73  feat_74  feat_75  feat_76  feat_77  feat_78  feat_79  feat_80  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0      2.0      1.0   \n",
       "1      2.0      1.0      0.0      1.0      0.0      1.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      2.0      1.0      0.0      1.0      0.0      0.0      1.0      1.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0      4.0      0.0   \n",
       "\n",
       "   feat_81  feat_82  feat_83  feat_84  feat_85  feat_86  feat_87  feat_88  \\\n",
       "0      0.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      2.0      2.0      0.0     22.0      0.0      1.0      2.0      0.0   \n",
       "4      1.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "\n",
       "   feat_89  feat_90  feat_91  feat_92  feat_93      target  \n",
       "0      0.0      0.0      0.0      0.0      0.0  b'Class_1'  \n",
       "1      0.0      0.0      0.0      0.0      0.0  b'Class_1'  \n",
       "2      0.0      0.0      0.0      0.0      0.0  b'Class_1'  \n",
       "3      0.0      0.0      0.0      0.0      0.0  b'Class_1'  \n",
       "4      0.0      1.0      0.0      0.0      0.0  b'Class_1'  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = loadarff('data/dataset.arff')\n",
    "df_data = pd.DataFrame(raw_data[0])\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decodifica string de target\n",
    "df_data[\"target\"] = df_data[\"target\"].str.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>feat_11</th>\n",
       "      <th>feat_12</th>\n",
       "      <th>feat_13</th>\n",
       "      <th>feat_14</th>\n",
       "      <th>feat_15</th>\n",
       "      <th>feat_16</th>\n",
       "      <th>feat_17</th>\n",
       "      <th>feat_18</th>\n",
       "      <th>feat_19</th>\n",
       "      <th>feat_20</th>\n",
       "      <th>feat_21</th>\n",
       "      <th>feat_22</th>\n",
       "      <th>feat_23</th>\n",
       "      <th>feat_24</th>\n",
       "      <th>feat_25</th>\n",
       "      <th>feat_26</th>\n",
       "      <th>feat_27</th>\n",
       "      <th>feat_28</th>\n",
       "      <th>feat_29</th>\n",
       "      <th>feat_30</th>\n",
       "      <th>feat_31</th>\n",
       "      <th>feat_32</th>\n",
       "      <th>feat_33</th>\n",
       "      <th>feat_34</th>\n",
       "      <th>feat_35</th>\n",
       "      <th>feat_36</th>\n",
       "      <th>feat_37</th>\n",
       "      <th>feat_38</th>\n",
       "      <th>feat_39</th>\n",
       "      <th>feat_40</th>\n",
       "      <th>feat_41</th>\n",
       "      <th>feat_42</th>\n",
       "      <th>feat_43</th>\n",
       "      <th>feat_44</th>\n",
       "      <th>feat_45</th>\n",
       "      <th>feat_46</th>\n",
       "      <th>feat_47</th>\n",
       "      <th>feat_48</th>\n",
       "      <th>feat_49</th>\n",
       "      <th>feat_50</th>\n",
       "      <th>feat_51</th>\n",
       "      <th>feat_52</th>\n",
       "      <th>feat_53</th>\n",
       "      <th>feat_54</th>\n",
       "      <th>feat_55</th>\n",
       "      <th>feat_56</th>\n",
       "      <th>feat_57</th>\n",
       "      <th>feat_58</th>\n",
       "      <th>feat_59</th>\n",
       "      <th>feat_60</th>\n",
       "      <th>feat_61</th>\n",
       "      <th>feat_62</th>\n",
       "      <th>feat_63</th>\n",
       "      <th>feat_64</th>\n",
       "      <th>feat_65</th>\n",
       "      <th>feat_66</th>\n",
       "      <th>feat_67</th>\n",
       "      <th>feat_68</th>\n",
       "      <th>feat_69</th>\n",
       "      <th>feat_70</th>\n",
       "      <th>feat_71</th>\n",
       "      <th>feat_72</th>\n",
       "      <th>feat_73</th>\n",
       "      <th>feat_74</th>\n",
       "      <th>feat_75</th>\n",
       "      <th>feat_76</th>\n",
       "      <th>feat_77</th>\n",
       "      <th>feat_78</th>\n",
       "      <th>feat_79</th>\n",
       "      <th>feat_80</th>\n",
       "      <th>feat_81</th>\n",
       "      <th>feat_82</th>\n",
       "      <th>feat_83</th>\n",
       "      <th>feat_84</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33971</th>\n",
       "      <td>33972.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Class_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27692</th>\n",
       "      <td>27693.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Class_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53548</th>\n",
       "      <td>53549.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Class_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51423</th>\n",
       "      <td>51424.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Class_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30912</th>\n",
       "      <td>30913.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Class_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  \\\n",
       "33971  33972.0     0.0     0.0    10.0     6.0     0.0     0.0     0.0   \n",
       "27692  27693.0     0.0     0.0     0.0     0.0     1.0     0.0     0.0   \n",
       "53548  53549.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "51423  51424.0     0.0     0.0     0.0     1.0     0.0     0.0     2.0   \n",
       "30912  30913.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       feat_8  feat_9  feat_10  feat_11  feat_12  feat_13  feat_14  feat_15  \\\n",
       "33971     0.0     0.0      0.0     15.0      0.0      1.0      0.0      0.0   \n",
       "27692     0.0     0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "53548     2.0     0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "51423     0.0     1.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "30912     0.0     0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       feat_16  feat_17  feat_18  feat_19  feat_20  feat_21  feat_22  feat_23  \\\n",
       "33971      3.0      0.0      0.0      1.0      0.0      1.0      0.0      0.0   \n",
       "27692      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "53548      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "51423      1.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "30912      0.0      0.0      1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       feat_24  feat_25  feat_26  feat_27  feat_28  feat_29  feat_30  feat_31  \\\n",
       "33971      0.0      0.0      2.0      1.0      1.0      0.0      0.0      0.0   \n",
       "27692      1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "53548      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "51423      1.0      1.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "30912      6.0      1.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       feat_32  feat_33  feat_34  feat_35  feat_36  feat_37  feat_38  feat_39  \\\n",
       "33971      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "27692      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "53548      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "51423      1.0      0.0      1.0      0.0      1.0      0.0      1.0      0.0   \n",
       "30912      0.0      1.0     14.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       feat_40  feat_41  feat_42  feat_43  feat_44  feat_45  feat_46  feat_47  \\\n",
       "33971      0.0      1.0      0.0      1.0      0.0      0.0     10.0      0.0   \n",
       "27692      2.0      0.0      1.0      4.0      1.0      0.0      0.0      0.0   \n",
       "53548      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "51423      1.0      1.0      1.0      0.0      0.0      0.0      0.0      8.0   \n",
       "30912      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       feat_48  feat_49  feat_50  feat_51  feat_52  feat_53  feat_54  feat_55  \\\n",
       "33971      1.0      0.0      0.0      0.0      1.0      0.0     19.0      2.0   \n",
       "27692      2.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "53548      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "51423      1.0      0.0      1.0      0.0      0.0      1.0      3.0      0.0   \n",
       "30912      2.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       feat_56  feat_57  feat_58  feat_59  feat_60  feat_61  feat_62  feat_63  \\\n",
       "33971      0.0      0.0      0.0      0.0      0.0      6.0      2.0      0.0   \n",
       "27692      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "53548      0.0      0.0      1.0      0.0      1.0      0.0      0.0      0.0   \n",
       "51423      0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "30912      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       feat_64  feat_65  feat_66  feat_67  feat_68  feat_69  feat_70  feat_71  \\\n",
       "33971      0.0      0.0      1.0      0.0      0.0      1.0      1.0      0.0   \n",
       "27692      2.0      1.0      0.0      0.0      0.0      0.0      4.0      0.0   \n",
       "53548      0.0      0.0      0.0      0.0      0.0      1.0      0.0      0.0   \n",
       "51423      0.0      1.0      0.0      2.0      0.0      0.0      2.0      5.0   \n",
       "30912      0.0      0.0      0.0      2.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       feat_72  feat_73  feat_74  feat_75  feat_76  feat_77  feat_78  feat_79  \\\n",
       "33971      0.0      0.0      1.0      0.0      0.0      0.0      0.0      1.0   \n",
       "27692      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "53548      0.0      1.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "51423      0.0      2.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "30912      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       feat_80  feat_81  feat_82  feat_83  feat_84  feat_85  feat_86  feat_87  \\\n",
       "33971      6.0      0.0      3.0      0.0      0.0      0.0      0.0      0.0   \n",
       "27692      0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "53548      0.0      0.0      0.0      8.0      0.0      0.0      1.0      0.0   \n",
       "51423      0.0      0.0      0.0      0.0      0.0      0.0      2.0      1.0   \n",
       "30912      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       feat_88  feat_89  feat_90  feat_91  feat_92  feat_93   target  \n",
       "33971      0.0      0.0      0.0      1.0      4.0      0.0  Class_6  \n",
       "27692      8.0      0.0      0.0      0.0      0.0      0.0  Class_4  \n",
       "53548      0.0      0.0      0.0      0.0      0.0      0.0  Class_8  \n",
       "51423      0.0      0.0      0.0      0.0      1.0      0.0  Class_8  \n",
       "30912      0.0      0.0      0.0      0.0      0.0      0.0  Class_5  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dataset: (61878, 95)\n"
     ]
    }
   ],
   "source": [
    "# verificando o número de linhas e colunas do dataset\n",
    "print(\"Shape dataset:\", df_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor mínimo das features: 0.0\n"
     ]
    }
   ],
   "source": [
    "# verificando o menor valor das colunas de características\n",
    "print(\"Valor mínimo das features:\", df_data.iloc[:,1:-1].min().min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor máximo das features: 352.0\n"
     ]
    }
   ],
   "source": [
    "# verificando o maior valor das colunas de características\n",
    "print(\"Valor máximo das features:\", df_data.iloc[:,1:-1].max().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de Instâncias por Classe:\n",
      " target\n",
      "Class_1     1929\n",
      "Class_2    16122\n",
      "Class_3     8004\n",
      "Class_4     2691\n",
      "Class_5     2739\n",
      "Class_6    14135\n",
      "Class_7     2839\n",
      "Class_8     8464\n",
      "Class_9     4955\n",
      "Name: id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# verificando o número de instâncias para cada classe\n",
    "print('Número de Instâncias por Classe:\\n', df_data.groupby('target').count()['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentual de Instâncias por Classe:\n",
      " target\n",
      "Class_1     3.117425\n",
      "Class_2    26.054494\n",
      "Class_3    12.935130\n",
      "Class_4     4.348880\n",
      "Class_5     4.426452\n",
      "Class_6    22.843337\n",
      "Class_7     4.588060\n",
      "Class_8    13.678529\n",
      "Class_9     8.007693\n",
      "Name: id, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# verificando o percentual de instâncias para cada classe\n",
    "print('Percentual de Instâncias por Classe:\\n', (df_data.groupby('target').count()['id']/df_data.shape[0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Número de Valores NaN: 0\n"
     ]
    }
   ],
   "source": [
    "# verificando se existem valores NaN\n",
    "print('\\nNúmero de Valores NaN:', df_data.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>feat_11</th>\n",
       "      <th>feat_12</th>\n",
       "      <th>feat_13</th>\n",
       "      <th>feat_14</th>\n",
       "      <th>feat_15</th>\n",
       "      <th>feat_16</th>\n",
       "      <th>feat_17</th>\n",
       "      <th>feat_18</th>\n",
       "      <th>feat_19</th>\n",
       "      <th>feat_20</th>\n",
       "      <th>feat_21</th>\n",
       "      <th>feat_22</th>\n",
       "      <th>feat_23</th>\n",
       "      <th>feat_24</th>\n",
       "      <th>feat_25</th>\n",
       "      <th>feat_26</th>\n",
       "      <th>feat_27</th>\n",
       "      <th>feat_28</th>\n",
       "      <th>feat_29</th>\n",
       "      <th>feat_30</th>\n",
       "      <th>feat_31</th>\n",
       "      <th>feat_32</th>\n",
       "      <th>feat_33</th>\n",
       "      <th>feat_34</th>\n",
       "      <th>feat_35</th>\n",
       "      <th>feat_36</th>\n",
       "      <th>feat_37</th>\n",
       "      <th>feat_38</th>\n",
       "      <th>feat_39</th>\n",
       "      <th>feat_40</th>\n",
       "      <th>feat_41</th>\n",
       "      <th>feat_42</th>\n",
       "      <th>feat_43</th>\n",
       "      <th>feat_44</th>\n",
       "      <th>feat_45</th>\n",
       "      <th>feat_46</th>\n",
       "      <th>feat_47</th>\n",
       "      <th>feat_48</th>\n",
       "      <th>feat_49</th>\n",
       "      <th>feat_50</th>\n",
       "      <th>feat_51</th>\n",
       "      <th>feat_52</th>\n",
       "      <th>feat_53</th>\n",
       "      <th>feat_54</th>\n",
       "      <th>feat_55</th>\n",
       "      <th>feat_56</th>\n",
       "      <th>feat_57</th>\n",
       "      <th>feat_58</th>\n",
       "      <th>feat_59</th>\n",
       "      <th>feat_60</th>\n",
       "      <th>feat_61</th>\n",
       "      <th>feat_62</th>\n",
       "      <th>feat_63</th>\n",
       "      <th>feat_64</th>\n",
       "      <th>feat_65</th>\n",
       "      <th>feat_66</th>\n",
       "      <th>feat_67</th>\n",
       "      <th>feat_68</th>\n",
       "      <th>feat_69</th>\n",
       "      <th>feat_70</th>\n",
       "      <th>feat_71</th>\n",
       "      <th>feat_72</th>\n",
       "      <th>feat_73</th>\n",
       "      <th>feat_74</th>\n",
       "      <th>feat_75</th>\n",
       "      <th>feat_76</th>\n",
       "      <th>feat_77</th>\n",
       "      <th>feat_78</th>\n",
       "      <th>feat_79</th>\n",
       "      <th>feat_80</th>\n",
       "      <th>feat_81</th>\n",
       "      <th>feat_82</th>\n",
       "      <th>feat_83</th>\n",
       "      <th>feat_84</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.00000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30939.500000</td>\n",
       "      <td>0.38668</td>\n",
       "      <td>0.263066</td>\n",
       "      <td>0.901467</td>\n",
       "      <td>0.779081</td>\n",
       "      <td>0.071043</td>\n",
       "      <td>0.025696</td>\n",
       "      <td>0.193704</td>\n",
       "      <td>0.662433</td>\n",
       "      <td>1.011296</td>\n",
       "      <td>0.263906</td>\n",
       "      <td>1.252869</td>\n",
       "      <td>0.140874</td>\n",
       "      <td>0.480979</td>\n",
       "      <td>1.696693</td>\n",
       "      <td>1.284398</td>\n",
       "      <td>1.413459</td>\n",
       "      <td>0.366108</td>\n",
       "      <td>0.575423</td>\n",
       "      <td>0.551699</td>\n",
       "      <td>0.471525</td>\n",
       "      <td>0.204014</td>\n",
       "      <td>0.729969</td>\n",
       "      <td>0.142522</td>\n",
       "      <td>2.643880</td>\n",
       "      <td>1.534520</td>\n",
       "      <td>0.563108</td>\n",
       "      <td>0.696613</td>\n",
       "      <td>0.238970</td>\n",
       "      <td>0.275768</td>\n",
       "      <td>0.150312</td>\n",
       "      <td>0.148680</td>\n",
       "      <td>1.043796</td>\n",
       "      <td>0.696516</td>\n",
       "      <td>0.946411</td>\n",
       "      <td>0.666263</td>\n",
       "      <td>0.709089</td>\n",
       "      <td>0.263632</td>\n",
       "      <td>0.582129</td>\n",
       "      <td>0.485585</td>\n",
       "      <td>1.653059</td>\n",
       "      <td>0.303468</td>\n",
       "      <td>0.698019</td>\n",
       "      <td>0.451146</td>\n",
       "      <td>0.560829</td>\n",
       "      <td>0.238130</td>\n",
       "      <td>0.641375</td>\n",
       "      <td>0.249669</td>\n",
       "      <td>1.584893</td>\n",
       "      <td>0.348314</td>\n",
       "      <td>0.324283</td>\n",
       "      <td>0.053298</td>\n",
       "      <td>0.213485</td>\n",
       "      <td>0.442063</td>\n",
       "      <td>2.072465</td>\n",
       "      <td>0.323120</td>\n",
       "      <td>0.303775</td>\n",
       "      <td>0.309108</td>\n",
       "      <td>0.697970</td>\n",
       "      <td>0.388603</td>\n",
       "      <td>1.029930</td>\n",
       "      <td>0.239746</td>\n",
       "      <td>1.187563</td>\n",
       "      <td>0.168590</td>\n",
       "      <td>1.256796</td>\n",
       "      <td>0.222228</td>\n",
       "      <td>0.571706</td>\n",
       "      <td>2.897653</td>\n",
       "      <td>0.392902</td>\n",
       "      <td>0.811128</td>\n",
       "      <td>0.892789</td>\n",
       "      <td>0.319290</td>\n",
       "      <td>0.858722</td>\n",
       "      <td>0.591050</td>\n",
       "      <td>0.579851</td>\n",
       "      <td>0.726817</td>\n",
       "      <td>0.748457</td>\n",
       "      <td>0.124196</td>\n",
       "      <td>0.366415</td>\n",
       "      <td>0.300446</td>\n",
       "      <td>0.698067</td>\n",
       "      <td>0.078461</td>\n",
       "      <td>0.187983</td>\n",
       "      <td>0.496719</td>\n",
       "      <td>0.070752</td>\n",
       "      <td>0.532306</td>\n",
       "      <td>1.128576</td>\n",
       "      <td>0.393549</td>\n",
       "      <td>0.874915</td>\n",
       "      <td>0.457772</td>\n",
       "      <td>0.812421</td>\n",
       "      <td>0.264941</td>\n",
       "      <td>0.380119</td>\n",
       "      <td>0.126135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17862.784315</td>\n",
       "      <td>1.52533</td>\n",
       "      <td>1.252073</td>\n",
       "      <td>2.934818</td>\n",
       "      <td>2.788005</td>\n",
       "      <td>0.438902</td>\n",
       "      <td>0.215333</td>\n",
       "      <td>1.030102</td>\n",
       "      <td>2.255770</td>\n",
       "      <td>3.474822</td>\n",
       "      <td>1.083340</td>\n",
       "      <td>3.042333</td>\n",
       "      <td>0.567089</td>\n",
       "      <td>2.014697</td>\n",
       "      <td>3.163212</td>\n",
       "      <td>3.862236</td>\n",
       "      <td>2.226163</td>\n",
       "      <td>1.477436</td>\n",
       "      <td>1.335985</td>\n",
       "      <td>4.636145</td>\n",
       "      <td>1.438727</td>\n",
       "      <td>0.696050</td>\n",
       "      <td>1.446220</td>\n",
       "      <td>0.782979</td>\n",
       "      <td>4.629015</td>\n",
       "      <td>2.332994</td>\n",
       "      <td>1.710305</td>\n",
       "      <td>2.873222</td>\n",
       "      <td>0.828112</td>\n",
       "      <td>1.901294</td>\n",
       "      <td>1.640880</td>\n",
       "      <td>0.897354</td>\n",
       "      <td>2.416849</td>\n",
       "      <td>1.310202</td>\n",
       "      <td>3.368622</td>\n",
       "      <td>3.197965</td>\n",
       "      <td>2.555119</td>\n",
       "      <td>0.756934</td>\n",
       "      <td>1.602579</td>\n",
       "      <td>3.298315</td>\n",
       "      <td>3.299798</td>\n",
       "      <td>1.085672</td>\n",
       "      <td>1.961189</td>\n",
       "      <td>1.706013</td>\n",
       "      <td>1.346090</td>\n",
       "      <td>2.587131</td>\n",
       "      <td>2.348359</td>\n",
       "      <td>1.446203</td>\n",
       "      <td>2.577071</td>\n",
       "      <td>1.369380</td>\n",
       "      <td>1.720470</td>\n",
       "      <td>0.513820</td>\n",
       "      <td>1.044788</td>\n",
       "      <td>2.006485</td>\n",
       "      <td>4.113319</td>\n",
       "      <td>0.998743</td>\n",
       "      <td>1.925806</td>\n",
       "      <td>1.082148</td>\n",
       "      <td>3.983722</td>\n",
       "      <td>2.577693</td>\n",
       "      <td>3.028469</td>\n",
       "      <td>1.017553</td>\n",
       "      <td>2.666742</td>\n",
       "      <td>0.946158</td>\n",
       "      <td>3.402080</td>\n",
       "      <td>0.783052</td>\n",
       "      <td>1.361874</td>\n",
       "      <td>4.974322</td>\n",
       "      <td>1.761054</td>\n",
       "      <td>4.111091</td>\n",
       "      <td>1.941368</td>\n",
       "      <td>1.162443</td>\n",
       "      <td>2.411646</td>\n",
       "      <td>5.783233</td>\n",
       "      <td>3.757822</td>\n",
       "      <td>3.200095</td>\n",
       "      <td>2.920038</td>\n",
       "      <td>0.906621</td>\n",
       "      <td>2.778317</td>\n",
       "      <td>1.285569</td>\n",
       "      <td>2.245671</td>\n",
       "      <td>0.461244</td>\n",
       "      <td>0.836269</td>\n",
       "      <td>2.434921</td>\n",
       "      <td>1.151460</td>\n",
       "      <td>1.900438</td>\n",
       "      <td>2.681554</td>\n",
       "      <td>1.575455</td>\n",
       "      <td>2.115466</td>\n",
       "      <td>1.527385</td>\n",
       "      <td>4.597804</td>\n",
       "      <td>2.045646</td>\n",
       "      <td>0.982385</td>\n",
       "      <td>1.201720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15470.250000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30939.500000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46408.750000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61.00000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>352.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       feat_1        feat_2        feat_3        feat_4  \\\n",
       "count  61878.000000  61878.00000  61878.000000  61878.000000  61878.000000   \n",
       "mean   30939.500000      0.38668      0.263066      0.901467      0.779081   \n",
       "std    17862.784315      1.52533      1.252073      2.934818      2.788005   \n",
       "min        1.000000      0.00000      0.000000      0.000000      0.000000   \n",
       "25%    15470.250000      0.00000      0.000000      0.000000      0.000000   \n",
       "50%    30939.500000      0.00000      0.000000      0.000000      0.000000   \n",
       "75%    46408.750000      0.00000      0.000000      0.000000      0.000000   \n",
       "max    61878.000000     61.00000     51.000000     64.000000     70.000000   \n",
       "\n",
       "             feat_5        feat_6        feat_7        feat_8        feat_9  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.071043      0.025696      0.193704      0.662433      1.011296   \n",
       "std        0.438902      0.215333      1.030102      2.255770      3.474822   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "max       19.000000     10.000000     38.000000     76.000000     43.000000   \n",
       "\n",
       "            feat_10       feat_11       feat_12       feat_13       feat_14  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.263906      1.252869      0.140874      0.480979      1.696693   \n",
       "std        1.083340      3.042333      0.567089      2.014697      3.163212   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      1.000000      0.000000      0.000000      2.000000   \n",
       "max       30.000000     38.000000     30.000000     72.000000     33.000000   \n",
       "\n",
       "            feat_15       feat_16       feat_17       feat_18       feat_19  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       1.284398      1.413459      0.366108      0.575423      0.551699   \n",
       "std        3.862236      2.226163      1.477436      1.335985      4.636145   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      2.000000      0.000000      1.000000      0.000000   \n",
       "max       46.000000     37.000000     43.000000     32.000000    121.000000   \n",
       "\n",
       "            feat_20       feat_21       feat_22       feat_23       feat_24  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.471525      0.204014      0.729969      0.142522      2.643880   \n",
       "std        1.438727      0.696050      1.446220      0.782979      4.629015   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      1.000000   \n",
       "75%        0.000000      0.000000      1.000000      0.000000      3.000000   \n",
       "max       27.000000     14.000000     22.000000     64.000000    263.000000   \n",
       "\n",
       "            feat_25       feat_26       feat_27       feat_28       feat_29  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       1.534520      0.563108      0.696613      0.238970      0.275768   \n",
       "std        2.332994      1.710305      2.873222      0.828112      1.901294   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        2.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       30.000000     33.000000    123.000000     22.000000     69.000000   \n",
       "\n",
       "            feat_30       feat_31       feat_32       feat_33       feat_34  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.150312      0.148680      1.043796      0.696516      0.946411   \n",
       "std        1.640880      0.897354      2.416849      1.310202      3.368622   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      1.000000      1.000000      1.000000   \n",
       "max       87.000000     59.000000    149.000000     24.000000     84.000000   \n",
       "\n",
       "            feat_35       feat_36       feat_37       feat_38       feat_39  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.666263      0.709089      0.263632      0.582129      0.485585   \n",
       "std        3.197965      2.555119      0.756934      1.602579      3.298315   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      1.000000      0.000000      1.000000      0.000000   \n",
       "max      105.000000     84.000000     22.000000     39.000000     78.000000   \n",
       "\n",
       "            feat_40       feat_41       feat_42       feat_43       feat_44  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       1.653059      0.303468      0.698019      0.451146      0.560829   \n",
       "std        3.299798      1.085672      1.961189      1.706013      1.346090   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        2.000000      0.000000      1.000000      0.000000      1.000000   \n",
       "max       41.000000     36.000000     41.000000     42.000000     34.000000   \n",
       "\n",
       "            feat_45       feat_46       feat_47       feat_48       feat_49  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.238130      0.641375      0.249669      1.584893      0.348314   \n",
       "std        2.587131      2.348359      1.446203      2.577071      1.369380   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      2.000000      0.000000   \n",
       "max       80.000000     41.000000     47.000000     49.000000     81.000000   \n",
       "\n",
       "            feat_50       feat_51       feat_52       feat_53       feat_54  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.324283      0.053298      0.213485      0.442063      2.072465   \n",
       "std        1.720470      0.513820      1.044788      2.006485      4.113319   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      2.000000   \n",
       "max       73.000000     44.000000     48.000000     53.000000     63.000000   \n",
       "\n",
       "            feat_55       feat_56       feat_57       feat_58       feat_59  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.323120      0.303775      0.309108      0.697970      0.388603   \n",
       "std        0.998743      1.925806      1.082148      3.983722      2.577693   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       27.000000     62.000000     30.000000    117.000000     97.000000   \n",
       "\n",
       "            feat_60       feat_61       feat_62       feat_63       feat_64  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       1.029930      0.239746      1.187563      0.168590      1.256796   \n",
       "std        3.028469      1.017553      2.666742      0.946158      3.402080   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      1.000000      0.000000      1.000000   \n",
       "max       40.000000     38.000000     56.000000     51.000000     73.000000   \n",
       "\n",
       "            feat_65       feat_66       feat_67       feat_68       feat_69  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.222228      0.571706      2.897653      0.392902      0.811128   \n",
       "std        0.783052      1.361874      4.974322      1.761054      4.111091   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "75%        0.000000      1.000000      4.000000      0.000000      0.000000   \n",
       "max       38.000000     36.000000    104.000000    109.000000     76.000000   \n",
       "\n",
       "            feat_70       feat_71       feat_72       feat_73       feat_74  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.892789      0.319290      0.858722      0.591050      0.579851   \n",
       "std        1.941368      1.162443      2.411646      5.783233      3.757822   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "max       46.000000     31.000000     30.000000    352.000000    231.000000   \n",
       "\n",
       "            feat_75       feat_76       feat_77       feat_78       feat_79  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.726817      0.748457      0.124196      0.366415      0.300446   \n",
       "std        3.200095      2.920038      0.906621      2.778317      1.285569   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       80.000000    102.000000     29.000000     80.000000     25.000000   \n",
       "\n",
       "            feat_80       feat_81       feat_82       feat_83       feat_84  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.698067      0.078461      0.187983      0.496719      0.070752   \n",
       "std        2.245671      0.461244      0.836269      2.434921      1.151460   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       54.000000     26.000000     24.000000     79.000000     76.000000   \n",
       "\n",
       "            feat_85       feat_86       feat_87       feat_88       feat_89  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.532306      1.128576      0.393549      0.874915      0.457772   \n",
       "std        1.900438      2.681554      1.575455      2.115466      1.527385   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      1.000000      0.000000      1.000000      0.000000   \n",
       "max       55.000000     65.000000     67.000000     30.000000     61.000000   \n",
       "\n",
       "            feat_90       feat_91       feat_92       feat_93  \n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  \n",
       "mean       0.812421      0.264941      0.380119      0.126135  \n",
       "std        4.597804      2.045646      0.982385      1.201720  \n",
       "min        0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.000000      0.000000      0.000000      0.000000  \n",
       "50%        0.000000      0.000000      0.000000      0.000000  \n",
       "75%        0.000000      0.000000      0.000000      0.000000  \n",
       "max      130.000000     52.000000     19.000000     87.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_data.drop(columns=[\"id\", \"target\"])\n",
    "y = df_data[[\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target \n",
       "Class_2    16122\n",
       "Class_6    14135\n",
       "Class_8     8464\n",
       "Class_3     8004\n",
       "Class_9     4955\n",
       "Class_7     2839\n",
       "Class_5     2739\n",
       "Class_4     2691\n",
       "Class_1     1929\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=4)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target \n",
       "Class_1    16122\n",
       "Class_2    16122\n",
       "Class_3    16122\n",
       "Class_4    16122\n",
       "Class_5    16122\n",
       "Class_6    16122\n",
       "Class_7    16122\n",
       "Class_8    16122\n",
       "Class_9    16122\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_smote.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"n_neighbors\": [5, 10, 15]\n",
    "}\n",
    "# define o modelo\n",
    "model = KNeighborsClassifier(n_jobs=1)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"max_depth\": [None, 50, 100, 200, 500, 1000]\n",
    "}\n",
    "# define o modelo\n",
    "model = DecisionTreeClassifier(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"DecisionTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"n_estimators\": [100, 300, 500],\n",
    "    \"max_depth\": [None, 400, 800],\n",
    "    \"class_weight\": [\"balanced_subsample\", None]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = RandomForestClassifier(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"RandomForest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes (Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = GaussianNB()\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"NaiveBayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"penalty\": [None, \"l2\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"max_iter\": [100, 300, 500, 700, 1000]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = LogisticRegression(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"LogisticRegression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"penalty\": [None, \"l2\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"max_iter\": [100, 300, 500, 700, 1000]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = Perceptron(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"Perceptron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"learning_rate_init\": [0.001, 0.01],\n",
    "    \"max_iter\": [200, 500, 700],\n",
    "    \"hidden_layer_sizes\": [20, 50, 100]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = MLPClassifier(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"MLPClassifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"C\": [1],\n",
    "    \"kernel\": [\"rbf\", \"linear\"]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = SVC(random_state=4, probability=True)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste de Hipótese\n",
    "\n",
    "Vamos avaliar se a média dos resultados obtidos com o modelo Random Forest é maior que a média dos resultados obtidos com o modelo MLP. Iremos realizar um teste de hipótese para checar se, estatisticamente, podemos constatar essa afirmação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"log_metrics/RandomForest.json\") as json_file:\n",
    "    json_rf = json.load(json_file)\n",
    "\n",
    "lista_resultados_rf = []\n",
    "for key in list(json_rf.keys()):\n",
    "    if (key != \"mean\") & (key != \"std\") & (key != \"time\"):\n",
    "        lista_resultados_rf.append(json_rf[key][\"metrics\"][\"f1_weighted\"])\n",
    "\n",
    "with open(\"log_metrics/MLPClassifier.json\") as json_file:\n",
    "    json_mlp = json.load(json_file)\n",
    "\n",
    "lista_resultados_mlp = []\n",
    "for key in list(json_mlp.keys()):\n",
    "    if (key != \"mean\") & (key != \"std\") & (key != \"time\"):\n",
    "        lista_resultados_mlp.append(json_mlp[key][\"metrics\"][\"f1_weighted\"])\n",
    "\n",
    "df_resultados = pd.DataFrame({\"rf\": lista_resultados_rf, \"mlp\": lista_resultados_mlp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "sns.set(rc={'figure.figsize':(10,5)})\n",
    "\n",
    "sns.histplot(df_resultados, x=\"rf\", ax=ax[0]).set_title(\"Distribuicao Random Forest\")\n",
    "sns.histplot(df_resultados, x=\"mlp\", ax=ax[1]).set_title(\"Distribuicao MLP\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Teste normalidade random forest: {stats.shapiro(df_resultados['rf'])}\\n\"\n",
    "    f\"Teste normalidade mlp: {stats.shapiro(df_resultados['mlp'])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.mannwhitneyu(df_resultados[\"rf\"], df_resultados[\"mlp\"], alternative=\"greater\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Variancia random forest: {np.var(df_resultados['rf'])}\\n\"\n",
    "    f\"Variancia mlp: {np.var(df_resultados['mlp'])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(a=df_resultados[\"rf\"], b=df_resultados[\"mlp\"], equal_var=True, alternative=\"greater\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
