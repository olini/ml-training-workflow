{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.io.arff import loadarff\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para criar os diretórios\n",
    "def creat_dir(model_name):\n",
    "    if not 'log_metrics' in os.listdir():\n",
    "        os.mkdir('log_metrics')\n",
    "    if not 'imgs' in os.listdir():\n",
    "        os.mkdir('imgs')\n",
    "    if not model_name in os.listdir('./imgs'):\n",
    "        os.mkdir('./imgs/'+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para adicionar as métricas de um fold em um dicionário\n",
    "def dic_par_metrics(y_test, y_onehot_test, y_pred, y_proba, grid_search_cv):\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    balanced_accuracy = metrics.balanced_accuracy_score(y_test, y_pred)\n",
    "    precision_micro = metrics.precision_score(y_test, y_pred, average='micro')\n",
    "    precision_macro = metrics.precision_score(y_test, y_pred, average='macro')\n",
    "    precision_weighted = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "    recall_micro = metrics.recall_score(y_test, y_pred, average='micro')\n",
    "    recall_macro = metrics.recall_score(y_test, y_pred, average='macro')\n",
    "    recall_weighted = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "    f1_micro = metrics.f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "    f1_weighted = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "    roc_auc_ovr_micro = metrics.roc_auc_score(y_onehot_test, y_proba, multi_class='ovr', average='micro')\n",
    "    roc_auc_ovo_micro = metrics.roc_auc_score(y_onehot_test, y_proba, multi_class='ovo', average='micro')\n",
    "    roc_auc_ovr_macro = metrics.roc_auc_score(y_onehot_test, y_proba, multi_class='ovr', average='macro')\n",
    "    roc_auc_ovo_macro = metrics.roc_auc_score(y_onehot_test, y_proba, multi_class='ovo', average='macro')\n",
    "    roc_auc_ovr_weighted = metrics.roc_auc_score(y_onehot_test, y_proba, multi_class='ovr', average='weighted')\n",
    "    roc_auc_ovo_weighted = metrics.roc_auc_score(y_onehot_test, y_proba, multi_class='ovo', average='weighted')\n",
    "    classification_report = metrics.classification_report(y_test, y_pred, output_dict=True)\n",
    "    dicMetricas = {\n",
    "        \"parameters\": grid_search_cv.best_params_,\n",
    "        \"metrics\":{\n",
    "            \"accuracy\": accuracy,\n",
    "            \"balanced_accuracy\": balanced_accuracy,\n",
    "            \"precision_micro\": precision_micro,\n",
    "            \"precision_macro\": precision_macro,\n",
    "            \"precision_weighted\": precision_weighted,\n",
    "            \"recall_micro\": recall_micro,\n",
    "            \"recall_macro\": recall_macro,\n",
    "            \"recall_weighted\": recall_weighted,\n",
    "            \"f1_micro\": f1_micro,\n",
    "            \"f1_macro\": f1_macro,\n",
    "            \"f1_weighted\": f1_weighted,\n",
    "            \"roc_auc_ovr_micro\": roc_auc_ovr_micro,\n",
    "            \"roc_auc_ovo_micro\": roc_auc_ovo_micro,\n",
    "            \"roc_auc_ovr_macro\": roc_auc_ovr_macro,\n",
    "            \"roc_auc_ovo_macro\": roc_auc_ovo_macro,\n",
    "            \"roc_auc_ovr_weighted\": roc_auc_ovr_weighted,\n",
    "            \"roc_auc_ovo_weighted\": roc_auc_ovo_weighted\n",
    "        },\n",
    "        \"classification_report\": classification_report\n",
    "    }\n",
    "    return dicMetricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para calcular a média e o desvio padrão das métricas de cada fold, além de plotar os boxplots\n",
    "def calc_mean_std(dic_json, model_name):\n",
    "    key = list(dic_json.keys())[0]\n",
    "    dic_mean = {}\n",
    "    dic_std = {}\n",
    "    for j in dic_json[key]['metrics'].keys():\n",
    "        metrics_list = []\n",
    "        for i in dic_json.keys():\n",
    "            metrics_list.append(dic_json[i]['metrics'][j])\n",
    "        mean = np.mean(metrics_list)\n",
    "        std = np.std(metrics_list)\n",
    "        dic_mean.update({j: mean})\n",
    "        dic_std.update({j: std})\n",
    "        plt.close('all')\n",
    "        plt.boxplot(metrics_list, labels=[model_name])\n",
    "        plt.ylabel(j)\n",
    "        plt.savefig('./imgs/'+model_name+'/boxplot_'+j+'.png')\n",
    "        plt.close('all')\n",
    "    dic_json.update({\"mean\": dic_mean})\n",
    "    dic_json.update({\"std\": dic_std})\n",
    "    return dic_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matriz_confusao_one_vs_one(y_test, y_pred, model_name, fold_i, flag_normalizado=\"true\"):\n",
    "    \"\"\"Plota a matriz de confusao comparando cada classe entre si, mostrando as predicoes contra as\n",
    "    classes verdadeiras.\n",
    "\n",
    "    Args:\n",
    "        y_test: serie com os valores verdadeiros\n",
    "        y_pred: serie com os valores preditos\n",
    "        flag_normalizado (optional): flag indicando se os valores da matriz de confusao devem ser\n",
    "        normalizados. Se devem ser normalizados pel. Defaults to None.\n",
    "    \"\"\"\n",
    "    class_names = np.unique(y_pred)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    cm_plot = metrics.ConfusionMatrixDisplay.from_predictions(\n",
    "        y_test, y_pred, cmap=\"YlOrRd\", normalize=flag_normalizado, ax=ax)\n",
    "    ax.set_xticklabels(class_names, rotation=45, ha=\"right\")\n",
    "    ax.set_title(f\"Matriz de Confusao - Modelo {model_name} - Fold {fold_i}\")\n",
    "\n",
    "    cm_plot.figure_.savefig(\n",
    "        f\"imgs/{model_name}/cm_normalizado_{flag_normalizado}_{model_name}_fold_{fold_i}.png\", \n",
    "        dpi=300\n",
    "    )\n",
    "    plt.close()\n",
    "    \n",
    "    return cm_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicializa_roc_one_class_vs_rest_kfold(y_onehot_test, y_pred_score, i, class_id, ax, tprs, aucs, mean_fpr):\n",
    "    viz = metrics.RocCurveDisplay.from_predictions(\n",
    "        y_onehot_test[:, class_id],\n",
    "        y_pred_score[:, class_id],\n",
    "        name=f\"ROC OvR Class_{class_id+1} fold {i}\",\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "        plot_chance_level=(i==9),\n",
    "    )\n",
    "\n",
    "    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_roc_one_class_vs_rest_kfold(tprs, aucs, mean_fpr, plot, model_name, class_id):\n",
    "    fig = plot[0]\n",
    "    ax = plot[1]\n",
    "    \n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = metrics.auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    ax.plot(\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        color=\"b\",\n",
    "        label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(\n",
    "        mean_fpr,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        label=r\"$\\pm$ 1 std. dev.\",\n",
    "    )\n",
    "    ax.set(\n",
    "        xlim=[-0.05, 1.05],\n",
    "        ylim=[-0.05, 1.05],\n",
    "        xlabel=\"False Positive Rate\",\n",
    "        ylabel=\"True Positive Rate\",\n",
    "        title=f\"Curva ROC media com desvio padrao\\nROC OvR Class_{class_id+1}\",\n",
    "    )\n",
    "    ax.axis(\"square\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    fig.savefig(f\"imgs/{model_name}/roc_{model_name}_class_{class_id+1}.png\", dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicializa_roc_micro_average_kfold(y_onehot_test, y_pred_score, i, ax, tprs, aucs, mean_fpr):\n",
    "    viz = metrics.RocCurveDisplay.from_predictions(\n",
    "        y_onehot_test.ravel(),\n",
    "        y_pred_score.ravel(),\n",
    "        name=f\"micro-average OvR fold {i}\",\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "        plot_chance_level=(i==9)\n",
    "    )\n",
    "\n",
    "    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_roc_micro_average_kfold(tprs, aucs, mean_fpr, fig, ax, model_name):\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = metrics.auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    ax.plot(\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        color=\"b\",\n",
    "        label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(\n",
    "        mean_fpr,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        label=r\"$\\pm$ 1 std. dev.\",\n",
    "    )\n",
    "    ax.set(\n",
    "        xlim=[-0.05, 1.05],\n",
    "        ylim=[-0.05, 1.05],\n",
    "        xlabel=\"False Positive Rate\",\n",
    "        ylabel=\"True Positive Rate\",\n",
    "        title=f\"Curva ROC media com desvio padrao\\nROC micro-average\",\n",
    "    )\n",
    "    ax.axis(\"square\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    fig.savefig(f\"imgs/{model_name}/roc_micro_average_{model_name}.png\", dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_k_fold_grid_search_cv(\n",
    "        model, params:dict, X, y, model_name, flag_smote=False, flag_variance_threshold=False\n",
    "):\n",
    "    \"\"\"Realiza o treino e validacao do modelo utilizando StratifiedKFold com GridSearchCV para\n",
    "    busca dos melhores hiperparametros (tendo assim um nested cross-validation).\n",
    "\n",
    "    Args:\n",
    "        model: modelo que se deseja treinar e validar\n",
    "        params (dict): dicionario com os parametros e seus respectivos valores possiveis para o \n",
    "        grid search\n",
    "        X: features do modelo\n",
    "        y: coluna de target do modelo\n",
    "    \"\"\"\n",
    "    startTime = time.time()\n",
    "    # criando os diretórios necessários para salvar as métricas e os plots\n",
    "    creat_dir(model_name)\n",
    "\n",
    "    print(f\"Modelo: {model_name}\")\n",
    "    dic_json = {}\n",
    "\n",
    "    n_splits_k_fold = 10\n",
    "    n_splits_grid_search = 5\n",
    "\n",
    "    matriz_tprs = [[] for i in range(9)]\n",
    "    matriz_aucs = [[] for i in range(9)]\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    lista_plots = [plt.subplots(figsize=(6, 6)) for i in range(9)]\n",
    "\n",
    "    tprs_micro_average = []\n",
    "    aucs_micro_average = []\n",
    "    fig_micro_average, ax_micro_average = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits_k_fold, random_state=4, shuffle=True)\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        print(f\"## INICIO FOLD {i} ##\")\n",
    "        # separa os dados de treino e teste\n",
    "        X_train = X.iloc[train_index]\n",
    "        X_test = X.iloc[test_index]\n",
    "        y_train = y.iloc[train_index]\n",
    "        y_test = y.iloc[test_index]\n",
    "        # realiza a tecnica SMOTE no dados de treino para tratamento do desbalanceamento\n",
    "        if flag_smote:\n",
    "            smote = SMOTE(random_state=4)\n",
    "            X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "        # realiza a tecnica de selecao de atributos utilizando Variance Threshold\n",
    "        if flag_variance_threshold:\n",
    "            filter_variance = VarianceThreshold(0.8)\n",
    "            X_train = filter_variance.fit_transform(X_train)\n",
    "            X_test = filter_variance.transform(X_test)\n",
    "        # normaliza os dados\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        # binariza a coluna target para uso no plot roc e metrica roc_auc_score\n",
    "        label_binarizer = LabelBinarizer().fit(y_train)\n",
    "        y_onehot_test = label_binarizer.transform(y_test)\n",
    "        # prepara o y_train\n",
    "        y_train = y_train.values.ravel()\n",
    "        # inicializa e roda o grid search\n",
    "        grid_search_cv = GridSearchCV(\n",
    "            estimator=model, param_grid=params, scoring=\"f1_weighted\", cv=n_splits_grid_search, \n",
    "            verbose=3)\n",
    "        grid_search_cv.fit(X_train, y_train)\n",
    "        # com os melhores parametros encontrados, realiza a predicao no fold de teste e calcula a \n",
    "        # metrica de avaliacao\n",
    "        y_pred = grid_search_cv.predict(X_test)\n",
    "        # verifica se o modelo em execucao eh o perceptron, ja que o mesmo nao possui a funcao \n",
    "        # predict_proba\n",
    "        if model_name != 'Perceptron':\n",
    "            y_proba = grid_search_cv.predict_proba(X_test)\n",
    "        else:\n",
    "            y_proba = grid_search_cv.decision_function(X_test)\n",
    "        # armazenando as metricas e os parametros em um dicionario\n",
    "        dic_fold = dic_par_metrics(y_test, y_onehot_test, y_pred, y_proba, grid_search_cv)\n",
    "        dic_json.update({\"fold \"+str(i): dic_fold})\n",
    "        # gera a matriz de confusao com dados normalizados e nao normalizados e salva ambas versoes\n",
    "        plot_matriz_confusao_one_vs_one(y_test, y_pred, model_name, i, flag_normalizado=\"true\")\n",
    "        plot_matriz_confusao_one_vs_one(y_test, y_pred, model_name, i, flag_normalizado=None)\n",
    "        # inicializa a curva roc para cada classe neste fold\n",
    "        for class_id, plot, tprs, aucs in zip(range(9), lista_plots, matriz_tprs, matriz_aucs):\n",
    "            inicializa_roc_one_class_vs_rest_kfold(\n",
    "                y_onehot_test, y_proba, i, class_id, plot[1], tprs, aucs, mean_fpr\n",
    "            )\n",
    "        # inicializa a curva roc micro average neste fold\n",
    "        inicializa_roc_micro_average_kfold(\n",
    "            y_onehot_test, y_proba, i, ax_micro_average, tprs_micro_average, \n",
    "            aucs_micro_average, mean_fpr\n",
    "        )\n",
    "        print(f\"## FINAL FOLD {i} ##\\n\", dic_fold)\n",
    "\n",
    "    endTime = time.time()\n",
    "    # inserindo a média dos folds no dicionário\n",
    "    dic_json = calc_mean_std(dic_json, model_name)\n",
    "    # inserindo o tempo de execução\n",
    "    dic_json.update({\"time\": endTime-startTime})\n",
    "    # salvando o dicionário no formato json\n",
    "    objOpen = open(f'./log_metrics/{model_name}.json', 'w')\n",
    "    objOpen.write(json.dumps(dic_json, indent=4))\n",
    "    objOpen.close()\n",
    "\n",
    "    # gera o plot da curva roc para cada classe, juntando todos os folds e realizando uma media\n",
    "    for class_id, plot, tprs, aucs in zip(range(9), lista_plots, matriz_tprs, matriz_aucs):\n",
    "        gera_roc_one_class_vs_rest_kfold(tprs, aucs, mean_fpr, plot, model_name, class_id)\n",
    "    # gera o plot da curva roc micro average, juntando todos os folds e realizando uma media \n",
    "    gera_roc_micro_average_kfold(\n",
    "        tprs_micro_average, aucs_micro_average, mean_fpr, fig_micro_average, ax_micro_average, \n",
    "        model_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carrega dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>feat_11</th>\n",
       "      <th>feat_12</th>\n",
       "      <th>feat_13</th>\n",
       "      <th>feat_14</th>\n",
       "      <th>feat_15</th>\n",
       "      <th>feat_16</th>\n",
       "      <th>feat_17</th>\n",
       "      <th>feat_18</th>\n",
       "      <th>feat_19</th>\n",
       "      <th>feat_20</th>\n",
       "      <th>feat_21</th>\n",
       "      <th>feat_22</th>\n",
       "      <th>feat_23</th>\n",
       "      <th>feat_24</th>\n",
       "      <th>feat_25</th>\n",
       "      <th>feat_26</th>\n",
       "      <th>feat_27</th>\n",
       "      <th>feat_28</th>\n",
       "      <th>feat_29</th>\n",
       "      <th>feat_30</th>\n",
       "      <th>feat_31</th>\n",
       "      <th>feat_32</th>\n",
       "      <th>feat_33</th>\n",
       "      <th>feat_34</th>\n",
       "      <th>feat_35</th>\n",
       "      <th>feat_36</th>\n",
       "      <th>feat_37</th>\n",
       "      <th>feat_38</th>\n",
       "      <th>feat_39</th>\n",
       "      <th>feat_40</th>\n",
       "      <th>feat_41</th>\n",
       "      <th>feat_42</th>\n",
       "      <th>feat_43</th>\n",
       "      <th>feat_44</th>\n",
       "      <th>feat_45</th>\n",
       "      <th>feat_46</th>\n",
       "      <th>feat_47</th>\n",
       "      <th>feat_48</th>\n",
       "      <th>feat_49</th>\n",
       "      <th>feat_50</th>\n",
       "      <th>feat_51</th>\n",
       "      <th>feat_52</th>\n",
       "      <th>feat_53</th>\n",
       "      <th>feat_54</th>\n",
       "      <th>feat_55</th>\n",
       "      <th>feat_56</th>\n",
       "      <th>feat_57</th>\n",
       "      <th>feat_58</th>\n",
       "      <th>feat_59</th>\n",
       "      <th>feat_60</th>\n",
       "      <th>feat_61</th>\n",
       "      <th>feat_62</th>\n",
       "      <th>feat_63</th>\n",
       "      <th>feat_64</th>\n",
       "      <th>feat_65</th>\n",
       "      <th>feat_66</th>\n",
       "      <th>feat_67</th>\n",
       "      <th>feat_68</th>\n",
       "      <th>feat_69</th>\n",
       "      <th>feat_70</th>\n",
       "      <th>feat_71</th>\n",
       "      <th>feat_72</th>\n",
       "      <th>feat_73</th>\n",
       "      <th>feat_74</th>\n",
       "      <th>feat_75</th>\n",
       "      <th>feat_76</th>\n",
       "      <th>feat_77</th>\n",
       "      <th>feat_78</th>\n",
       "      <th>feat_79</th>\n",
       "      <th>feat_80</th>\n",
       "      <th>feat_81</th>\n",
       "      <th>feat_82</th>\n",
       "      <th>feat_83</th>\n",
       "      <th>feat_84</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'Class_1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'Class_1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'Class_1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'Class_1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'Class_1'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  \\\n",
       "0  1.0     1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1  2.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0   \n",
       "2  3.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0   \n",
       "3  4.0     1.0     0.0     0.0     1.0     6.0     1.0     5.0     0.0   \n",
       "4  5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   feat_9  feat_10  feat_11  feat_12  feat_13  feat_14  feat_15  feat_16  \\\n",
       "0     0.0      0.0      1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1     0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2     0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3     0.0      1.0      1.0      0.0      1.0      0.0      0.0      1.0   \n",
       "4     0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   feat_17  feat_18  feat_19  feat_20  feat_21  feat_22  feat_23  feat_24  \\\n",
       "0      2.0      0.0      0.0      0.0      0.0      1.0      0.0      4.0   \n",
       "1      0.0      2.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      1.0      0.0      0.0      0.0      0.0      0.0      0.0      7.0   \n",
       "4      4.0      0.0      0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "\n",
       "   feat_25  feat_26  feat_27  feat_28  feat_29  feat_30  feat_31  feat_32  \\\n",
       "0      1.0      1.0      0.0      0.0      2.0      0.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      2.0      2.0      0.0      0.0      0.0     58.0      0.0     10.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   feat_33  feat_34  feat_35  feat_36  feat_37  feat_38  feat_39  feat_40  \\\n",
       "0      0.0      0.0      1.0      0.0      0.0      0.0      0.0      1.0   \n",
       "1      0.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "2      1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      3.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   feat_41  feat_42  feat_43  feat_44  feat_45  feat_46  feat_47  feat_48  \\\n",
       "0      0.0      5.0      0.0      0.0      0.0      0.0      0.0      2.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "3      0.0      0.0      0.0      2.0      0.0      2.0      0.0      1.0   \n",
       "4      1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   feat_49  feat_50  feat_51  feat_52  feat_53  feat_54  feat_55  feat_56  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      1.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "3      2.0      1.0      3.0      0.0      0.0      3.0      1.0      0.0   \n",
       "4      0.0      2.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   feat_57  feat_58  feat_59  feat_60  feat_61  feat_62  feat_63  feat_64  \\\n",
       "0      2.0      0.0      0.0     11.0      0.0      1.0      1.0      0.0   \n",
       "1      0.0      1.0      0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      1.0      0.0      0.0   \n",
       "\n",
       "   feat_65  feat_66  feat_67  feat_68  feat_69  feat_70  feat_71  feat_72  \\\n",
       "0      1.0      0.0      7.0      0.0      0.0      0.0      1.0      0.0   \n",
       "1      0.0      0.0      1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      6.0      0.0      0.0      2.0      0.0      0.0   \n",
       "3      2.0      1.0      5.0      0.0      0.0      4.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0      1.0      0.0      0.0      3.0      0.0   \n",
       "\n",
       "   feat_73  feat_74  feat_75  feat_76  feat_77  feat_78  feat_79  feat_80  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0      2.0      1.0   \n",
       "1      2.0      1.0      0.0      1.0      0.0      1.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      2.0      1.0      0.0      1.0      0.0      0.0      1.0      1.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0      4.0      0.0   \n",
       "\n",
       "   feat_81  feat_82  feat_83  feat_84  feat_85  feat_86  feat_87  feat_88  \\\n",
       "0      0.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      2.0      2.0      0.0     22.0      0.0      1.0      2.0      0.0   \n",
       "4      1.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "\n",
       "   feat_89  feat_90  feat_91  feat_92  feat_93      target  \n",
       "0      0.0      0.0      0.0      0.0      0.0  b'Class_1'  \n",
       "1      0.0      0.0      0.0      0.0      0.0  b'Class_1'  \n",
       "2      0.0      0.0      0.0      0.0      0.0  b'Class_1'  \n",
       "3      0.0      0.0      0.0      0.0      0.0  b'Class_1'  \n",
       "4      0.0      1.0      0.0      0.0      0.0  b'Class_1'  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = loadarff('data/dataset.arff')\n",
    "df_data = pd.DataFrame(raw_data[0])\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decodifica string de target\n",
    "df_data[\"target\"] = df_data[\"target\"].str.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>feat_11</th>\n",
       "      <th>feat_12</th>\n",
       "      <th>feat_13</th>\n",
       "      <th>feat_14</th>\n",
       "      <th>feat_15</th>\n",
       "      <th>feat_16</th>\n",
       "      <th>feat_17</th>\n",
       "      <th>feat_18</th>\n",
       "      <th>feat_19</th>\n",
       "      <th>feat_20</th>\n",
       "      <th>feat_21</th>\n",
       "      <th>feat_22</th>\n",
       "      <th>feat_23</th>\n",
       "      <th>feat_24</th>\n",
       "      <th>feat_25</th>\n",
       "      <th>feat_26</th>\n",
       "      <th>feat_27</th>\n",
       "      <th>feat_28</th>\n",
       "      <th>feat_29</th>\n",
       "      <th>feat_30</th>\n",
       "      <th>feat_31</th>\n",
       "      <th>feat_32</th>\n",
       "      <th>feat_33</th>\n",
       "      <th>feat_34</th>\n",
       "      <th>feat_35</th>\n",
       "      <th>feat_36</th>\n",
       "      <th>feat_37</th>\n",
       "      <th>feat_38</th>\n",
       "      <th>feat_39</th>\n",
       "      <th>feat_40</th>\n",
       "      <th>feat_41</th>\n",
       "      <th>feat_42</th>\n",
       "      <th>feat_43</th>\n",
       "      <th>feat_44</th>\n",
       "      <th>feat_45</th>\n",
       "      <th>feat_46</th>\n",
       "      <th>feat_47</th>\n",
       "      <th>feat_48</th>\n",
       "      <th>feat_49</th>\n",
       "      <th>feat_50</th>\n",
       "      <th>feat_51</th>\n",
       "      <th>feat_52</th>\n",
       "      <th>feat_53</th>\n",
       "      <th>feat_54</th>\n",
       "      <th>feat_55</th>\n",
       "      <th>feat_56</th>\n",
       "      <th>feat_57</th>\n",
       "      <th>feat_58</th>\n",
       "      <th>feat_59</th>\n",
       "      <th>feat_60</th>\n",
       "      <th>feat_61</th>\n",
       "      <th>feat_62</th>\n",
       "      <th>feat_63</th>\n",
       "      <th>feat_64</th>\n",
       "      <th>feat_65</th>\n",
       "      <th>feat_66</th>\n",
       "      <th>feat_67</th>\n",
       "      <th>feat_68</th>\n",
       "      <th>feat_69</th>\n",
       "      <th>feat_70</th>\n",
       "      <th>feat_71</th>\n",
       "      <th>feat_72</th>\n",
       "      <th>feat_73</th>\n",
       "      <th>feat_74</th>\n",
       "      <th>feat_75</th>\n",
       "      <th>feat_76</th>\n",
       "      <th>feat_77</th>\n",
       "      <th>feat_78</th>\n",
       "      <th>feat_79</th>\n",
       "      <th>feat_80</th>\n",
       "      <th>feat_81</th>\n",
       "      <th>feat_82</th>\n",
       "      <th>feat_83</th>\n",
       "      <th>feat_84</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48568</th>\n",
       "      <td>48569.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Class_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37224</th>\n",
       "      <td>37225.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Class_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35218</th>\n",
       "      <td>35219.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Class_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776</th>\n",
       "      <td>2777.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>1603.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  \\\n",
       "48568  48569.0     0.0     1.0     0.0     0.0     0.0     0.0     1.0   \n",
       "37224  37225.0     0.0     1.0     4.0     1.0     0.0     0.0     0.0   \n",
       "35218  35219.0     0.0     0.0     1.0     2.0     0.0     0.0     0.0   \n",
       "2776    2777.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1602    1603.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0   \n",
       "\n",
       "       feat_8  feat_9  feat_10  feat_11  feat_12  feat_13  feat_14  feat_15  \\\n",
       "48568     1.0     0.0      0.0      1.0      0.0      0.0      0.0      2.0   \n",
       "37224     0.0     0.0      0.0      8.0      1.0      0.0      0.0      0.0   \n",
       "35218     0.0     0.0      2.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2776      0.0    14.0      0.0      0.0      0.0      0.0      0.0      2.0   \n",
       "1602      0.0     0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       feat_16  feat_17  feat_18  feat_19  feat_20  feat_21  feat_22  feat_23  \\\n",
       "48568      0.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "37224      5.0      0.0      1.0      0.0      0.0      1.0      0.0      0.0   \n",
       "35218      0.0      2.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "2776       0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1602       0.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "\n",
       "       feat_24  feat_25  feat_26  feat_27  feat_28  feat_29  feat_30  feat_31  \\\n",
       "48568      5.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "37224      2.0      0.0      2.0      9.0      3.0      0.0      0.0      0.0   \n",
       "35218      2.0      1.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2776       1.0      1.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1602       5.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       feat_32  feat_33  feat_34  feat_35  feat_36  feat_37  feat_38  feat_39  \\\n",
       "48568      5.0      0.0      0.0      0.0      0.0      1.0      0.0      0.0   \n",
       "37224      0.0      0.0      1.0      0.0      0.0      0.0      1.0      0.0   \n",
       "35218      0.0      0.0      0.0      0.0      2.0      0.0      0.0      0.0   \n",
       "2776       6.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1602       0.0      0.0      0.0      0.0      4.0      0.0      0.0      1.0   \n",
       "\n",
       "       feat_40  feat_41  feat_42  feat_43  feat_44  feat_45  feat_46  feat_47  \\\n",
       "48568      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "37224      0.0      0.0      0.0      0.0      0.0      1.0      8.0      0.0   \n",
       "35218      0.0      0.0      2.0      0.0      3.0      0.0      0.0      0.0   \n",
       "2776       0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1602       0.0      0.0      0.0      0.0      0.0      0.0      0.0      4.0   \n",
       "\n",
       "       feat_48  feat_49  feat_50  feat_51  feat_52  feat_53  feat_54  feat_55  \\\n",
       "48568      1.0      0.0      1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "37224      0.0      1.0      0.0      0.0      0.0      1.0      5.0      0.0   \n",
       "35218      0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "2776       1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1602       1.0      0.0      1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       feat_56  feat_57  feat_58  feat_59  feat_60  feat_61  feat_62  feat_63  \\\n",
       "48568      0.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "37224      2.0      0.0      0.0      0.0      1.0      8.0      1.0      0.0   \n",
       "35218      0.0      2.0      0.0      0.0     10.0      0.0      0.0      0.0   \n",
       "2776       0.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "1602       0.0      0.0      0.0      0.0      0.0      0.0      2.0      0.0   \n",
       "\n",
       "       feat_64  feat_65  feat_66  feat_67  feat_68  feat_69  feat_70  feat_71  \\\n",
       "48568      0.0      1.0      0.0      5.0      0.0      1.0      0.0      1.0   \n",
       "37224      0.0      0.0      0.0      0.0      2.0      0.0      0.0      0.0   \n",
       "35218      0.0      0.0      1.0      2.0      0.0      0.0      0.0      0.0   \n",
       "2776       8.0      0.0      0.0      3.0      0.0      0.0      0.0      0.0   \n",
       "1602       3.0      2.0      0.0      5.0      0.0      1.0      0.0     10.0   \n",
       "\n",
       "       feat_72  feat_73  feat_74  feat_75  feat_76  feat_77  feat_78  feat_79  \\\n",
       "48568      0.0      1.0      0.0      1.0      1.0      0.0      0.0      0.0   \n",
       "37224      0.0      1.0      1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "35218      2.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2776       0.0      2.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "1602       1.0      0.0      0.0      0.0      0.0      0.0      2.0      0.0   \n",
       "\n",
       "       feat_80  feat_81  feat_82  feat_83  feat_84  feat_85  feat_86  feat_87  \\\n",
       "48568      1.0      0.0      0.0     18.0      0.0      0.0      0.0      0.0   \n",
       "37224      9.0      0.0      1.0      0.0      0.0      0.0      1.0      0.0   \n",
       "35218      0.0      0.0      0.0      1.0      0.0      0.0      1.0      0.0   \n",
       "2776       0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1602       0.0      0.0      0.0      0.0      0.0      0.0      1.0      2.0   \n",
       "\n",
       "       feat_88  feat_89  feat_90  feat_91  feat_92  feat_93   target  \n",
       "48568      0.0      0.0      2.0      0.0      0.0      0.0  Class_8  \n",
       "37224      0.0      3.0      0.0      0.0      0.0      0.0  Class_6  \n",
       "35218      0.0      0.0      0.0      0.0      0.0      0.0  Class_6  \n",
       "2776       0.0      0.0      0.0      0.0      0.0      0.0  Class_2  \n",
       "1602       1.0      0.0      0.0      0.0      0.0      0.0  Class_1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dataset: (61878, 95)\n"
     ]
    }
   ],
   "source": [
    "# verificando o número de linhas e colunas do dataset\n",
    "print(\"Shape dataset:\", df_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor mínimo das features: 0.0\n"
     ]
    }
   ],
   "source": [
    "# verificando o menor valor das colunas de características\n",
    "print(\"Valor mínimo das features:\", df_data.iloc[:,1:-1].min().min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor máximo das features: 352.0\n"
     ]
    }
   ],
   "source": [
    "# verificando o maior valor das colunas de características\n",
    "print(\"Valor máximo das features:\", df_data.iloc[:,1:-1].max().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de Instâncias por Classe:\n",
      " target\n",
      "Class_1     1929\n",
      "Class_2    16122\n",
      "Class_3     8004\n",
      "Class_4     2691\n",
      "Class_5     2739\n",
      "Class_6    14135\n",
      "Class_7     2839\n",
      "Class_8     8464\n",
      "Class_9     4955\n",
      "Name: id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# verificando o número de instâncias para cada classe\n",
    "print('Número de Instâncias por Classe:\\n', df_data.groupby('target').count()['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentual de Instâncias por Classe:\n",
      " target\n",
      "Class_1     3.117425\n",
      "Class_2    26.054494\n",
      "Class_3    12.935130\n",
      "Class_4     4.348880\n",
      "Class_5     4.426452\n",
      "Class_6    22.843337\n",
      "Class_7     4.588060\n",
      "Class_8    13.678529\n",
      "Class_9     8.007693\n",
      "Name: id, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# verificando o percentual de instâncias para cada classe\n",
    "print('Percentual de Instâncias por Classe:\\n', (df_data.groupby('target').count()['id']/df_data.shape[0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Número de Valores NaN: 0\n"
     ]
    }
   ],
   "source": [
    "# verificando se existem valores NaN\n",
    "print('\\nNúmero de Valores NaN:', df_data.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>feat_11</th>\n",
       "      <th>feat_12</th>\n",
       "      <th>feat_13</th>\n",
       "      <th>feat_14</th>\n",
       "      <th>feat_15</th>\n",
       "      <th>feat_16</th>\n",
       "      <th>feat_17</th>\n",
       "      <th>feat_18</th>\n",
       "      <th>feat_19</th>\n",
       "      <th>feat_20</th>\n",
       "      <th>feat_21</th>\n",
       "      <th>feat_22</th>\n",
       "      <th>feat_23</th>\n",
       "      <th>feat_24</th>\n",
       "      <th>feat_25</th>\n",
       "      <th>feat_26</th>\n",
       "      <th>feat_27</th>\n",
       "      <th>feat_28</th>\n",
       "      <th>feat_29</th>\n",
       "      <th>feat_30</th>\n",
       "      <th>feat_31</th>\n",
       "      <th>feat_32</th>\n",
       "      <th>feat_33</th>\n",
       "      <th>feat_34</th>\n",
       "      <th>feat_35</th>\n",
       "      <th>feat_36</th>\n",
       "      <th>feat_37</th>\n",
       "      <th>feat_38</th>\n",
       "      <th>feat_39</th>\n",
       "      <th>feat_40</th>\n",
       "      <th>feat_41</th>\n",
       "      <th>feat_42</th>\n",
       "      <th>feat_43</th>\n",
       "      <th>feat_44</th>\n",
       "      <th>feat_45</th>\n",
       "      <th>feat_46</th>\n",
       "      <th>feat_47</th>\n",
       "      <th>feat_48</th>\n",
       "      <th>feat_49</th>\n",
       "      <th>feat_50</th>\n",
       "      <th>feat_51</th>\n",
       "      <th>feat_52</th>\n",
       "      <th>feat_53</th>\n",
       "      <th>feat_54</th>\n",
       "      <th>feat_55</th>\n",
       "      <th>feat_56</th>\n",
       "      <th>feat_57</th>\n",
       "      <th>feat_58</th>\n",
       "      <th>feat_59</th>\n",
       "      <th>feat_60</th>\n",
       "      <th>feat_61</th>\n",
       "      <th>feat_62</th>\n",
       "      <th>feat_63</th>\n",
       "      <th>feat_64</th>\n",
       "      <th>feat_65</th>\n",
       "      <th>feat_66</th>\n",
       "      <th>feat_67</th>\n",
       "      <th>feat_68</th>\n",
       "      <th>feat_69</th>\n",
       "      <th>feat_70</th>\n",
       "      <th>feat_71</th>\n",
       "      <th>feat_72</th>\n",
       "      <th>feat_73</th>\n",
       "      <th>feat_74</th>\n",
       "      <th>feat_75</th>\n",
       "      <th>feat_76</th>\n",
       "      <th>feat_77</th>\n",
       "      <th>feat_78</th>\n",
       "      <th>feat_79</th>\n",
       "      <th>feat_80</th>\n",
       "      <th>feat_81</th>\n",
       "      <th>feat_82</th>\n",
       "      <th>feat_83</th>\n",
       "      <th>feat_84</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.00000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30939.500000</td>\n",
       "      <td>0.38668</td>\n",
       "      <td>0.263066</td>\n",
       "      <td>0.901467</td>\n",
       "      <td>0.779081</td>\n",
       "      <td>0.071043</td>\n",
       "      <td>0.025696</td>\n",
       "      <td>0.193704</td>\n",
       "      <td>0.662433</td>\n",
       "      <td>1.011296</td>\n",
       "      <td>0.263906</td>\n",
       "      <td>1.252869</td>\n",
       "      <td>0.140874</td>\n",
       "      <td>0.480979</td>\n",
       "      <td>1.696693</td>\n",
       "      <td>1.284398</td>\n",
       "      <td>1.413459</td>\n",
       "      <td>0.366108</td>\n",
       "      <td>0.575423</td>\n",
       "      <td>0.551699</td>\n",
       "      <td>0.471525</td>\n",
       "      <td>0.204014</td>\n",
       "      <td>0.729969</td>\n",
       "      <td>0.142522</td>\n",
       "      <td>2.643880</td>\n",
       "      <td>1.534520</td>\n",
       "      <td>0.563108</td>\n",
       "      <td>0.696613</td>\n",
       "      <td>0.238970</td>\n",
       "      <td>0.275768</td>\n",
       "      <td>0.150312</td>\n",
       "      <td>0.148680</td>\n",
       "      <td>1.043796</td>\n",
       "      <td>0.696516</td>\n",
       "      <td>0.946411</td>\n",
       "      <td>0.666263</td>\n",
       "      <td>0.709089</td>\n",
       "      <td>0.263632</td>\n",
       "      <td>0.582129</td>\n",
       "      <td>0.485585</td>\n",
       "      <td>1.653059</td>\n",
       "      <td>0.303468</td>\n",
       "      <td>0.698019</td>\n",
       "      <td>0.451146</td>\n",
       "      <td>0.560829</td>\n",
       "      <td>0.238130</td>\n",
       "      <td>0.641375</td>\n",
       "      <td>0.249669</td>\n",
       "      <td>1.584893</td>\n",
       "      <td>0.348314</td>\n",
       "      <td>0.324283</td>\n",
       "      <td>0.053298</td>\n",
       "      <td>0.213485</td>\n",
       "      <td>0.442063</td>\n",
       "      <td>2.072465</td>\n",
       "      <td>0.323120</td>\n",
       "      <td>0.303775</td>\n",
       "      <td>0.309108</td>\n",
       "      <td>0.697970</td>\n",
       "      <td>0.388603</td>\n",
       "      <td>1.029930</td>\n",
       "      <td>0.239746</td>\n",
       "      <td>1.187563</td>\n",
       "      <td>0.168590</td>\n",
       "      <td>1.256796</td>\n",
       "      <td>0.222228</td>\n",
       "      <td>0.571706</td>\n",
       "      <td>2.897653</td>\n",
       "      <td>0.392902</td>\n",
       "      <td>0.811128</td>\n",
       "      <td>0.892789</td>\n",
       "      <td>0.319290</td>\n",
       "      <td>0.858722</td>\n",
       "      <td>0.591050</td>\n",
       "      <td>0.579851</td>\n",
       "      <td>0.726817</td>\n",
       "      <td>0.748457</td>\n",
       "      <td>0.124196</td>\n",
       "      <td>0.366415</td>\n",
       "      <td>0.300446</td>\n",
       "      <td>0.698067</td>\n",
       "      <td>0.078461</td>\n",
       "      <td>0.187983</td>\n",
       "      <td>0.496719</td>\n",
       "      <td>0.070752</td>\n",
       "      <td>0.532306</td>\n",
       "      <td>1.128576</td>\n",
       "      <td>0.393549</td>\n",
       "      <td>0.874915</td>\n",
       "      <td>0.457772</td>\n",
       "      <td>0.812421</td>\n",
       "      <td>0.264941</td>\n",
       "      <td>0.380119</td>\n",
       "      <td>0.126135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17862.784315</td>\n",
       "      <td>1.52533</td>\n",
       "      <td>1.252073</td>\n",
       "      <td>2.934818</td>\n",
       "      <td>2.788005</td>\n",
       "      <td>0.438902</td>\n",
       "      <td>0.215333</td>\n",
       "      <td>1.030102</td>\n",
       "      <td>2.255770</td>\n",
       "      <td>3.474822</td>\n",
       "      <td>1.083340</td>\n",
       "      <td>3.042333</td>\n",
       "      <td>0.567089</td>\n",
       "      <td>2.014697</td>\n",
       "      <td>3.163212</td>\n",
       "      <td>3.862236</td>\n",
       "      <td>2.226163</td>\n",
       "      <td>1.477436</td>\n",
       "      <td>1.335985</td>\n",
       "      <td>4.636145</td>\n",
       "      <td>1.438727</td>\n",
       "      <td>0.696050</td>\n",
       "      <td>1.446220</td>\n",
       "      <td>0.782979</td>\n",
       "      <td>4.629015</td>\n",
       "      <td>2.332994</td>\n",
       "      <td>1.710305</td>\n",
       "      <td>2.873222</td>\n",
       "      <td>0.828112</td>\n",
       "      <td>1.901294</td>\n",
       "      <td>1.640880</td>\n",
       "      <td>0.897354</td>\n",
       "      <td>2.416849</td>\n",
       "      <td>1.310202</td>\n",
       "      <td>3.368622</td>\n",
       "      <td>3.197965</td>\n",
       "      <td>2.555119</td>\n",
       "      <td>0.756934</td>\n",
       "      <td>1.602579</td>\n",
       "      <td>3.298315</td>\n",
       "      <td>3.299798</td>\n",
       "      <td>1.085672</td>\n",
       "      <td>1.961189</td>\n",
       "      <td>1.706013</td>\n",
       "      <td>1.346090</td>\n",
       "      <td>2.587131</td>\n",
       "      <td>2.348359</td>\n",
       "      <td>1.446203</td>\n",
       "      <td>2.577071</td>\n",
       "      <td>1.369380</td>\n",
       "      <td>1.720470</td>\n",
       "      <td>0.513820</td>\n",
       "      <td>1.044788</td>\n",
       "      <td>2.006485</td>\n",
       "      <td>4.113319</td>\n",
       "      <td>0.998743</td>\n",
       "      <td>1.925806</td>\n",
       "      <td>1.082148</td>\n",
       "      <td>3.983722</td>\n",
       "      <td>2.577693</td>\n",
       "      <td>3.028469</td>\n",
       "      <td>1.017553</td>\n",
       "      <td>2.666742</td>\n",
       "      <td>0.946158</td>\n",
       "      <td>3.402080</td>\n",
       "      <td>0.783052</td>\n",
       "      <td>1.361874</td>\n",
       "      <td>4.974322</td>\n",
       "      <td>1.761054</td>\n",
       "      <td>4.111091</td>\n",
       "      <td>1.941368</td>\n",
       "      <td>1.162443</td>\n",
       "      <td>2.411646</td>\n",
       "      <td>5.783233</td>\n",
       "      <td>3.757822</td>\n",
       "      <td>3.200095</td>\n",
       "      <td>2.920038</td>\n",
       "      <td>0.906621</td>\n",
       "      <td>2.778317</td>\n",
       "      <td>1.285569</td>\n",
       "      <td>2.245671</td>\n",
       "      <td>0.461244</td>\n",
       "      <td>0.836269</td>\n",
       "      <td>2.434921</td>\n",
       "      <td>1.151460</td>\n",
       "      <td>1.900438</td>\n",
       "      <td>2.681554</td>\n",
       "      <td>1.575455</td>\n",
       "      <td>2.115466</td>\n",
       "      <td>1.527385</td>\n",
       "      <td>4.597804</td>\n",
       "      <td>2.045646</td>\n",
       "      <td>0.982385</td>\n",
       "      <td>1.201720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15470.250000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30939.500000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46408.750000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61.00000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>352.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       feat_1        feat_2        feat_3        feat_4  \\\n",
       "count  61878.000000  61878.00000  61878.000000  61878.000000  61878.000000   \n",
       "mean   30939.500000      0.38668      0.263066      0.901467      0.779081   \n",
       "std    17862.784315      1.52533      1.252073      2.934818      2.788005   \n",
       "min        1.000000      0.00000      0.000000      0.000000      0.000000   \n",
       "25%    15470.250000      0.00000      0.000000      0.000000      0.000000   \n",
       "50%    30939.500000      0.00000      0.000000      0.000000      0.000000   \n",
       "75%    46408.750000      0.00000      0.000000      0.000000      0.000000   \n",
       "max    61878.000000     61.00000     51.000000     64.000000     70.000000   \n",
       "\n",
       "             feat_5        feat_6        feat_7        feat_8        feat_9  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.071043      0.025696      0.193704      0.662433      1.011296   \n",
       "std        0.438902      0.215333      1.030102      2.255770      3.474822   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "max       19.000000     10.000000     38.000000     76.000000     43.000000   \n",
       "\n",
       "            feat_10       feat_11       feat_12       feat_13       feat_14  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.263906      1.252869      0.140874      0.480979      1.696693   \n",
       "std        1.083340      3.042333      0.567089      2.014697      3.163212   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      1.000000      0.000000      0.000000      2.000000   \n",
       "max       30.000000     38.000000     30.000000     72.000000     33.000000   \n",
       "\n",
       "            feat_15       feat_16       feat_17       feat_18       feat_19  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       1.284398      1.413459      0.366108      0.575423      0.551699   \n",
       "std        3.862236      2.226163      1.477436      1.335985      4.636145   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      2.000000      0.000000      1.000000      0.000000   \n",
       "max       46.000000     37.000000     43.000000     32.000000    121.000000   \n",
       "\n",
       "            feat_20       feat_21       feat_22       feat_23       feat_24  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.471525      0.204014      0.729969      0.142522      2.643880   \n",
       "std        1.438727      0.696050      1.446220      0.782979      4.629015   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      1.000000   \n",
       "75%        0.000000      0.000000      1.000000      0.000000      3.000000   \n",
       "max       27.000000     14.000000     22.000000     64.000000    263.000000   \n",
       "\n",
       "            feat_25       feat_26       feat_27       feat_28       feat_29  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       1.534520      0.563108      0.696613      0.238970      0.275768   \n",
       "std        2.332994      1.710305      2.873222      0.828112      1.901294   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        2.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       30.000000     33.000000    123.000000     22.000000     69.000000   \n",
       "\n",
       "            feat_30       feat_31       feat_32       feat_33       feat_34  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.150312      0.148680      1.043796      0.696516      0.946411   \n",
       "std        1.640880      0.897354      2.416849      1.310202      3.368622   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      1.000000      1.000000      1.000000   \n",
       "max       87.000000     59.000000    149.000000     24.000000     84.000000   \n",
       "\n",
       "            feat_35       feat_36       feat_37       feat_38       feat_39  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.666263      0.709089      0.263632      0.582129      0.485585   \n",
       "std        3.197965      2.555119      0.756934      1.602579      3.298315   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      1.000000      0.000000      1.000000      0.000000   \n",
       "max      105.000000     84.000000     22.000000     39.000000     78.000000   \n",
       "\n",
       "            feat_40       feat_41       feat_42       feat_43       feat_44  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       1.653059      0.303468      0.698019      0.451146      0.560829   \n",
       "std        3.299798      1.085672      1.961189      1.706013      1.346090   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        2.000000      0.000000      1.000000      0.000000      1.000000   \n",
       "max       41.000000     36.000000     41.000000     42.000000     34.000000   \n",
       "\n",
       "            feat_45       feat_46       feat_47       feat_48       feat_49  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.238130      0.641375      0.249669      1.584893      0.348314   \n",
       "std        2.587131      2.348359      1.446203      2.577071      1.369380   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      2.000000      0.000000   \n",
       "max       80.000000     41.000000     47.000000     49.000000     81.000000   \n",
       "\n",
       "            feat_50       feat_51       feat_52       feat_53       feat_54  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.324283      0.053298      0.213485      0.442063      2.072465   \n",
       "std        1.720470      0.513820      1.044788      2.006485      4.113319   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      2.000000   \n",
       "max       73.000000     44.000000     48.000000     53.000000     63.000000   \n",
       "\n",
       "            feat_55       feat_56       feat_57       feat_58       feat_59  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.323120      0.303775      0.309108      0.697970      0.388603   \n",
       "std        0.998743      1.925806      1.082148      3.983722      2.577693   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       27.000000     62.000000     30.000000    117.000000     97.000000   \n",
       "\n",
       "            feat_60       feat_61       feat_62       feat_63       feat_64  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       1.029930      0.239746      1.187563      0.168590      1.256796   \n",
       "std        3.028469      1.017553      2.666742      0.946158      3.402080   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      1.000000      0.000000      1.000000   \n",
       "max       40.000000     38.000000     56.000000     51.000000     73.000000   \n",
       "\n",
       "            feat_65       feat_66       feat_67       feat_68       feat_69  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.222228      0.571706      2.897653      0.392902      0.811128   \n",
       "std        0.783052      1.361874      4.974322      1.761054      4.111091   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "75%        0.000000      1.000000      4.000000      0.000000      0.000000   \n",
       "max       38.000000     36.000000    104.000000    109.000000     76.000000   \n",
       "\n",
       "            feat_70       feat_71       feat_72       feat_73       feat_74  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.892789      0.319290      0.858722      0.591050      0.579851   \n",
       "std        1.941368      1.162443      2.411646      5.783233      3.757822   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "max       46.000000     31.000000     30.000000    352.000000    231.000000   \n",
       "\n",
       "            feat_75       feat_76       feat_77       feat_78       feat_79  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.726817      0.748457      0.124196      0.366415      0.300446   \n",
       "std        3.200095      2.920038      0.906621      2.778317      1.285569   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       80.000000    102.000000     29.000000     80.000000     25.000000   \n",
       "\n",
       "            feat_80       feat_81       feat_82       feat_83       feat_84  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.698067      0.078461      0.187983      0.496719      0.070752   \n",
       "std        2.245671      0.461244      0.836269      2.434921      1.151460   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       54.000000     26.000000     24.000000     79.000000     76.000000   \n",
       "\n",
       "            feat_85       feat_86       feat_87       feat_88       feat_89  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.532306      1.128576      0.393549      0.874915      0.457772   \n",
       "std        1.900438      2.681554      1.575455      2.115466      1.527385   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      1.000000      0.000000      1.000000      0.000000   \n",
       "max       55.000000     65.000000     67.000000     30.000000     61.000000   \n",
       "\n",
       "            feat_90       feat_91       feat_92       feat_93  \n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  \n",
       "mean       0.812421      0.264941      0.380119      0.126135  \n",
       "std        4.597804      2.045646      0.982385      1.201720  \n",
       "min        0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.000000      0.000000      0.000000      0.000000  \n",
       "50%        0.000000      0.000000      0.000000      0.000000  \n",
       "75%        0.000000      0.000000      0.000000      0.000000  \n",
       "max      130.000000     52.000000     19.000000     87.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_data.drop(columns=[\"id\", \"target\"])\n",
    "y = df_data[[\"target\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: KNN\n",
      "## INICIO FOLD 0 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.756 total time=   4.6s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.762 total time=   4.2s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.756 total time=   4.3s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.766 total time=   4.4s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.761 total time=   5.1s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.755 total time=   4.5s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.760 total time=   6.3s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.753 total time=   4.5s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.761 total time=   4.8s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.755 total time=   4.4s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.750 total time=   4.8s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.756 total time=   5.3s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.748 total time=   4.8s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.760 total time=   5.6s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.754 total time=   5.3s\n",
      "## FINAL FOLD 0 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7774725274725275, 'balanced_accuracy': 0.7091265107522307, 'precision_micro': 0.7774725274725275, 'precision_macro': 0.7632733339044037, 'precision_weighted': 0.7764377254457373, 'recall_micro': 0.7774725274725275, 'recall_macro': 0.7091265107522307, 'recall_weighted': 0.7774725274725275, 'f1_micro': 0.7774725274725275, 'f1_macro': 0.726238310296594, 'f1_weighted': 0.7712381643746367, 'roc_auc_ovr_micro': 0.9543757412249619, 'roc_auc_ovo_micro': 0.9543757412249619, 'roc_auc_ovr_macro': 0.9299930094749267, 'roc_auc_ovo_macro': 0.9299930094749267, 'roc_auc_ovr_weighted': 0.9397506368507609, 'roc_auc_ovo_weighted': 0.9397506368507609}, 'classification_report': {'Class_1': {'precision': 0.6032608695652174, 'recall': 0.5751295336787565, 'f1-score': 0.5888594164456232, 'support': 193.0}, 'Class_2': {'precision': 0.6802651708312085, 'recall': 0.8270303781773094, 'f1-score': 0.7465025181869054, 'support': 1613.0}, 'Class_3': {'precision': 0.5555555555555556, 'recall': 0.48125, 'f1-score': 0.5157401205626256, 'support': 800.0}, 'Class_4': {'precision': 0.6774193548387096, 'recall': 0.31226765799256506, 'f1-score': 0.42748091603053434, 'support': 269.0}, 'Class_5': {'precision': 0.9298245614035088, 'recall': 0.9671532846715328, 'f1-score': 0.9481216457960643, 'support': 274.0}, 'Class_6': {'precision': 0.9316239316239316, 'recall': 0.9256900212314225, 'f1-score': 0.9286474973375932, 'support': 1413.0}, 'Class_7': {'precision': 0.7373271889400922, 'recall': 0.5633802816901409, 'f1-score': 0.6387225548902196, 'support': 284.0}, 'Class_8': {'precision': 0.8958837772397095, 'recall': 0.8736717827626919, 'f1-score': 0.8846383741781231, 'support': 847.0}, 'Class_9': {'precision': 0.8582995951417004, 'recall': 0.8565656565656565, 'f1-score': 0.8574317492416582, 'support': 495.0}, 'accuracy': 0.7774725274725275, 'macro avg': {'precision': 0.7632733339044037, 'recall': 0.7091265107522307, 'f1-score': 0.726238310296594, 'support': 6188.0}, 'weighted avg': {'precision': 0.7764377254457373, 'recall': 0.7774725274725275, 'f1-score': 0.7712381643746367, 'support': 6188.0}}}\n",
      "## INICIO FOLD 1 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.758 total time=   4.0s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.759 total time=   3.9s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.759 total time=   4.1s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.761 total time=   4.0s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.765 total time=   4.2s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.751 total time=   4.1s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.756 total time=   4.2s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.756 total time=   4.1s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.761 total time=   4.1s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.760 total time=   3.9s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.753 total time=   4.5s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.754 total time=   3.9s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.752 total time=   4.0s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.754 total time=   4.1s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.752 total time=   4.2s\n",
      "## FINAL FOLD 1 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7773109243697479, 'balanced_accuracy': 0.7054995811348125, 'precision_micro': 0.7773109243697479, 'precision_macro': 0.7547942339427455, 'precision_weighted': 0.7744074873639456, 'recall_micro': 0.7773109243697479, 'recall_macro': 0.7054995811348125, 'recall_weighted': 0.7773109243697479, 'f1_micro': 0.7773109243697479, 'f1_macro': 0.7221430150063037, 'f1_weighted': 0.770856844257754, 'roc_auc_ovr_micro': 0.9530114168883704, 'roc_auc_ovo_micro': 0.9530114168883704, 'roc_auc_ovr_macro': 0.9253920386311402, 'roc_auc_ovo_macro': 0.9253920386311402, 'roc_auc_ovr_weighted': 0.9386026021713715, 'roc_auc_ovo_weighted': 0.9386026021713715}, 'classification_report': {'Class_1': {'precision': 0.5675675675675675, 'recall': 0.5440414507772021, 'f1-score': 0.5555555555555555, 'support': 193.0}, 'Class_2': {'precision': 0.6906952965235174, 'recall': 0.8380893300248139, 'f1-score': 0.757286995515695, 'support': 1612.0}, 'Class_3': {'precision': 0.5414847161572053, 'recall': 0.46441947565543074, 'f1-score': 0.5, 'support': 801.0}, 'Class_4': {'precision': 0.6390977443609023, 'recall': 0.3159851301115242, 'f1-score': 0.4228855721393035, 'support': 269.0}, 'Class_5': {'precision': 0.9501779359430605, 'recall': 0.9744525547445255, 'f1-score': 0.9621621621621621, 'support': 274.0}, 'Class_6': {'precision': 0.9265220433869839, 'recall': 0.9370134465675867, 'f1-score': 0.9317382125263899, 'support': 1413.0}, 'Class_7': {'precision': 0.7094017094017094, 'recall': 0.5845070422535211, 'f1-score': 0.6409266409266409, 'support': 284.0}, 'Class_8': {'precision': 0.9011124845488258, 'recall': 0.8606847697756789, 'f1-score': 0.8804347826086957, 'support': 847.0}, 'Class_9': {'precision': 0.8670886075949367, 'recall': 0.8303030303030303, 'f1-score': 0.848297213622291, 'support': 495.0}, 'accuracy': 0.7773109243697479, 'macro avg': {'precision': 0.7547942339427455, 'recall': 0.7054995811348125, 'f1-score': 0.7221430150063037, 'support': 6188.0}, 'weighted avg': {'precision': 0.7744074873639456, 'recall': 0.7773109243697479, 'f1-score': 0.770856844257754, 'support': 6188.0}}}\n",
      "## INICIO FOLD 2 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.758 total time=   4.0s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.763 total time=   4.3s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.760 total time=   4.4s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.767 total time=   4.1s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.765 total time=   4.0s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.751 total time=   4.0s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.760 total time=   4.1s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.755 total time=   3.9s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.764 total time=   4.2s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.761 total time=   4.3s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.750 total time=   5.1s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.756 total time=   5.4s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.750 total time=   4.4s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.760 total time=   4.0s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.756 total time=   4.2s\n",
      "## FINAL FOLD 2 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7584033613445378, 'balanced_accuracy': 0.6853178819244552, 'precision_micro': 0.7584033613445378, 'precision_macro': 0.7323020902731736, 'precision_weighted': 0.7574334090932247, 'recall_micro': 0.7584033613445378, 'recall_macro': 0.6853178819244552, 'recall_weighted': 0.7584033613445378, 'f1_micro': 0.7584033613445378, 'f1_macro': 0.6994957370059827, 'f1_weighted': 0.752310854219091, 'roc_auc_ovr_micro': 0.9486233070064085, 'roc_auc_ovo_micro': 0.9486233070064085, 'roc_auc_ovr_macro': 0.9203413576667406, 'roc_auc_ovo_macro': 0.9203413576667406, 'roc_auc_ovr_weighted': 0.9330841931720867, 'roc_auc_ovo_weighted': 0.9330841931720867}, 'classification_report': {'Class_1': {'precision': 0.5362318840579711, 'recall': 0.5751295336787565, 'f1-score': 0.5550000000000002, 'support': 193.0}, 'Class_2': {'precision': 0.6651538073625819, 'recall': 0.8182382133995038, 'f1-score': 0.7337969401947149, 'support': 1612.0}, 'Class_3': {'precision': 0.5071022727272727, 'recall': 0.44569288389513106, 'f1-score': 0.4744186046511628, 'support': 801.0}, 'Class_4': {'precision': 0.5798319327731093, 'recall': 0.25650557620817843, 'f1-score': 0.3556701030927835, 'support': 269.0}, 'Class_5': {'precision': 0.9345454545454546, 'recall': 0.9379562043795621, 'f1-score': 0.9362477231329691, 'support': 274.0}, 'Class_6': {'precision': 0.9379061371841155, 'recall': 0.9193205944798302, 'f1-score': 0.9285203716940672, 'support': 1413.0}, 'Class_7': {'precision': 0.7090909090909091, 'recall': 0.5492957746478874, 'f1-score': 0.6190476190476191, 'support': 284.0}, 'Class_8': {'precision': 0.8936959208899876, 'recall': 0.8536009445100354, 'f1-score': 0.8731884057971014, 'support': 847.0}, 'Class_9': {'precision': 0.8271604938271605, 'recall': 0.8121212121212121, 'f1-score': 0.8195718654434251, 'support': 495.0}, 'accuracy': 0.7584033613445378, 'macro avg': {'precision': 0.7323020902731736, 'recall': 0.6853178819244552, 'f1-score': 0.6994957370059827, 'support': 6188.0}, 'weighted avg': {'precision': 0.7574334090932247, 'recall': 0.7584033613445378, 'f1-score': 0.752310854219091, 'support': 6188.0}}}\n",
      "## INICIO FOLD 3 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.758 total time=   4.0s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.758 total time=   4.0s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.757 total time=   4.2s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.767 total time=   4.0s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.764 total time=   5.0s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.752 total time=   4.3s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.752 total time=   4.1s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.754 total time=   4.1s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.764 total time=   3.8s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.761 total time=   4.2s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.750 total time=   4.2s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.751 total time=   4.7s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.750 total time=   3.9s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.755 total time=   4.3s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.754 total time=   4.5s\n",
      "## FINAL FOLD 3 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7752100840336135, 'balanced_accuracy': 0.7007424960509946, 'precision_micro': 0.7752100840336135, 'precision_macro': 0.756058713135783, 'precision_weighted': 0.7737224451791707, 'recall_micro': 0.7752100840336135, 'recall_macro': 0.7007424960509946, 'recall_weighted': 0.7752100840336135, 'f1_micro': 0.7752100840336135, 'f1_macro': 0.7181776523653624, 'f1_weighted': 0.7687716679702882, 'roc_auc_ovr_micro': 0.9542318248871077, 'roc_auc_ovo_micro': 0.9542318248871077, 'roc_auc_ovr_macro': 0.9264431502370538, 'roc_auc_ovo_macro': 0.9264431502370538, 'roc_auc_ovr_weighted': 0.9393511964743346, 'roc_auc_ovo_weighted': 0.9393511964743346}, 'classification_report': {'Class_1': {'precision': 0.601123595505618, 'recall': 0.5544041450777202, 'f1-score': 0.5768194070080862, 'support': 193.0}, 'Class_2': {'precision': 0.6809596733027055, 'recall': 0.8275434243176178, 'f1-score': 0.7471296555586671, 'support': 1612.0}, 'Class_3': {'precision': 0.5394190871369294, 'recall': 0.4868913857677903, 'f1-score': 0.5118110236220473, 'support': 801.0}, 'Class_4': {'precision': 0.6293103448275862, 'recall': 0.27137546468401486, 'f1-score': 0.3792207792207792, 'support': 269.0}, 'Class_5': {'precision': 0.9395017793594306, 'recall': 0.9635036496350365, 'f1-score': 0.9513513513513514, 'support': 274.0}, 'Class_6': {'precision': 0.9391117478510028, 'recall': 0.9278131634819533, 'f1-score': 0.9334282662869348, 'support': 1413.0}, 'Class_7': {'precision': 0.7293577981651376, 'recall': 0.5598591549295775, 'f1-score': 0.6334661354581673, 'support': 284.0}, 'Class_8': {'precision': 0.9008464328899637, 'recall': 0.8806146572104019, 'f1-score': 0.8906156604901375, 'support': 846.0}, 'Class_9': {'precision': 0.8448979591836735, 'recall': 0.8346774193548387, 'f1-score': 0.8397565922920893, 'support': 496.0}, 'accuracy': 0.7752100840336135, 'macro avg': {'precision': 0.756058713135783, 'recall': 0.7007424960509946, 'f1-score': 0.7181776523653624, 'support': 6188.0}, 'weighted avg': {'precision': 0.7737224451791707, 'recall': 0.7752100840336135, 'f1-score': 0.7687716679702882, 'support': 6188.0}}}\n",
      "## INICIO FOLD 4 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.758 total time=   4.4s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.760 total time=   4.1s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.761 total time=   4.1s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.762 total time=   4.1s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.764 total time=   3.9s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.753 total time=   4.0s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.755 total time=   4.1s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.755 total time=   4.1s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.760 total time=   4.1s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.758 total time=   4.4s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.753 total time=   4.1s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.756 total time=   4.1s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.749 total time=   4.0s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.755 total time=   4.0s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.755 total time=   3.9s\n",
      "## FINAL FOLD 4 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7847446670976083, 'balanced_accuracy': 0.7071901175616736, 'precision_micro': 0.7847446670976083, 'precision_macro': 0.7651035373320122, 'precision_weighted': 0.7826430366515397, 'recall_micro': 0.7847446670976083, 'recall_macro': 0.7071901175616736, 'recall_weighted': 0.7847446670976083, 'f1_micro': 0.7847446670976083, 'f1_macro': 0.7261667439520055, 'f1_weighted': 0.7779674172991606, 'roc_auc_ovr_micro': 0.9548997467286602, 'roc_auc_ovo_micro': 0.9548997467286602, 'roc_auc_ovr_macro': 0.9269552680587538, 'roc_auc_ovo_macro': 0.9269552680587538, 'roc_auc_ovr_weighted': 0.9407409217189135, 'roc_auc_ovo_weighted': 0.9407409217189135}, 'classification_report': {'Class_1': {'precision': 0.5961538461538461, 'recall': 0.48186528497409326, 'f1-score': 0.5329512893982807, 'support': 193.0}, 'Class_2': {'precision': 0.6974619289340102, 'recall': 0.8523573200992556, 'f1-score': 0.7671691792294807, 'support': 1612.0}, 'Class_3': {'precision': 0.5588652482269504, 'recall': 0.4918851435705368, 'f1-score': 0.5232403718459495, 'support': 801.0}, 'Class_4': {'precision': 0.6774193548387096, 'recall': 0.31226765799256506, 'f1-score': 0.42748091603053434, 'support': 269.0}, 'Class_5': {'precision': 0.9405594405594405, 'recall': 0.9817518248175182, 'f1-score': 0.9607142857142856, 'support': 274.0}, 'Class_6': {'precision': 0.9378127233738385, 'recall': 0.9285208775654635, 'f1-score': 0.9331436699857752, 'support': 1413.0}, 'Class_7': {'precision': 0.7191489361702128, 'recall': 0.5950704225352113, 'f1-score': 0.651252408477842, 'support': 284.0}, 'Class_8': {'precision': 0.898428053204353, 'recall': 0.8782505910165485, 'f1-score': 0.8882247459653317, 'support': 846.0}, 'Class_9': {'precision': 0.8600823045267489, 'recall': 0.842741935483871, 'f1-score': 0.8513238289205702, 'support': 496.0}, 'accuracy': 0.7847446670976083, 'macro avg': {'precision': 0.7651035373320122, 'recall': 0.7071901175616736, 'f1-score': 0.7261667439520055, 'support': 6188.0}, 'weighted avg': {'precision': 0.7826430366515397, 'recall': 0.7847446670976083, 'f1-score': 0.7779674172991606, 'support': 6188.0}}}\n",
      "## INICIO FOLD 5 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.760 total time=   3.7s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.759 total time=   4.2s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.757 total time=   4.1s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.768 total time=   4.1s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.764 total time=   4.3s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.755 total time=   4.2s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.757 total time=   4.0s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.753 total time=   4.4s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.761 total time=   4.1s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.758 total time=   4.3s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.755 total time=   4.3s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.753 total time=   3.9s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.749 total time=   4.0s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.762 total time=   4.3s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.753 total time=   4.0s\n",
      "## FINAL FOLD 5 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7692307692307693, 'balanced_accuracy': 0.6915704665710335, 'precision_micro': 0.7692307692307693, 'precision_macro': 0.7498599215704576, 'precision_weighted': 0.7666291047287005, 'recall_micro': 0.7692307692307693, 'recall_macro': 0.6915704665710335, 'recall_weighted': 0.7692307692307693, 'f1_micro': 0.7692307692307693, 'f1_macro': 0.7099780096970183, 'f1_weighted': 0.7621573983859411, 'roc_auc_ovr_micro': 0.9520233606843365, 'roc_auc_ovo_micro': 0.9520233606843365, 'roc_auc_ovr_macro': 0.9242119237727151, 'roc_auc_ovo_macro': 0.9242119237727151, 'roc_auc_ovr_weighted': 0.93617965560962, 'roc_auc_ovo_weighted': 0.93617965560962}, 'classification_report': {'Class_1': {'precision': 0.5857988165680473, 'recall': 0.5129533678756477, 'f1-score': 0.5469613259668508, 'support': 193.0}, 'Class_2': {'precision': 0.6812114989733059, 'recall': 0.8232009925558312, 'f1-score': 0.745505617977528, 'support': 1612.0}, 'Class_3': {'precision': 0.5255172413793103, 'recall': 0.47625, 'f1-score': 0.49967213114754094, 'support': 800.0}, 'Class_4': {'precision': 0.6371681415929203, 'recall': 0.26666666666666666, 'f1-score': 0.37597911227154046, 'support': 270.0}, 'Class_5': {'precision': 0.9422382671480144, 'recall': 0.9560439560439561, 'f1-score': 0.9490909090909091, 'support': 273.0}, 'Class_6': {'precision': 0.9278642149929278, 'recall': 0.9278642149929278, 'f1-score': 0.9278642149929278, 'support': 1414.0}, 'Class_7': {'precision': 0.7136363636363636, 'recall': 0.5528169014084507, 'f1-score': 0.623015873015873, 'support': 284.0}, 'Class_8': {'precision': 0.8790419161676647, 'recall': 0.8676122931442081, 'f1-score': 0.8732897085068413, 'support': 846.0}, 'Class_9': {'precision': 0.8562628336755647, 'recall': 0.8407258064516129, 'f1-score': 0.8484231943031536, 'support': 496.0}, 'accuracy': 0.7692307692307693, 'macro avg': {'precision': 0.7498599215704576, 'recall': 0.6915704665710335, 'f1-score': 0.7099780096970183, 'support': 6188.0}, 'weighted avg': {'precision': 0.7666291047287005, 'recall': 0.7692307692307693, 'f1-score': 0.7621573983859411, 'support': 6188.0}}}\n",
      "## INICIO FOLD 6 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.755 total time=   4.5s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.756 total time=   4.0s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.753 total time=   4.5s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.764 total time=   3.9s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.764 total time=   4.2s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.750 total time=   4.0s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.752 total time=   4.5s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.753 total time=   4.1s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.760 total time=   4.1s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.758 total time=   3.8s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.750 total time=   4.0s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.750 total time=   4.2s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.748 total time=   4.3s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.759 total time=   4.0s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.758 total time=   4.2s\n",
      "## FINAL FOLD 6 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7729476405946994, 'balanced_accuracy': 0.7047515586732889, 'precision_micro': 0.7729476405946994, 'precision_macro': 0.7524886188407044, 'precision_weighted': 0.7710669606688403, 'recall_micro': 0.7729476405946994, 'recall_macro': 0.7047515586732889, 'recall_weighted': 0.7729476405946994, 'f1_micro': 0.7729476405946994, 'f1_macro': 0.7220068179567997, 'f1_weighted': 0.7680102608807666, 'roc_auc_ovr_micro': 0.9535616652682652, 'roc_auc_ovo_micro': 0.9535616652682652, 'roc_auc_ovr_macro': 0.9276744388670577, 'roc_auc_ovo_macro': 0.9276744388670577, 'roc_auc_ovr_weighted': 0.9387244751827313, 'roc_auc_ovo_weighted': 0.9387244751827313}, 'classification_report': {'Class_1': {'precision': 0.5780346820809249, 'recall': 0.5181347150259067, 'f1-score': 0.546448087431694, 'support': 193.0}, 'Class_2': {'precision': 0.6824570536179073, 'recall': 0.8132754342431762, 'f1-score': 0.7421454854231532, 'support': 1612.0}, 'Class_3': {'precision': 0.5350140056022409, 'recall': 0.4775, 'f1-score': 0.5046235138705416, 'support': 800.0}, 'Class_4': {'precision': 0.6506849315068494, 'recall': 0.35315985130111527, 'f1-score': 0.45783132530120485, 'support': 269.0}, 'Class_5': {'precision': 0.9321428571428572, 'recall': 0.9525547445255474, 'f1-score': 0.9422382671480145, 'support': 274.0}, 'Class_6': {'precision': 0.9272598870056498, 'recall': 0.9285714285714286, 'f1-score': 0.9279151943462897, 'support': 1414.0}, 'Class_7': {'precision': 0.7008547008547008, 'recall': 0.5774647887323944, 'f1-score': 0.6332046332046333, 'support': 284.0}, 'Class_8': {'precision': 0.9003690036900369, 'recall': 0.8652482269503546, 'f1-score': 0.8824593128390598, 'support': 846.0}, 'Class_9': {'precision': 0.8655804480651731, 'recall': 0.8568548387096774, 'f1-score': 0.8611955420466059, 'support': 496.0}, 'accuracy': 0.7729476405946994, 'macro avg': {'precision': 0.7524886188407044, 'recall': 0.7047515586732889, 'f1-score': 0.7220068179567997, 'support': 6188.0}, 'weighted avg': {'precision': 0.7710669606688403, 'recall': 0.7729476405946994, 'f1-score': 0.7680102608807666, 'support': 6188.0}}}\n",
      "## INICIO FOLD 7 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.757 total time=   4.5s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.762 total time=   4.3s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.758 total time=   4.3s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.763 total time=   4.2s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.763 total time=   3.9s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.750 total time=   4.2s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.754 total time=   4.2s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.757 total time=   4.1s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.761 total time=   4.3s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.762 total time=   4.2s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.750 total time=   4.1s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.755 total time=   4.2s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.753 total time=   4.4s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.760 total time=   4.1s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.755 total time=   4.3s\n",
      "## FINAL FOLD 7 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7739172592113769, 'balanced_accuracy': 0.7077399748085533, 'precision_micro': 0.7739172592113769, 'precision_macro': 0.7692904757112762, 'precision_weighted': 0.775872977823879, 'recall_micro': 0.7739172592113769, 'recall_macro': 0.7077399748085533, 'recall_weighted': 0.7739172592113769, 'f1_micro': 0.7739172592113769, 'f1_macro': 0.7266044579323425, 'f1_weighted': 0.768172424321502, 'roc_auc_ovr_micro': 0.9532978066792327, 'roc_auc_ovo_micro': 0.9532978066792327, 'roc_auc_ovr_macro': 0.9275104122779838, 'roc_auc_ovo_macro': 0.9275104122779838, 'roc_auc_ovr_weighted': 0.9376051823575932, 'roc_auc_ovo_weighted': 0.9376051823575932}, 'classification_report': {'Class_1': {'precision': 0.5977653631284916, 'recall': 0.5544041450777202, 'f1-score': 0.5752688172043011, 'support': 193.0}, 'Class_2': {'precision': 0.6671679197994987, 'recall': 0.825682382133995, 'f1-score': 0.7380094261158858, 'support': 1612.0}, 'Class_3': {'precision': 0.5271428571428571, 'recall': 0.46125, 'f1-score': 0.49200000000000005, 'support': 800.0}, 'Class_4': {'precision': 0.7129629629629629, 'recall': 0.2862453531598513, 'f1-score': 0.4084880636604774, 'support': 269.0}, 'Class_5': {'precision': 0.9633699633699634, 'recall': 0.9598540145985401, 'f1-score': 0.9616087751371114, 'support': 274.0}, 'Class_6': {'precision': 0.9373198847262247, 'recall': 0.92008486562942, 'f1-score': 0.9286224125624554, 'support': 1414.0}, 'Class_7': {'precision': 0.7448559670781894, 'recall': 0.6373239436619719, 'f1-score': 0.6869070208728653, 'support': 284.0}, 'Class_8': {'precision': 0.9041769041769042, 'recall': 0.8699763593380615, 'f1-score': 0.8867469879518072, 'support': 846.0}, 'Class_9': {'precision': 0.8688524590163934, 'recall': 0.8548387096774194, 'f1-score': 0.8617886178861789, 'support': 496.0}, 'accuracy': 0.7739172592113769, 'macro avg': {'precision': 0.7692904757112762, 'recall': 0.7077399748085533, 'f1-score': 0.7266044579323425, 'support': 6188.0}, 'weighted avg': {'precision': 0.775872977823879, 'recall': 0.7739172592113769, 'f1-score': 0.768172424321502, 'support': 6188.0}}}\n",
      "## INICIO FOLD 8 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.758 total time=   4.2s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.761 total time=   4.1s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.756 total time=   4.1s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.763 total time=   4.1s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.761 total time=   4.0s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.753 total time=   4.0s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.757 total time=   4.3s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.754 total time=   4.3s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.761 total time=   4.4s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.758 total time=   4.2s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.756 total time=   4.0s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.754 total time=   4.5s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.752 total time=   3.9s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.762 total time=   4.4s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.754 total time=   4.2s\n",
      "## FINAL FOLD 8 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.769031840956845, 'balanced_accuracy': 0.6876916323828011, 'precision_micro': 0.769031840956845, 'precision_macro': 0.7437763138815457, 'precision_weighted': 0.7657570292765582, 'recall_micro': 0.769031840956845, 'recall_macro': 0.6876916323828011, 'recall_weighted': 0.769031840956845, 'f1_micro': 0.769031840956845, 'f1_macro': 0.7041268719825668, 'f1_weighted': 0.7615447946983509, 'roc_auc_ovr_micro': 0.9487407236595112, 'roc_auc_ovo_micro': 0.9487407236595112, 'roc_auc_ovr_macro': 0.9161411475040718, 'roc_auc_ovo_macro': 0.9161411475040718, 'roc_auc_ovr_weighted': 0.9334497681722753, 'roc_auc_ovo_weighted': 0.9334497681722753}, 'classification_report': {'Class_1': {'precision': 0.5764705882352941, 'recall': 0.5077720207253886, 'f1-score': 0.5399449035812672, 'support': 193.0}, 'Class_2': {'precision': 0.683991683991684, 'recall': 0.8163771712158809, 'f1-score': 0.744343891402715, 'support': 1612.0}, 'Class_3': {'precision': 0.5271523178807948, 'recall': 0.4975, 'f1-score': 0.5118971061093248, 'support': 800.0}, 'Class_4': {'precision': 0.6060606060606061, 'recall': 0.22304832713754646, 'f1-score': 0.3260869565217392, 'support': 269.0}, 'Class_5': {'precision': 0.9601449275362319, 'recall': 0.9671532846715328, 'f1-score': 0.9636363636363637, 'support': 274.0}, 'Class_6': {'precision': 0.9289267945984364, 'recall': 0.9243281471004243, 'f1-score': 0.9266217653314427, 'support': 1414.0}, 'Class_7': {'precision': 0.6710526315789473, 'recall': 0.5387323943661971, 'f1-score': 0.59765625, 'support': 284.0}, 'Class_8': {'precision': 0.8848413631022327, 'recall': 0.8900709219858156, 'f1-score': 0.8874484384207425, 'support': 846.0}, 'Class_9': {'precision': 0.8553459119496856, 'recall': 0.8242424242424242, 'f1-score': 0.8395061728395062, 'support': 495.0}, 'accuracy': 0.769031840956845, 'macro avg': {'precision': 0.7437763138815457, 'recall': 0.6876916323828011, 'f1-score': 0.7041268719825668, 'support': 6187.0}, 'weighted avg': {'precision': 0.7657570292765582, 'recall': 0.769031840956845, 'f1-score': 0.7615447946983509, 'support': 6187.0}}}\n",
      "## INICIO FOLD 9 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.755 total time=   4.1s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.762 total time=   4.0s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.757 total time=   4.2s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.769 total time=   4.0s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.761 total time=   4.1s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.752 total time=   4.0s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.755 total time=   4.0s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.751 total time=   4.1s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.763 total time=   4.0s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.759 total time=   4.0s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.750 total time=   4.0s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.755 total time=   4.1s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.750 total time=   4.4s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.761 total time=   3.9s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.755 total time=   4.0s\n",
      "## FINAL FOLD 9 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7759818975270729, 'balanced_accuracy': 0.6996436397132134, 'precision_micro': 0.7759818975270729, 'precision_macro': 0.7570892678247078, 'precision_weighted': 0.7740721643029415, 'recall_micro': 0.7759818975270729, 'recall_macro': 0.6996436397132134, 'recall_weighted': 0.7759818975270729, 'f1_micro': 0.7759818975270729, 'f1_macro': 0.7172292825171459, 'f1_weighted': 0.7687800697953733, 'roc_auc_ovr_micro': 0.9557214775690536, 'roc_auc_ovo_micro': 0.9557214775690536, 'roc_auc_ovr_macro': 0.9289602989931784, 'roc_auc_ovo_macro': 0.9289602989931784, 'roc_auc_ovr_weighted': 0.9404128540019802, 'roc_auc_ovo_weighted': 0.9404128540019802}, 'classification_report': {'Class_1': {'precision': 0.5647668393782384, 'recall': 0.5677083333333334, 'f1-score': 0.5662337662337663, 'support': 192.0}, 'Class_2': {'precision': 0.6829020801623541, 'recall': 0.8344699318040918, 'f1-score': 0.7511160714285714, 'support': 1613.0}, 'Class_3': {'precision': 0.5314285714285715, 'recall': 0.465, 'f1-score': 0.4960000000000001, 'support': 800.0}, 'Class_4': {'precision': 0.631578947368421, 'recall': 0.26765799256505574, 'f1-score': 0.3759791122715404, 'support': 269.0}, 'Class_5': {'precision': 0.9388489208633094, 'recall': 0.9525547445255474, 'f1-score': 0.9456521739130435, 'support': 274.0}, 'Class_6': {'precision': 0.9321074964639321, 'recall': 0.9321074964639321, 'f1-score': 0.9321074964639321, 'support': 1414.0}, 'Class_7': {'precision': 0.7621359223300971, 'recall': 0.5547703180212014, 'f1-score': 0.6421267893660533, 'support': 283.0}, 'Class_8': {'precision': 0.9008363201911589, 'recall': 0.8902007083825265, 'f1-score': 0.8954869358669834, 'support': 847.0}, 'Class_9': {'precision': 0.869198312236287, 'recall': 0.8323232323232324, 'f1-score': 0.8503611971104231, 'support': 495.0}, 'accuracy': 0.7759818975270729, 'macro avg': {'precision': 0.7570892678247078, 'recall': 0.6996436397132134, 'f1-score': 0.7172292825171459, 'support': 6187.0}, 'weighted avg': {'precision': 0.7740721643029415, 'recall': 0.7759818975270729, 'f1-score': 0.7687800697953733, 'support': 6187.0}}}\n"
     ]
    }
   ],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"n_neighbors\": [5, 10, 15]\n",
    "}\n",
    "# define o modelo\n",
    "model = KNeighborsClassifier(n_jobs=1)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: KNN_smote\n",
      "## INICIO FOLD 0 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.874 total time=  23.0s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.875 total time=  22.1s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.888 total time=  22.2s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.903 total time=  22.3s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.903 total time=  22.1s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.842 total time=  21.6s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.850 total time=  22.0s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.861 total time=  21.6s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.873 total time=  21.5s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.870 total time=  22.2s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.822 total time=  21.6s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.834 total time=  21.6s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.844 total time=  21.3s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.854 total time=  22.2s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.852 total time=  22.6s\n",
      "## FINAL FOLD 0 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7317388493859082, 'balanced_accuracy': 0.7495735370512586, 'precision_micro': 0.7317388493859082, 'precision_macro': 0.6852403480970336, 'precision_weighted': 0.7722697913399149, 'recall_micro': 0.7317388493859082, 'recall_macro': 0.7495735370512586, 'recall_weighted': 0.7317388493859082, 'f1_micro': 0.7317388493859082, 'f1_macro': 0.7042827831266973, 'f1_weighted': 0.742296461243722, 'roc_auc_ovr_micro': 0.9241127903476045, 'roc_auc_ovo_micro': 0.9241127903476045, 'roc_auc_ovr_macro': 0.9164024311205529, 'roc_auc_ovo_macro': 0.9164024311205529, 'roc_auc_ovr_weighted': 0.9164367154180246, 'roc_auc_ovo_weighted': 0.9164367154180246}, 'classification_report': {'Class_1': {'precision': 0.4551282051282051, 'recall': 0.7357512953367875, 'f1-score': 0.5623762376237624, 'support': 193.0}, 'Class_2': {'precision': 0.7932816537467701, 'recall': 0.5709857408555487, 'f1-score': 0.6640230713770728, 'support': 1613.0}, 'Class_3': {'precision': 0.4891416752843847, 'recall': 0.59125, 'f1-score': 0.5353706847764573, 'support': 800.0}, 'Class_4': {'precision': 0.3359683794466403, 'recall': 0.6319702602230484, 'f1-score': 0.43870967741935485, 'support': 269.0}, 'Class_5': {'precision': 0.8725490196078431, 'recall': 0.9744525547445255, 'f1-score': 0.9206896551724137, 'support': 274.0}, 'Class_6': {'precision': 0.9667721518987342, 'recall': 0.86482661004954, 'f1-score': 0.9129622711991034, 'support': 1413.0}, 'Class_7': {'precision': 0.5284552845528455, 'recall': 0.6866197183098591, 'f1-score': 0.5972434915773354, 'support': 284.0}, 'Class_8': {'precision': 0.9096612296110415, 'recall': 0.8559622195985832, 'f1-score': 0.8819951338199512, 'support': 847.0}, 'Class_9': {'precision': 0.8162055335968379, 'recall': 0.8343434343434344, 'f1-score': 0.8251748251748252, 'support': 495.0}, 'accuracy': 0.7317388493859082, 'macro avg': {'precision': 0.6852403480970336, 'recall': 0.7495735370512586, 'f1-score': 0.7042827831266973, 'support': 6188.0}, 'weighted avg': {'precision': 0.7722697913399149, 'recall': 0.7317388493859082, 'f1-score': 0.742296461243722, 'support': 6188.0}}}\n",
      "## INICIO FOLD 1 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.872 total time=  22.7s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.875 total time=  21.3s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.890 total time=  22.8s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.901 total time=  22.0s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.901 total time=  21.5s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.838 total time=  21.7s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.849 total time=  21.0s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.863 total time=  22.5s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.871 total time=  22.4s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.872 total time=  21.7s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.818 total time=  22.2s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.832 total time=  22.4s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.846 total time=  22.6s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.851 total time=  22.3s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.853 total time=  22.0s\n",
      "## FINAL FOLD 1 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7417582417582418, 'balanced_accuracy': 0.7543724466081041, 'precision_micro': 0.7417582417582418, 'precision_macro': 0.6944232490871154, 'precision_weighted': 0.7819636585143084, 'recall_micro': 0.7417582417582418, 'recall_macro': 0.7543724466081041, 'recall_weighted': 0.7417582417582418, 'f1_micro': 0.7417582417582419, 'f1_macro': 0.7121091675463903, 'f1_weighted': 0.752361346112138, 'roc_auc_ovr_micro': 0.9260792073529726, 'roc_auc_ovo_micro': 0.9260792073529726, 'roc_auc_ovr_macro': 0.9159482802653132, 'roc_auc_ovo_macro': 0.9159482802653132, 'roc_auc_ovr_weighted': 0.9185175929885805, 'roc_auc_ovo_weighted': 0.9185175929885805}, 'classification_report': {'Class_1': {'precision': 0.44339622641509435, 'recall': 0.7305699481865285, 'f1-score': 0.5518590998043053, 'support': 193.0}, 'Class_2': {'precision': 0.8090753424657534, 'recall': 0.5862282878411911, 'f1-score': 0.6798561151079136, 'support': 1612.0}, 'Class_3': {'precision': 0.4916584887144259, 'recall': 0.6254681647940075, 'f1-score': 0.5505494505494506, 'support': 801.0}, 'Class_4': {'precision': 0.3540772532188841, 'recall': 0.6133828996282528, 'f1-score': 0.4489795918367347, 'support': 269.0}, 'Class_5': {'precision': 0.8741935483870967, 'recall': 0.9890510948905109, 'f1-score': 0.9280821917808219, 'support': 274.0}, 'Class_6': {'precision': 0.9712286158631416, 'recall': 0.883934890304317, 'f1-score': 0.925527973323453, 'support': 1413.0}, 'Class_7': {'precision': 0.5536723163841808, 'recall': 0.6901408450704225, 'f1-score': 0.6144200626959248, 'support': 284.0}, 'Class_8': {'precision': 0.9184993531694696, 'recall': 0.8382526564344747, 'f1-score': 0.8765432098765432, 'support': 847.0}, 'Class_9': {'precision': 0.8340080971659919, 'recall': 0.8323232323232324, 'f1-score': 0.8331648129423659, 'support': 495.0}, 'accuracy': 0.7417582417582418, 'macro avg': {'precision': 0.6944232490871154, 'recall': 0.7543724466081041, 'f1-score': 0.7121091675463903, 'support': 6188.0}, 'weighted avg': {'precision': 0.7819636585143084, 'recall': 0.7417582417582418, 'f1-score': 0.752361346112138, 'support': 6188.0}}}\n",
      "## INICIO FOLD 2 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.873 total time=  22.3s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.877 total time=  21.3s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.888 total time=  22.4s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.903 total time=  21.2s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.904 total time=  21.5s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.842 total time=  21.6s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.850 total time=  22.8s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.863 total time=  21.8s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.872 total time=  21.9s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.873 total time=  26.7s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.821 total time=  27.9s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.833 total time=  25.5s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.846 total time=  23.9s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.852 total time=  31.1s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.853 total time=  34.7s\n",
      "## FINAL FOLD 2 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7202650290885585, 'balanced_accuracy': 0.7284809878884891, 'precision_micro': 0.7202650290885585, 'precision_macro': 0.6774334113217719, 'precision_weighted': 0.7643337554010803, 'recall_micro': 0.7202650290885585, 'recall_macro': 0.7284809878884891, 'recall_weighted': 0.7202650290885585, 'f1_micro': 0.7202650290885585, 'f1_macro': 0.6910459893797359, 'f1_weighted': 0.733115658107601, 'roc_auc_ovr_micro': 0.9186948344644157, 'roc_auc_ovo_micro': 0.9186948344644157, 'roc_auc_ovr_macro': 0.9034966568711348, 'roc_auc_ovo_macro': 0.9034966568711348, 'roc_auc_ovr_weighted': 0.9100125860111906, 'roc_auc_ovo_weighted': 0.9100125860111906}, 'classification_report': {'Class_1': {'precision': 0.4123076923076923, 'recall': 0.694300518134715, 'f1-score': 0.5173745173745175, 'support': 193.0}, 'Class_2': {'precision': 0.7855319148936171, 'recall': 0.5725806451612904, 'f1-score': 0.6623609616074633, 'support': 1612.0}, 'Class_3': {'precision': 0.44921875, 'recall': 0.5742821473158551, 'f1-score': 0.5041095890410958, 'support': 801.0}, 'Class_4': {'precision': 0.31446540880503143, 'recall': 0.5576208178438662, 'f1-score': 0.4021447721179625, 'support': 269.0}, 'Class_5': {'precision': 0.8969072164948454, 'recall': 0.9525547445255474, 'f1-score': 0.9238938053097345, 'support': 274.0}, 'Class_6': {'precision': 0.9644549763033176, 'recall': 0.8641188959660298, 'f1-score': 0.9115341545352744, 'support': 1413.0}, 'Class_7': {'precision': 0.5449438202247191, 'recall': 0.6830985915492958, 'f1-score': 0.6062500000000001, 'support': 284.0}, 'Class_8': {'precision': 0.9097938144329897, 'recall': 0.833530106257379, 'f1-score': 0.8699938385705484, 'support': 847.0}, 'Class_9': {'precision': 0.8192771084337349, 'recall': 0.8242424242424242, 'f1-score': 0.8217522658610271, 'support': 495.0}, 'accuracy': 0.7202650290885585, 'macro avg': {'precision': 0.6774334113217719, 'recall': 0.7284809878884891, 'f1-score': 0.6910459893797359, 'support': 6188.0}, 'weighted avg': {'precision': 0.7643337554010803, 'recall': 0.7202650290885585, 'f1-score': 0.733115658107601, 'support': 6188.0}}}\n",
      "## INICIO FOLD 3 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.869 total time=  34.4s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.876 total time=  33.0s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.888 total time=  31.5s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.902 total time=  33.3s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.902 total time=  32.5s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.840 total time=  35.4s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.849 total time=  33.7s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.860 total time=  34.5s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.872 total time=  33.5s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.868 total time=  34.6s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.820 total time=  28.2s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.832 total time=  36.2s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.843 total time=  33.3s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.853 total time=  33.6s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.848 total time=  33.2s\n",
      "## FINAL FOLD 3 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.731415643180349, 'balanced_accuracy': 0.750364758539511, 'precision_micro': 0.731415643180349, 'precision_macro': 0.69110552685963, 'precision_weighted': 0.7795598826674902, 'recall_micro': 0.731415643180349, 'recall_macro': 0.750364758539511, 'recall_weighted': 0.731415643180349, 'f1_micro': 0.731415643180349, 'f1_macro': 0.7063585000194494, 'f1_weighted': 0.7436001308594579, 'roc_auc_ovr_micro': 0.9252620807720932, 'roc_auc_ovo_micro': 0.9252620807720932, 'roc_auc_ovr_macro': 0.9169100085969135, 'roc_auc_ovo_macro': 0.9169100085969135, 'roc_auc_ovr_weighted': 0.9176509531754158, 'roc_auc_ovo_weighted': 0.9176509531754158}, 'classification_report': {'Class_1': {'precision': 0.44025157232704404, 'recall': 0.7253886010362695, 'f1-score': 0.547945205479452, 'support': 193.0}, 'Class_2': {'precision': 0.8165304268846503, 'recall': 0.5576923076923077, 'f1-score': 0.6627349797272392, 'support': 1612.0}, 'Class_3': {'precision': 0.47297297297297297, 'recall': 0.6117353308364545, 'f1-score': 0.5334784975503539, 'support': 801.0}, 'Class_4': {'precision': 0.31679389312977096, 'recall': 0.6171003717472119, 'f1-score': 0.41866330390920553, 'support': 269.0}, 'Class_5': {'precision': 0.8963210702341137, 'recall': 0.9781021897810219, 'f1-score': 0.9354275741710296, 'support': 274.0}, 'Class_6': {'precision': 0.9645110410094637, 'recall': 0.8655343241330502, 'f1-score': 0.9123461395001865, 'support': 1413.0}, 'Class_7': {'precision': 0.5726495726495726, 'recall': 0.7077464788732394, 'f1-score': 0.6330708661417322, 'support': 284.0}, 'Class_8': {'precision': 0.9272959183673469, 'recall': 0.859338061465721, 'f1-score': 0.8920245398773006, 'support': 846.0}, 'Class_9': {'precision': 0.8126232741617357, 'recall': 0.8306451612903226, 'f1-score': 0.8215353938185445, 'support': 496.0}, 'accuracy': 0.731415643180349, 'macro avg': {'precision': 0.69110552685963, 'recall': 0.750364758539511, 'f1-score': 0.7063585000194494, 'support': 6188.0}, 'weighted avg': {'precision': 0.7795598826674902, 'recall': 0.731415643180349, 'f1-score': 0.7436001308594579, 'support': 6188.0}}}\n",
      "## INICIO FOLD 4 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.870 total time=  33.5s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.877 total time=  32.7s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.888 total time=  32.7s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.903 total time=  35.5s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.903 total time=  33.7s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.840 total time=  32.7s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.851 total time=  32.0s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.858 total time=  33.6s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.871 total time=  32.2s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.873 total time=  32.4s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.819 total time=  32.5s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.834 total time=  30.3s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.839 total time=  31.9s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.851 total time=  30.9s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.853 total time=  35.2s\n",
      "## FINAL FOLD 4 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7236586942469295, 'balanced_accuracy': 0.7310431887049244, 'precision_micro': 0.7236586942469295, 'precision_macro': 0.6782890919890305, 'precision_weighted': 0.7679629250620121, 'recall_micro': 0.7236586942469295, 'recall_macro': 0.7310431887049244, 'recall_weighted': 0.7236586942469295, 'f1_micro': 0.7236586942469295, 'f1_macro': 0.6924199337018992, 'f1_weighted': 0.7356239568295228, 'roc_auc_ovr_micro': 0.922476201475195, 'roc_auc_ovo_micro': 0.922476201475195, 'roc_auc_ovr_macro': 0.9094539714840744, 'roc_auc_ovo_macro': 0.9094539714840744, 'roc_auc_ovr_weighted': 0.9151724834538528, 'roc_auc_ovo_weighted': 0.9151724834538528}, 'classification_report': {'Class_1': {'precision': 0.4084967320261438, 'recall': 0.6476683937823834, 'f1-score': 0.501002004008016, 'support': 193.0}, 'Class_2': {'precision': 0.8035087719298246, 'recall': 0.5682382133995038, 'f1-score': 0.6656976744186047, 'support': 1612.0}, 'Class_3': {'precision': 0.46507177033492825, 'recall': 0.6067415730337079, 'f1-score': 0.5265438786565547, 'support': 801.0}, 'Class_4': {'precision': 0.3253012048192771, 'recall': 0.6022304832713755, 'f1-score': 0.4224250325945242, 'support': 269.0}, 'Class_5': {'precision': 0.8562300319488818, 'recall': 0.9781021897810219, 'f1-score': 0.9131175468483818, 'support': 274.0}, 'Class_6': {'precision': 0.9577464788732394, 'recall': 0.8662420382165605, 'f1-score': 0.9096989966555185, 'support': 1413.0}, 'Class_7': {'precision': 0.5650887573964497, 'recall': 0.6725352112676056, 'f1-score': 0.6141479099678456, 'support': 284.0}, 'Class_8': {'precision': 0.899873257287706, 'recall': 0.8392434988179669, 'f1-score': 0.8685015290519879, 'support': 846.0}, 'Class_9': {'precision': 0.8232848232848233, 'recall': 0.7983870967741935, 'f1-score': 0.8106448311156602, 'support': 496.0}, 'accuracy': 0.7236586942469295, 'macro avg': {'precision': 0.6782890919890305, 'recall': 0.7310431887049244, 'f1-score': 0.6924199337018992, 'support': 6188.0}, 'weighted avg': {'precision': 0.7679629250620121, 'recall': 0.7236586942469295, 'f1-score': 0.7356239568295228, 'support': 6188.0}}}\n",
      "## INICIO FOLD 5 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.871 total time=  33.8s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.878 total time=  32.3s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.891 total time=  27.7s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.903 total time=  21.3s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.902 total time=  21.4s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.841 total time=  21.6s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.849 total time=  22.2s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.861 total time=  21.8s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.874 total time=  21.6s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.870 total time=  21.3s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.821 total time=  21.0s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.833 total time=  21.9s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.844 total time=  21.4s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.854 total time=  22.4s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.851 total time=  21.3s\n",
      "## FINAL FOLD 5 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7210730446024564, 'balanced_accuracy': 0.7329644260164145, 'precision_micro': 0.7210730446024564, 'precision_macro': 0.678880821881492, 'precision_weighted': 0.7630911855246674, 'recall_micro': 0.7210730446024564, 'recall_macro': 0.7329644260164145, 'recall_weighted': 0.7210730446024564, 'f1_micro': 0.7210730446024564, 'f1_macro': 0.6940797920741202, 'f1_weighted': 0.7322155104638765, 'roc_auc_ovr_micro': 0.9200838053634263, 'roc_auc_ovo_micro': 0.9200838053634263, 'roc_auc_ovr_macro': 0.9072141374763907, 'roc_auc_ovo_macro': 0.9072141374763907, 'roc_auc_ovr_weighted': 0.9115219067552373, 'roc_auc_ovo_weighted': 0.9115219067552373}, 'classification_report': {'Class_1': {'precision': 0.4440894568690096, 'recall': 0.7202072538860104, 'f1-score': 0.549407114624506, 'support': 193.0}, 'Class_2': {'precision': 0.7917398945518453, 'recall': 0.5589330024813896, 'f1-score': 0.6552727272727272, 'support': 1612.0}, 'Class_3': {'precision': 0.4478468899521531, 'recall': 0.585, 'f1-score': 0.5073170731707317, 'support': 800.0}, 'Class_4': {'precision': 0.33617021276595743, 'recall': 0.5851851851851851, 'f1-score': 0.427027027027027, 'support': 270.0}, 'Class_5': {'precision': 0.902027027027027, 'recall': 0.978021978021978, 'f1-score': 0.9384885764499121, 'support': 273.0}, 'Class_6': {'precision': 0.9571651090342679, 'recall': 0.8691654879773691, 'f1-score': 0.911045218680504, 'support': 1414.0}, 'Class_7': {'precision': 0.5185185185185185, 'recall': 0.6408450704225352, 'f1-score': 0.573228346456693, 'support': 284.0}, 'Class_8': {'precision': 0.8991172761664565, 'recall': 0.8427895981087471, 'f1-score': 0.8700427089688836, 'support': 846.0}, 'Class_9': {'precision': 0.8132530120481928, 'recall': 0.8165322580645161, 'f1-score': 0.8148893360160966, 'support': 496.0}, 'accuracy': 0.7210730446024564, 'macro avg': {'precision': 0.678880821881492, 'recall': 0.7329644260164145, 'f1-score': 0.6940797920741202, 'support': 6188.0}, 'weighted avg': {'precision': 0.7630911855246674, 'recall': 0.7210730446024564, 'f1-score': 0.7322155104638765, 'support': 6188.0}}}\n",
      "## INICIO FOLD 6 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.869 total time=  21.8s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.875 total time=  21.4s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.885 total time=  21.2s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.905 total time=  21.8s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.903 total time=  21.7s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.840 total time=  21.0s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.850 total time=  21.5s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.861 total time=  21.6s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.875 total time=  22.0s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.873 total time=  21.5s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.822 total time=  22.3s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.836 total time=  21.4s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.843 total time=  22.3s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.853 total time=  21.3s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.853 total time=  23.5s\n",
      "## FINAL FOLD 6 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7293148028442146, 'balanced_accuracy': 0.7462116075534571, 'precision_micro': 0.7293148028442146, 'precision_macro': 0.6869897310951383, 'precision_weighted': 0.7740610743283073, 'recall_micro': 0.7293148028442146, 'recall_macro': 0.7462116075534571, 'recall_weighted': 0.7293148028442146, 'f1_micro': 0.7293148028442146, 'f1_macro': 0.7027310895811403, 'f1_weighted': 0.74015908786195, 'roc_auc_ovr_micro': 0.9244649113778822, 'roc_auc_ovo_micro': 0.9244649113778822, 'roc_auc_ovr_macro': 0.9150192116992542, 'roc_auc_ovo_macro': 0.9150192116992542, 'roc_auc_ovr_weighted': 0.9172408878364096, 'roc_auc_ovo_weighted': 0.9172408878364096}, 'classification_report': {'Class_1': {'precision': 0.4012738853503185, 'recall': 0.6528497409326425, 'f1-score': 0.49704142011834324, 'support': 193.0}, 'Class_2': {'precision': 0.8065099457504521, 'recall': 0.5533498759305211, 'f1-score': 0.656364974245769, 'support': 1612.0}, 'Class_3': {'precision': 0.4670487106017192, 'recall': 0.61125, 'f1-score': 0.5295073091499729, 'support': 800.0}, 'Class_4': {'precision': 0.36863543788187375, 'recall': 0.6728624535315985, 'f1-score': 0.4763157894736842, 'support': 269.0}, 'Class_5': {'precision': 0.8758389261744967, 'recall': 0.9525547445255474, 'f1-score': 0.9125874125874125, 'support': 274.0}, 'Class_6': {'precision': 0.9588828549262994, 'recall': 0.8741159830268741, 'f1-score': 0.9145394006659269, 'support': 1414.0}, 'Class_7': {'precision': 0.5588235294117647, 'recall': 0.7359154929577465, 'f1-score': 0.635258358662614, 'support': 284.0}, 'Class_8': {'precision': 0.9115384615384615, 'recall': 0.8404255319148937, 'f1-score': 0.8745387453874539, 'support': 846.0}, 'Class_9': {'precision': 0.8343558282208589, 'recall': 0.8225806451612904, 'f1-score': 0.8284263959390863, 'support': 496.0}, 'accuracy': 0.7293148028442146, 'macro avg': {'precision': 0.6869897310951383, 'recall': 0.7462116075534571, 'f1-score': 0.7027310895811403, 'support': 6188.0}, 'weighted avg': {'precision': 0.7740610743283073, 'recall': 0.7293148028442146, 'f1-score': 0.74015908786195, 'support': 6188.0}}}\n",
      "## INICIO FOLD 7 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.875 total time=  21.2s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.877 total time=  21.3s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.893 total time=  22.2s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.904 total time=  21.6s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.904 total time=  21.0s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.842 total time=  21.1s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.849 total time=  21.4s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.865 total time=  21.2s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.871 total time=  21.6s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.872 total time=  21.8s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.823 total time=  22.9s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.833 total time=  21.3s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.846 total time=  21.5s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.849 total time=  22.0s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.852 total time=  21.3s\n",
      "## FINAL FOLD 7 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7317388493859082, 'balanced_accuracy': 0.7498514845498514, 'precision_micro': 0.7317388493859082, 'precision_macro': 0.689635081049302, 'precision_weighted': 0.7743103132381217, 'recall_micro': 0.7317388493859082, 'recall_macro': 0.7498514845498514, 'recall_weighted': 0.7317388493859082, 'f1_micro': 0.7317388493859082, 'f1_macro': 0.7064163946695323, 'f1_weighted': 0.7432792420478429, 'roc_auc_ovr_micro': 0.9248069893420299, 'roc_auc_ovo_micro': 0.9248069893420299, 'roc_auc_ovr_macro': 0.9144902554563807, 'roc_auc_ovo_macro': 0.9144902554563807, 'roc_auc_ovr_weighted': 0.9169049623170265, 'roc_auc_ovo_weighted': 0.9169049623170265}, 'classification_report': {'Class_1': {'precision': 0.4533333333333333, 'recall': 0.7046632124352331, 'f1-score': 0.5517241379310345, 'support': 193.0}, 'Class_2': {'precision': 0.7916666666666666, 'recall': 0.5775434243176178, 'f1-score': 0.6678622668579627, 'support': 1612.0}, 'Class_3': {'precision': 0.48416751787538304, 'recall': 0.5925, 'f1-score': 0.5328836424957841, 'support': 800.0}, 'Class_4': {'precision': 0.33659491193737767, 'recall': 0.6394052044609665, 'f1-score': 0.441025641025641, 'support': 269.0}, 'Class_5': {'precision': 0.8817567567567568, 'recall': 0.9525547445255474, 'f1-score': 0.9157894736842106, 'support': 274.0}, 'Class_6': {'precision': 0.9568627450980393, 'recall': 0.8628005657708628, 'f1-score': 0.907400520639643, 'support': 1414.0}, 'Class_7': {'precision': 0.5329949238578681, 'recall': 0.7394366197183099, 'f1-score': 0.6194690265486726, 'support': 284.0}, 'Class_8': {'precision': 0.9323607427055703, 'recall': 0.8309692671394799, 'f1-score': 0.8787499999999999, 'support': 846.0}, 'Class_9': {'precision': 0.8369781312127237, 'recall': 0.8487903225806451, 'f1-score': 0.8428428428428428, 'support': 496.0}, 'accuracy': 0.7317388493859082, 'macro avg': {'precision': 0.689635081049302, 'recall': 0.7498514845498514, 'f1-score': 0.7064163946695323, 'support': 6188.0}, 'weighted avg': {'precision': 0.7743103132381217, 'recall': 0.7317388493859082, 'f1-score': 0.7432792420478429, 'support': 6188.0}}}\n",
      "## INICIO FOLD 8 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.873 total time=  22.1s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.879 total time=  21.1s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.889 total time=  21.4s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.904 total time=  21.8s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.905 total time=  21.7s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.842 total time=  21.0s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.854 total time=  21.5s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.859 total time=  21.5s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.871 total time=  21.4s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.873 total time=  21.8s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.822 total time=  21.7s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.837 total time=  21.4s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.840 total time=  21.4s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.852 total time=  21.3s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.852 total time=  21.2s\n",
      "## FINAL FOLD 8 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.722320995636011, 'balanced_accuracy': 0.7317627075535456, 'precision_micro': 0.722320995636011, 'precision_macro': 0.6800957838840685, 'precision_weighted': 0.7646543081804325, 'recall_micro': 0.722320995636011, 'recall_macro': 0.7317627075535456, 'recall_weighted': 0.722320995636011, 'f1_micro': 0.722320995636011, 'f1_macro': 0.6941744378480587, 'f1_weighted': 0.7328271633808456, 'roc_auc_ovr_micro': 0.9208732590864712, 'roc_auc_ovo_micro': 0.9208732590864712, 'roc_auc_ovr_macro': 0.9065632660300627, 'roc_auc_ovo_macro': 0.9065632660300627, 'roc_auc_ovr_weighted': 0.9122115051475768, 'roc_auc_ovo_weighted': 0.9122115051475768}, 'classification_report': {'Class_1': {'precision': 0.451505016722408, 'recall': 0.6994818652849741, 'f1-score': 0.548780487804878, 'support': 193.0}, 'Class_2': {'precision': 0.7866786678667866, 'recall': 0.5421836228287841, 'f1-score': 0.6419390378259272, 'support': 1612.0}, 'Class_3': {'precision': 0.45722171113155474, 'recall': 0.62125, 'f1-score': 0.5267620561738209, 'support': 800.0}, 'Class_4': {'precision': 0.3369098712446352, 'recall': 0.5836431226765799, 'f1-score': 0.42721088435374144, 'support': 269.0}, 'Class_5': {'precision': 0.8866666666666667, 'recall': 0.9708029197080292, 'f1-score': 0.926829268292683, 'support': 274.0}, 'Class_6': {'precision': 0.955984555984556, 'recall': 0.8755304101838756, 'f1-score': 0.9139904023624955, 'support': 1414.0}, 'Class_7': {'precision': 0.50997150997151, 'recall': 0.6302816901408451, 'f1-score': 0.5637795275590551, 'support': 284.0}, 'Class_8': {'precision': 0.9128787878787878, 'recall': 0.8546099290780141, 'f1-score': 0.8827838827838826, 'support': 846.0}, 'Class_9': {'precision': 0.823045267489712, 'recall': 0.8080808080808081, 'f1-score': 0.8154943934760449, 'support': 495.0}, 'accuracy': 0.722320995636011, 'macro avg': {'precision': 0.6800957838840685, 'recall': 0.7317627075535456, 'f1-score': 0.6941744378480587, 'support': 6187.0}, 'weighted avg': {'precision': 0.7646543081804325, 'recall': 0.722320995636011, 'f1-score': 0.7328271633808456, 'support': 6187.0}}}\n",
      "## INICIO FOLD 9 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.870 total time=  21.8s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.877 total time=  21.6s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.890 total time=  21.9s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.901 total time=  22.1s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.904 total time=  22.9s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.838 total time=  21.9s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.851 total time=  21.3s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.862 total time=  21.6s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.871 total time=  22.5s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.872 total time=  21.7s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.820 total time=  21.9s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.832 total time=  21.5s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.844 total time=  21.9s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.851 total time=  21.7s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.852 total time=  21.8s\n",
      "## FINAL FOLD 9 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7257152093098432, 'balanced_accuracy': 0.7428581195789872, 'precision_micro': 0.7257152093098432, 'precision_macro': 0.6859116687590737, 'precision_weighted': 0.7708400505383949, 'recall_micro': 0.7257152093098432, 'recall_macro': 0.7428581195789872, 'recall_weighted': 0.7257152093098432, 'f1_micro': 0.7257152093098433, 'f1_macro': 0.6999558123894183, 'f1_weighted': 0.7375460719221869, 'roc_auc_ovr_micro': 0.9259151399166472, 'roc_auc_ovo_micro': 0.9259151399166472, 'roc_auc_ovr_macro': 0.9150670056734262, 'roc_auc_ovo_macro': 0.9150670056734262, 'roc_auc_ovr_weighted': 0.917427563833515, 'roc_auc_ovo_weighted': 0.917427563833515}, 'classification_report': {'Class_1': {'precision': 0.3778409090909091, 'recall': 0.6927083333333334, 'f1-score': 0.4889705882352942, 'support': 192.0}, 'Class_2': {'precision': 0.783641160949868, 'recall': 0.5523868567885927, 'f1-score': 0.648, 'support': 1613.0}, 'Class_3': {'precision': 0.47076023391812866, 'recall': 0.60375, 'f1-score': 0.529025191675794, 'support': 800.0}, 'Class_4': {'precision': 0.3473053892215569, 'recall': 0.6468401486988847, 'f1-score': 0.451948051948052, 'support': 269.0}, 'Class_5': {'precision': 0.8855218855218855, 'recall': 0.9598540145985401, 'f1-score': 0.9211908931698775, 'support': 274.0}, 'Class_6': {'precision': 0.963808025177026, 'recall': 0.8663366336633663, 'f1-score': 0.9124767225325886, 'support': 1414.0}, 'Class_7': {'precision': 0.5892857142857143, 'recall': 0.6996466431095406, 'f1-score': 0.6397415185783523, 'support': 283.0}, 'Class_8': {'precision': 0.9137055837563451, 'recall': 0.8500590318772137, 'f1-score': 0.8807339449541284, 'support': 847.0}, 'Class_9': {'precision': 0.8413361169102297, 'recall': 0.8141414141414142, 'f1-score': 0.8275154004106777, 'support': 495.0}, 'accuracy': 0.7257152093098432, 'macro avg': {'precision': 0.6859116687590737, 'recall': 0.7428581195789872, 'f1-score': 0.6999558123894183, 'support': 6187.0}, 'weighted avg': {'precision': 0.7708400505383949, 'recall': 0.7257152093098432, 'f1-score': 0.7375460719221869, 'support': 6187.0}}}\n"
     ]
    }
   ],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"n_neighbors\": [5, 10, 15]\n",
    "}\n",
    "# define o modelo\n",
    "model = KNeighborsClassifier(n_jobs=1)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"KNN_smote\", flag_smote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: KNN_variance_threshold\n",
      "## INICIO FOLD 0 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.758 total time=   3.6s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.764 total time=   4.2s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.760 total time=   3.6s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.769 total time=   3.6s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.763 total time=   3.9s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.756 total time=   3.7s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.764 total time=   3.4s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.757 total time=   3.5s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.767 total time=   3.4s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.756 total time=   3.9s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.751 total time=   3.6s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.762 total time=   3.8s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.752 total time=   3.5s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.765 total time=   3.6s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.757 total time=   3.6s\n",
      "## FINAL FOLD 0 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7808661926308985, 'balanced_accuracy': 0.7097505090791594, 'precision_micro': 0.7808661926308985, 'precision_macro': 0.7676396559034491, 'precision_weighted': 0.7801338562409592, 'recall_micro': 0.7808661926308985, 'recall_macro': 0.7097505090791594, 'recall_weighted': 0.7808661926308985, 'f1_micro': 0.7808661926308985, 'f1_macro': 0.7280980169554653, 'f1_weighted': 0.7743125289204548, 'roc_auc_ovr_micro': 0.9563863082215135, 'roc_auc_ovo_micro': 0.9563863082215135, 'roc_auc_ovr_macro': 0.9306685770302825, 'roc_auc_ovo_macro': 0.9306685770302825, 'roc_auc_ovr_weighted': 0.9419493792774597, 'roc_auc_ovo_weighted': 0.9419493792774597}, 'classification_report': {'Class_1': {'precision': 0.5925925925925926, 'recall': 0.5803108808290155, 'f1-score': 0.5863874345549739, 'support': 193.0}, 'Class_2': {'precision': 0.6820020222446916, 'recall': 0.8363298202107874, 'f1-score': 0.7513227513227514, 'support': 1613.0}, 'Class_3': {'precision': 0.5638766519823789, 'recall': 0.48, 'f1-score': 0.5185685347738016, 'support': 800.0}, 'Class_4': {'precision': 0.6693548387096774, 'recall': 0.30855018587360594, 'f1-score': 0.4223918575063613, 'support': 269.0}, 'Class_5': {'precision': 0.9460431654676259, 'recall': 0.9598540145985401, 'f1-score': 0.9528985507246377, 'support': 274.0}, 'Class_6': {'precision': 0.9385275196568977, 'recall': 0.9292285916489739, 'f1-score': 0.933854907539118, 'support': 1413.0}, 'Class_7': {'precision': 0.775609756097561, 'recall': 0.5598591549295775, 'f1-score': 0.6503067484662577, 'support': 284.0}, 'Class_8': {'precision': 0.8936678614097969, 'recall': 0.8831168831168831, 'f1-score': 0.8883610451306413, 'support': 847.0}, 'Class_9': {'precision': 0.8470824949698189, 'recall': 0.8505050505050505, 'f1-score': 0.8487903225806451, 'support': 495.0}, 'accuracy': 0.7808661926308985, 'macro avg': {'precision': 0.7676396559034491, 'recall': 0.7097505090791594, 'f1-score': 0.7280980169554653, 'support': 6188.0}, 'weighted avg': {'precision': 0.7801338562409592, 'recall': 0.7808661926308985, 'f1-score': 0.7743125289204548, 'support': 6188.0}}}\n",
      "## INICIO FOLD 1 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.761 total time=   4.0s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.762 total time=   3.7s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.761 total time=   3.6s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.768 total time=   3.7s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.769 total time=   3.7s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.755 total time=   3.7s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.756 total time=   3.8s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.755 total time=   3.7s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.765 total time=   3.4s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.759 total time=   3.8s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.755 total time=   3.7s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.754 total time=   3.4s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.752 total time=   3.6s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.759 total time=   3.6s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.756 total time=   3.7s\n",
      "## FINAL FOLD 1 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7794117647058824, 'balanced_accuracy': 0.7074530111351938, 'precision_micro': 0.7794117647058824, 'precision_macro': 0.7603314338172085, 'precision_weighted': 0.7768996240043977, 'recall_micro': 0.7794117647058824, 'recall_macro': 0.7074530111351938, 'recall_weighted': 0.7794117647058824, 'f1_micro': 0.7794117647058824, 'f1_macro': 0.725173707308963, 'f1_weighted': 0.7728446291312588, 'roc_auc_ovr_micro': 0.9535132470147822, 'roc_auc_ovo_micro': 0.9535132470147822, 'roc_auc_ovr_macro': 0.9276479784464716, 'roc_auc_ovo_macro': 0.9276479784464716, 'roc_auc_ovr_weighted': 0.9391087054031103, 'roc_auc_ovo_weighted': 0.9391087054031103}, 'classification_report': {'Class_1': {'precision': 0.5754189944134078, 'recall': 0.533678756476684, 'f1-score': 0.5537634408602151, 'support': 193.0}, 'Class_2': {'precision': 0.6875637104994903, 'recall': 0.836848635235732, 'f1-score': 0.7548964745383324, 'support': 1612.0}, 'Class_3': {'precision': 0.5359765051395007, 'recall': 0.4556803995006242, 'f1-score': 0.4925775978407557, 'support': 801.0}, 'Class_4': {'precision': 0.6818181818181818, 'recall': 0.3345724907063197, 'f1-score': 0.4488778054862843, 'support': 269.0}, 'Class_5': {'precision': 0.9537366548042705, 'recall': 0.9781021897810219, 'f1-score': 0.9657657657657659, 'support': 274.0}, 'Class_6': {'precision': 0.9345070422535211, 'recall': 0.9391365888181175, 'f1-score': 0.9368160960112955, 'support': 1413.0}, 'Class_7': {'precision': 0.7030567685589519, 'recall': 0.5669014084507042, 'f1-score': 0.6276803118908383, 'support': 284.0}, 'Class_8': {'precision': 0.9013398294762485, 'recall': 0.8736717827626919, 'f1-score': 0.8872901678657074, 'support': 847.0}, 'Class_9': {'precision': 0.8695652173913043, 'recall': 0.8484848484848485, 'f1-score': 0.8588957055214724, 'support': 495.0}, 'accuracy': 0.7794117647058824, 'macro avg': {'precision': 0.7603314338172085, 'recall': 0.7074530111351938, 'f1-score': 0.725173707308963, 'support': 6188.0}, 'weighted avg': {'precision': 0.7768996240043977, 'recall': 0.7794117647058824, 'f1-score': 0.7728446291312588, 'support': 6188.0}}}\n",
      "## INICIO FOLD 2 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.756 total time=   3.4s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.764 total time=   3.7s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.760 total time=   3.5s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.771 total time=   3.6s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.770 total time=   3.6s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.753 total time=   3.8s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.760 total time=   3.4s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.757 total time=   3.6s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.769 total time=   3.6s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.765 total time=   3.6s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.752 total time=   3.8s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.759 total time=   3.7s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.752 total time=   3.8s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.765 total time=   4.0s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.762 total time=   3.6s\n",
      "## FINAL FOLD 2 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7658371040723982, 'balanced_accuracy': 0.6913527089386583, 'precision_micro': 0.7658371040723982, 'precision_macro': 0.7358809151680873, 'precision_weighted': 0.7632993280401554, 'recall_micro': 0.7658371040723982, 'recall_macro': 0.6913527089386583, 'recall_weighted': 0.7658371040723982, 'f1_micro': 0.7658371040723982, 'f1_macro': 0.7051808497550757, 'f1_weighted': 0.7595580799166881, 'roc_auc_ovr_micro': 0.9501832597596992, 'roc_auc_ovo_micro': 0.9501832597596992, 'roc_auc_ovr_macro': 0.922233478826121, 'roc_auc_ovo_macro': 0.922233478826121, 'roc_auc_ovr_weighted': 0.9350119062310436, 'roc_auc_ovo_weighted': 0.9350119062310436}, 'classification_report': {'Class_1': {'precision': 0.54, 'recall': 0.5595854922279793, 'f1-score': 0.5496183206106869, 'support': 193.0}, 'Class_2': {'precision': 0.680306905370844, 'recall': 0.825062034739454, 'f1-score': 0.7457246986262966, 'support': 1612.0}, 'Class_3': {'precision': 0.5077138849929874, 'recall': 0.4519350811485643, 'f1-score': 0.47820343461030385, 'support': 801.0}, 'Class_4': {'precision': 0.56, 'recall': 0.26022304832713755, 'f1-score': 0.35532994923857875, 'support': 269.0}, 'Class_5': {'precision': 0.9283154121863799, 'recall': 0.9452554744525548, 'f1-score': 0.9367088607594937, 'support': 274.0}, 'Class_6': {'precision': 0.9435600578871202, 'recall': 0.9228591648973815, 'f1-score': 0.9330948121645797, 'support': 1413.0}, 'Class_7': {'precision': 0.7407407407407407, 'recall': 0.5633802816901409, 'f1-score': 0.64, 'support': 284.0}, 'Class_8': {'precision': 0.893719806763285, 'recall': 0.8736717827626919, 'f1-score': 0.8835820895522388, 'support': 847.0}, 'Class_9': {'precision': 0.8285714285714286, 'recall': 0.8202020202020202, 'f1-score': 0.8243654822335026, 'support': 495.0}, 'accuracy': 0.7658371040723982, 'macro avg': {'precision': 0.7358809151680873, 'recall': 0.6913527089386583, 'f1-score': 0.7051808497550757, 'support': 6188.0}, 'weighted avg': {'precision': 0.7632993280401554, 'recall': 0.7658371040723982, 'f1-score': 0.7595580799166881, 'support': 6188.0}}}\n",
      "## INICIO FOLD 3 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.758 total time=   3.8s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.761 total time=   3.7s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.759 total time=   3.5s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.768 total time=   4.0s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.769 total time=   3.4s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.752 total time=   3.6s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.759 total time=   3.6s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.756 total time=   3.6s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.762 total time=   3.6s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.762 total time=   3.5s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.750 total time=   3.6s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.755 total time=   3.5s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.751 total time=   3.6s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.760 total time=   3.4s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.758 total time=   3.9s\n",
      "## FINAL FOLD 3 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7769877181641888, 'balanced_accuracy': 0.7029528212212971, 'precision_micro': 0.7769877181641888, 'precision_macro': 0.7568380596153309, 'precision_weighted': 0.7744424847920071, 'recall_micro': 0.7769877181641888, 'recall_macro': 0.7029528212212971, 'recall_weighted': 0.7769877181641888, 'f1_micro': 0.7769877181641888, 'f1_macro': 0.7208546867035307, 'f1_weighted': 0.7703909977102885, 'roc_auc_ovr_micro': 0.9541563117371905, 'roc_auc_ovo_micro': 0.9541563117371905, 'roc_auc_ovr_macro': 0.9259472832184026, 'roc_auc_ovo_macro': 0.9259472832184026, 'roc_auc_ovr_weighted': 0.9391475044530218, 'roc_auc_ovo_weighted': 0.9391475044530218}, 'classification_report': {'Class_1': {'precision': 0.5932203389830508, 'recall': 0.5440414507772021, 'f1-score': 0.5675675675675677, 'support': 193.0}, 'Class_2': {'precision': 0.6805909322465614, 'recall': 0.8287841191066998, 'f1-score': 0.7474125874125875, 'support': 1612.0}, 'Class_3': {'precision': 0.5362731152204836, 'recall': 0.4706616729088639, 'f1-score': 0.5013297872340424, 'support': 801.0}, 'Class_4': {'precision': 0.6111111111111112, 'recall': 0.2862453531598513, 'f1-score': 0.389873417721519, 'support': 269.0}, 'Class_5': {'precision': 0.9602888086642599, 'recall': 0.9708029197080292, 'f1-score': 0.9655172413793104, 'support': 274.0}, 'Class_6': {'precision': 0.9420186113099499, 'recall': 0.9313517338995047, 'f1-score': 0.9366548042704627, 'support': 1413.0}, 'Class_7': {'precision': 0.7361111111111112, 'recall': 0.5598591549295775, 'f1-score': 0.636, 'support': 284.0}, 'Class_8': {'precision': 0.8985680190930787, 'recall': 0.8900709219858156, 'f1-score': 0.8942992874109263, 'support': 846.0}, 'Class_9': {'precision': 0.8533604887983707, 'recall': 0.844758064516129, 'f1-score': 0.8490374873353597, 'support': 496.0}, 'accuracy': 0.7769877181641888, 'macro avg': {'precision': 0.7568380596153309, 'recall': 0.7029528212212971, 'f1-score': 0.7208546867035307, 'support': 6188.0}, 'weighted avg': {'precision': 0.7744424847920071, 'recall': 0.7769877181641888, 'f1-score': 0.7703909977102885, 'support': 6188.0}}}\n",
      "## INICIO FOLD 4 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.757 total time=   3.6s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.764 total time=   3.6s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.761 total time=   3.6s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.768 total time=   3.5s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.763 total time=   3.8s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.756 total time=   3.5s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.760 total time=   3.4s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.757 total time=   3.7s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.765 total time=   3.7s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.760 total time=   3.9s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.753 total time=   3.8s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.757 total time=   3.6s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.754 total time=   3.8s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.760 total time=   3.6s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.759 total time=   3.8s\n",
      "## FINAL FOLD 4 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7853910795087266, 'balanced_accuracy': 0.7095053564166839, 'precision_micro': 0.7853910795087266, 'precision_macro': 0.7686627730270585, 'precision_weighted': 0.7841067653085597, 'recall_micro': 0.7853910795087266, 'recall_macro': 0.7095053564166839, 'recall_weighted': 0.7853910795087266, 'f1_micro': 0.7853910795087266, 'f1_macro': 0.7282031502175297, 'f1_weighted': 0.7787803505470339, 'roc_auc_ovr_micro': 0.9562471090071949, 'roc_auc_ovo_micro': 0.9562471090071949, 'roc_auc_ovr_macro': 0.9283561777660884, 'roc_auc_ovo_macro': 0.9283561777660884, 'roc_auc_ovr_weighted': 0.9421239094726543, 'roc_auc_ovo_weighted': 0.9421239094726543}, 'classification_report': {'Class_1': {'precision': 0.5853658536585366, 'recall': 0.49740932642487046, 'f1-score': 0.53781512605042, 'support': 193.0}, 'Class_2': {'precision': 0.6974961676034747, 'recall': 0.8467741935483871, 'f1-score': 0.7649201456990754, 'support': 1612.0}, 'Class_3': {'precision': 0.5569620253164557, 'recall': 0.4943820224719101, 'f1-score': 0.5238095238095238, 'support': 801.0}, 'Class_4': {'precision': 0.7033898305084746, 'recall': 0.30855018587360594, 'f1-score': 0.42894056847545214, 'support': 269.0}, 'Class_5': {'precision': 0.9403508771929825, 'recall': 0.9781021897810219, 'f1-score': 0.9588550983899821, 'support': 274.0}, 'Class_6': {'precision': 0.9433285509325682, 'recall': 0.9306440198159943, 'f1-score': 0.9369433558959744, 'support': 1413.0}, 'Class_7': {'precision': 0.7510917030567685, 'recall': 0.6056338028169014, 'f1-score': 0.6705653021442494, 'support': 284.0}, 'Class_8': {'precision': 0.8927294398092968, 'recall': 0.8853427895981087, 'f1-score': 0.8890207715133531, 'support': 846.0}, 'Class_9': {'precision': 0.8472505091649695, 'recall': 0.8387096774193549, 'f1-score': 0.8429584599797366, 'support': 496.0}, 'accuracy': 0.7853910795087266, 'macro avg': {'precision': 0.7686627730270585, 'recall': 0.7095053564166839, 'f1-score': 0.7282031502175297, 'support': 6188.0}, 'weighted avg': {'precision': 0.7841067653085597, 'recall': 0.7853910795087266, 'f1-score': 0.7787803505470339, 'support': 6188.0}}}\n",
      "## INICIO FOLD 5 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.763 total time=   3.6s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.764 total time=   3.6s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.759 total time=   3.3s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.772 total time=   3.6s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.769 total time=   3.5s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.758 total time=   3.7s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.760 total time=   3.6s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.756 total time=   3.5s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.767 total time=   3.9s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.762 total time=   3.9s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.755 total time=   3.5s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.757 total time=   3.6s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.752 total time=   3.3s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.766 total time=   3.9s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.760 total time=   4.0s\n",
      "## FINAL FOLD 5 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7718164188752424, 'balanced_accuracy': 0.6946537646563603, 'precision_micro': 0.7718164188752424, 'precision_macro': 0.7549442956202327, 'precision_weighted': 0.7688618809352491, 'recall_micro': 0.7718164188752424, 'recall_macro': 0.6946537646563603, 'recall_weighted': 0.7718164188752424, 'f1_micro': 0.7718164188752425, 'f1_macro': 0.7132858516229855, 'f1_weighted': 0.7644444960963249, 'roc_auc_ovr_micro': 0.9536739017961866, 'roc_auc_ovo_micro': 0.9536739017961866, 'roc_auc_ovr_macro': 0.9263182747787371, 'roc_auc_ovo_macro': 0.9263182747787371, 'roc_auc_ovr_weighted': 0.9380973625725165, 'roc_auc_ovo_weighted': 0.9380973625725165}, 'classification_report': {'Class_1': {'precision': 0.6319018404907976, 'recall': 0.533678756476684, 'f1-score': 0.5786516853932584, 'support': 193.0}, 'Class_2': {'precision': 0.6841015018125324, 'recall': 0.8194789081885856, 'f1-score': 0.7456957380750777, 'support': 1612.0}, 'Class_3': {'precision': 0.5210884353741496, 'recall': 0.47875, 'f1-score': 0.4990228013029316, 'support': 800.0}, 'Class_4': {'precision': 0.6481481481481481, 'recall': 0.25925925925925924, 'f1-score': 0.3703703703703703, 'support': 270.0}, 'Class_5': {'precision': 0.9460431654676259, 'recall': 0.9633699633699634, 'f1-score': 0.9546279491833031, 'support': 273.0}, 'Class_6': {'precision': 0.9267605633802817, 'recall': 0.9306930693069307, 'f1-score': 0.9287226534932956, 'support': 1414.0}, 'Class_7': {'precision': 0.6905829596412556, 'recall': 0.5422535211267606, 'f1-score': 0.6074950690335306, 'support': 284.0}, 'Class_8': {'precision': 0.8866587957497049, 'recall': 0.8877068557919622, 'f1-score': 0.887182516243355, 'support': 846.0}, 'Class_9': {'precision': 0.8592132505175983, 'recall': 0.8366935483870968, 'f1-score': 0.8478038815117466, 'support': 496.0}, 'accuracy': 0.7718164188752424, 'macro avg': {'precision': 0.7549442956202327, 'recall': 0.6946537646563603, 'f1-score': 0.7132858516229855, 'support': 6188.0}, 'weighted avg': {'precision': 0.7688618809352491, 'recall': 0.7718164188752424, 'f1-score': 0.7644444960963249, 'support': 6188.0}}}\n",
      "## INICIO FOLD 6 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.755 total time=   4.2s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.761 total time=   4.1s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.757 total time=   4.0s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.770 total time=   5.1s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.769 total time=   3.7s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.752 total time=   3.7s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.755 total time=   3.7s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.751 total time=   4.1s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.766 total time=   4.2s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.761 total time=   4.3s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.751 total time=   3.8s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.751 total time=   4.1s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.749 total time=   4.1s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.764 total time=   3.6s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.758 total time=   4.0s\n",
      "## FINAL FOLD 6 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7734324499030382, 'balanced_accuracy': 0.7005722117516697, 'precision_micro': 0.7734324499030382, 'precision_macro': 0.7506680255297563, 'precision_weighted': 0.7709650024404134, 'recall_micro': 0.7734324499030382, 'recall_macro': 0.7005722117516697, 'recall_weighted': 0.7734324499030382, 'f1_micro': 0.7734324499030382, 'f1_macro': 0.718066816337161, 'f1_weighted': 0.7679279849294303, 'roc_auc_ovr_micro': 0.9554327996426556, 'roc_auc_ovo_micro': 0.9554327996426556, 'roc_auc_ovr_macro': 0.9288137821955149, 'roc_auc_ovo_macro': 0.9288137821955149, 'roc_auc_ovr_weighted': 0.940548601755117, 'roc_auc_ovo_weighted': 0.940548601755117}, 'classification_report': {'Class_1': {'precision': 0.5280898876404494, 'recall': 0.48704663212435234, 'f1-score': 0.5067385444743935, 'support': 193.0}, 'Class_2': {'precision': 0.6898535564853556, 'recall': 0.8182382133995038, 'f1-score': 0.7485811577752554, 'support': 1612.0}, 'Class_3': {'precision': 0.525, 'recall': 0.4725, 'f1-score': 0.4973684210526315, 'support': 800.0}, 'Class_4': {'precision': 0.6518518518518519, 'recall': 0.3271375464684015, 'f1-score': 0.4356435643564357, 'support': 269.0}, 'Class_5': {'precision': 0.9630996309963099, 'recall': 0.9525547445255474, 'f1-score': 0.9577981651376147, 'support': 274.0}, 'Class_6': {'precision': 0.9279151943462898, 'recall': 0.9285714285714286, 'f1-score': 0.928243195475433, 'support': 1414.0}, 'Class_7': {'precision': 0.7167381974248928, 'recall': 0.5880281690140845, 'f1-score': 0.6460348162475822, 'support': 284.0}, 'Class_8': {'precision': 0.8919567827130852, 'recall': 0.8782505910165485, 'f1-score': 0.8850506253722454, 'support': 846.0}, 'Class_9': {'precision': 0.8615071283095723, 'recall': 0.8528225806451613, 'f1-score': 0.8571428571428572, 'support': 496.0}, 'accuracy': 0.7734324499030382, 'macro avg': {'precision': 0.7506680255297563, 'recall': 0.7005722117516697, 'f1-score': 0.718066816337161, 'support': 6188.0}, 'weighted avg': {'precision': 0.7709650024404134, 'recall': 0.7734324499030382, 'f1-score': 0.7679279849294303, 'support': 6188.0}}}\n",
      "## INICIO FOLD 7 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.757 total time=   4.1s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.766 total time=   3.8s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.758 total time=   3.7s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.770 total time=   4.0s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.768 total time=   3.6s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.755 total time=   3.8s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.758 total time=   3.5s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.756 total time=   3.5s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.764 total time=   4.0s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.761 total time=   3.8s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.752 total time=   3.7s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.756 total time=   3.6s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.754 total time=   3.6s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.760 total time=   3.7s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.758 total time=   3.8s\n",
      "## FINAL FOLD 7 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7789269553975436, 'balanced_accuracy': 0.7129359087913036, 'precision_micro': 0.7789269553975436, 'precision_macro': 0.7697401961898609, 'precision_weighted': 0.7801609284532127, 'recall_micro': 0.7789269553975436, 'recall_macro': 0.7129359087913036, 'recall_weighted': 0.7789269553975436, 'f1_micro': 0.7789269553975436, 'f1_macro': 0.7301433080304158, 'f1_weighted': 0.7733185947345159, 'roc_auc_ovr_micro': 0.9537578437440065, 'roc_auc_ovo_micro': 0.9537578437440065, 'roc_auc_ovr_macro': 0.9279552276709898, 'roc_auc_ovo_macro': 0.9279552276709898, 'roc_auc_ovr_weighted': 0.9384785051914807, 'roc_auc_ovo_weighted': 0.9384785051914807}, 'classification_report': {'Class_1': {'precision': 0.6032608695652174, 'recall': 0.5751295336787565, 'f1-score': 0.5888594164456232, 'support': 193.0}, 'Class_2': {'precision': 0.6829020801623541, 'recall': 0.8349875930521092, 'f1-score': 0.7513257047167178, 'support': 1612.0}, 'Class_3': {'precision': 0.53601108033241, 'recall': 0.48375, 'f1-score': 0.5085413929040736, 'support': 800.0}, 'Class_4': {'precision': 0.6851851851851852, 'recall': 0.275092936802974, 'f1-score': 0.3925729442970822, 'support': 269.0}, 'Class_5': {'precision': 0.9740740740740741, 'recall': 0.9598540145985401, 'f1-score': 0.9669117647058824, 'support': 274.0}, 'Class_6': {'precision': 0.9351585014409222, 'recall': 0.917963224893918, 'f1-score': 0.9264810849393291, 'support': 1414.0}, 'Class_7': {'precision': 0.7298387096774194, 'recall': 0.6373239436619719, 'f1-score': 0.6804511278195489, 'support': 284.0}, 'Class_8': {'precision': 0.9064837905236908, 'recall': 0.859338061465721, 'f1-score': 0.8822815533980582, 'support': 846.0}, 'Class_9': {'precision': 0.8747474747474747, 'recall': 0.8729838709677419, 'f1-score': 0.8738647830474268, 'support': 496.0}, 'accuracy': 0.7789269553975436, 'macro avg': {'precision': 0.7697401961898609, 'recall': 0.7129359087913036, 'f1-score': 0.7301433080304158, 'support': 6188.0}, 'weighted avg': {'precision': 0.7801609284532127, 'recall': 0.7789269553975436, 'f1-score': 0.7733185947345159, 'support': 6188.0}}}\n",
      "## INICIO FOLD 8 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.763 total time=   3.6s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.766 total time=   3.7s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.762 total time=   3.6s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.770 total time=   3.6s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.767 total time=   3.6s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.758 total time=   4.0s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.760 total time=   3.6s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.752 total time=   3.9s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.763 total time=   3.8s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.759 total time=   3.6s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.755 total time=   3.9s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.757 total time=   3.8s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.752 total time=   3.5s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.762 total time=   4.0s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.758 total time=   3.7s\n",
      "## FINAL FOLD 8 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7722644254081138, 'balanced_accuracy': 0.6919516520532448, 'precision_micro': 0.7722644254081138, 'precision_macro': 0.746311807789776, 'precision_weighted': 0.7692966984480007, 'recall_micro': 0.7722644254081138, 'recall_macro': 0.6919516520532448, 'recall_weighted': 0.7722644254081138, 'f1_micro': 0.7722644254081138, 'f1_macro': 0.7087209606474038, 'f1_weighted': 0.7653656973121078, 'roc_auc_ovr_micro': 0.9511839157684733, 'roc_auc_ovo_micro': 0.9511839157684733, 'roc_auc_ovr_macro': 0.9187226439007653, 'roc_auc_ovo_macro': 0.9187226439007653, 'roc_auc_ovr_weighted': 0.9362543838427415, 'roc_auc_ovo_weighted': 0.9362543838427415}, 'classification_report': {'Class_1': {'precision': 0.5755813953488372, 'recall': 0.5129533678756477, 'f1-score': 0.5424657534246575, 'support': 193.0}, 'Class_2': {'precision': 0.6897089397089398, 'recall': 0.8232009925558312, 'f1-score': 0.7505656108597285, 'support': 1612.0}, 'Class_3': {'precision': 0.5332446808510638, 'recall': 0.50125, 'f1-score': 0.5167525773195876, 'support': 800.0}, 'Class_4': {'precision': 0.6160714285714286, 'recall': 0.25650557620817843, 'f1-score': 0.3622047244094488, 'support': 269.0}, 'Class_5': {'precision': 0.9363957597173145, 'recall': 0.9671532846715328, 'f1-score': 0.9515260323159785, 'support': 274.0}, 'Class_6': {'precision': 0.9293361884368309, 'recall': 0.9207920792079208, 'f1-score': 0.925044404973357, 'support': 1414.0}, 'Class_7': {'precision': 0.6866359447004609, 'recall': 0.5246478873239436, 'f1-score': 0.594810379241517, 'support': 284.0}, 'Class_8': {'precision': 0.8905882352941177, 'recall': 0.8947990543735225, 'f1-score': 0.8926886792452831, 'support': 846.0}, 'Class_9': {'precision': 0.8592436974789915, 'recall': 0.8262626262626263, 'f1-score': 0.8424304840370752, 'support': 495.0}, 'accuracy': 0.7722644254081138, 'macro avg': {'precision': 0.746311807789776, 'recall': 0.6919516520532448, 'f1-score': 0.7087209606474038, 'support': 6187.0}, 'weighted avg': {'precision': 0.7692966984480007, 'recall': 0.7722644254081138, 'f1-score': 0.7653656973121078, 'support': 6187.0}}}\n",
      "## INICIO FOLD 9 ##\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.758 total time=   3.9s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.768 total time=   3.7s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.761 total time=   3.9s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.771 total time=   3.8s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.767 total time=   3.8s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.753 total time=   3.6s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.761 total time=   4.2s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.752 total time=   4.8s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.766 total time=   4.4s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.759 total time=   5.7s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.753 total time=   7.8s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.760 total time=   5.5s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.750 total time=   3.9s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.762 total time=   3.6s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.759 total time=   3.9s\n",
      "## FINAL FOLD 9 ##\n",
      " {'parameters': {'n_neighbors': 5}, 'metrics': {'accuracy': 0.7748504929691288, 'balanced_accuracy': 0.7002796806954834, 'precision_micro': 0.7748504929691288, 'precision_macro': 0.7538138197337818, 'precision_weighted': 0.7714609407011053, 'recall_micro': 0.7748504929691288, 'recall_macro': 0.7002796806954834, 'recall_weighted': 0.7748504929691288, 'f1_micro': 0.7748504929691288, 'f1_macro': 0.7169743960651835, 'f1_weighted': 0.7676069833442994, 'roc_auc_ovr_micro': 0.9561393571624147, 'roc_auc_ovo_micro': 0.9561393571624147, 'roc_auc_ovr_macro': 0.9308015455118755, 'roc_auc_ovo_macro': 0.9308015455118755, 'roc_auc_ovr_weighted': 0.941243350665852, 'roc_auc_ovo_weighted': 0.941243350665852}, 'classification_report': {'Class_1': {'precision': 0.5867346938775511, 'recall': 0.5989583333333334, 'f1-score': 0.5927835051546393, 'support': 192.0}, 'Class_2': {'precision': 0.6845360824742268, 'recall': 0.8233106013639182, 'f1-score': 0.7475372924289334, 'support': 1613.0}, 'Class_3': {'precision': 0.5294117647058824, 'recall': 0.4725, 'f1-score': 0.499339498018494, 'support': 800.0}, 'Class_4': {'precision': 0.5847457627118644, 'recall': 0.25650557620817843, 'f1-score': 0.3565891472868217, 'support': 269.0}, 'Class_5': {'precision': 0.9530685920577617, 'recall': 0.9635036496350365, 'f1-score': 0.9582577132486388, 'support': 274.0}, 'Class_6': {'precision': 0.9297752808988764, 'recall': 0.9363507779349364, 'f1-score': 0.9330514446793515, 'support': 1414.0}, 'Class_7': {'precision': 0.7487684729064039, 'recall': 0.5371024734982333, 'f1-score': 0.6255144032921811, 'support': 283.0}, 'Class_8': {'precision': 0.8887587822014051, 'recall': 0.8961038961038961, 'f1-score': 0.8924162257495591, 'support': 847.0}, 'Class_9': {'precision': 0.8785249457700651, 'recall': 0.8181818181818182, 'f1-score': 0.8472803347280335, 'support': 495.0}, 'accuracy': 0.7748504929691288, 'macro avg': {'precision': 0.7538138197337818, 'recall': 0.7002796806954834, 'f1-score': 0.7169743960651835, 'support': 6187.0}, 'weighted avg': {'precision': 0.7714609407011053, 'recall': 0.7748504929691288, 'f1-score': 0.7676069833442994, 'support': 6187.0}}}\n"
     ]
    }
   ],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"n_neighbors\": [5, 10, 15]\n",
    "}\n",
    "# define o modelo\n",
    "model = KNeighborsClassifier(n_jobs=1)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(\n",
    "    model, params, X, y, \"KNN_variance_threshold\", flag_variance_threshold=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: DecisionTree\n",
      "## INICIO FOLD 0 ##\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=None;, score=0.699 total time=   2.5s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=None;, score=0.696 total time=   2.5s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=None;, score=0.698 total time=   3.3s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=None;, score=0.707 total time=   2.7s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=None;, score=0.701 total time=   2.9s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=50;, score=0.701 total time=   2.2s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=50;, score=0.696 total time=   2.5s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=50;, score=0.699 total time=   2.5s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=50;, score=0.706 total time=   2.5s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=50;, score=0.704 total time=   2.5s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=100;, score=0.699 total time=   2.4s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=100;, score=0.696 total time=   2.3s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=100;, score=0.698 total time=   2.8s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=100;, score=0.707 total time=   2.6s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=100;, score=0.701 total time=   2.5s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=200;, score=0.699 total time=   3.2s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=200;, score=0.696 total time=   2.4s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=200;, score=0.698 total time=   2.5s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=200;, score=0.707 total time=   2.2s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=200;, score=0.701 total time=   2.4s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=500;, score=0.699 total time=   2.4s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=500;, score=0.696 total time=   2.8s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=500;, score=0.698 total time=   2.7s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=500;, score=0.707 total time=   2.5s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=500;, score=0.701 total time=   2.6s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=1000;, score=0.699 total time=   2.7s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=1000;, score=0.696 total time=   2.9s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=1000;, score=0.698 total time=   3.1s\n"
     ]
    }
   ],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"max_depth\": [None, 50, 100, 200, 500, 1000]\n",
    "}\n",
    "# define o modelo\n",
    "model = DecisionTreeClassifier(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"DecisionTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"max_depth\": [None, 50, 100, 200, 500, 1000]\n",
    "}\n",
    "# define o modelo\n",
    "model = DecisionTreeClassifier(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"DecisionTree_smote\", flag_smote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"max_depth\": [None, 50, 100, 200, 500, 1000]\n",
    "}\n",
    "# define o modelo\n",
    "model = DecisionTreeClassifier(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(\n",
    "    model, params, X, y, \"DecisionTree_variance_threshold\", flag_variance_threshold=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    #\"n_estimators\": [100, 300, 500],\n",
    "    \"n_estimators\": [300, 500],\n",
    "    #\"max_depth\": [None, 400, 800],\n",
    "    \"class_weight\": [\"balanced_subsample\", None]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = RandomForestClassifier(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"RandomForest_smote\", flag_smote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes (Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = GaussianNB()\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"NaiveBayes_smote\", flag_smote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"penalty\": [None, \"l2\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"max_iter\": [100, 300, 500, 700, 1000]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = LogisticRegression(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"LogisticRegression_smote\", flag_smote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"penalty\": [None, \"l2\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"max_iter\": [100, 300, 500, 700, 1000]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = Perceptron(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"Perceptron_smote\", flag_smote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"learning_rate_init\": [0.001, 0.01],\n",
    "    \"max_iter\": [200, 500, 700],\n",
    "    \"hidden_layer_sizes\": [20, 50, 100]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = MLPClassifier(random_state=4)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"MLPClassifier_smote\", flag_smote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os parametros e seus respectivos valores a serem testados no grid search\n",
    "params = {\n",
    "    \"C\": [1],\n",
    "    \"kernel\": [\"rbf\", \"linear\"]\n",
    "}\n",
    "\n",
    "# define o modelo\n",
    "model = SVC(random_state=4, probability=True)\n",
    "# chama a funcao que roda o stratified k fold e valida o modelo realizando a busca por hiper \n",
    "# parametros com grid search cv, fazendo assim um nested cross-validation\n",
    "stratified_k_fold_grid_search_cv(model, params, X, y, \"SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste de Hipótese\n",
    "\n",
    "Vamos avaliar se a média dos resultados obtidos com o modelo Random Forest é maior que a média dos resultados obtidos com o modelo MLP. Iremos realizar um teste de hipótese para checar se, estatisticamente, podemos constatar essa afirmação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"log_metrics/RandomForest.json\") as json_file:\n",
    "    json_rf = json.load(json_file)\n",
    "\n",
    "lista_resultados_rf = []\n",
    "for key in list(json_rf.keys()):\n",
    "    if (key != \"mean\") & (key != \"std\") & (key != \"time\"):\n",
    "        lista_resultados_rf.append(json_rf[key][\"metrics\"][\"f1_weighted\"])\n",
    "\n",
    "with open(\"log_metrics/MLPClassifier.json\") as json_file:\n",
    "    json_mlp = json.load(json_file)\n",
    "\n",
    "lista_resultados_mlp = []\n",
    "for key in list(json_mlp.keys()):\n",
    "    if (key != \"mean\") & (key != \"std\") & (key != \"time\"):\n",
    "        lista_resultados_mlp.append(json_mlp[key][\"metrics\"][\"f1_weighted\"])\n",
    "\n",
    "df_resultados = pd.DataFrame({\"rf\": lista_resultados_rf, \"mlp\": lista_resultados_mlp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "sns.set(rc={'figure.figsize':(10,5)})\n",
    "\n",
    "sns.histplot(df_resultados, x=\"rf\", ax=ax[0]).set_title(\"Distribuicao Random Forest\")\n",
    "sns.histplot(df_resultados, x=\"mlp\", ax=ax[1]).set_title(\"Distribuicao MLP\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Teste normalidade random forest: {stats.shapiro(df_resultados['rf'])}\\n\"\n",
    "    f\"Teste normalidade mlp: {stats.shapiro(df_resultados['mlp'])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.mannwhitneyu(df_resultados[\"rf\"], df_resultados[\"mlp\"], alternative=\"greater\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Variancia random forest: {np.var(df_resultados['rf'])}\\n\"\n",
    "    f\"Variancia mlp: {np.var(df_resultados['mlp'])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(a=df_resultados[\"rf\"], b=df_resultados[\"mlp\"], equal_var=True, alternative=\"greater\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
